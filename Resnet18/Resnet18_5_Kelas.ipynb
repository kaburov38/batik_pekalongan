{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FF-56R2ou8f"
      },
      "outputs": [],
      "source": [
        "#Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exGK9yjdo144"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNCGaHqso3TA"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSa3Uefro6HM"
      },
      "source": [
        "**Load Data Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzqp5kVno3Qd"
      },
      "outputs": [],
      "source": [
        "Motif_liong = glob.glob('/content/drive/MyDrive/Deep Learning/Dataset/augmented/PEKALONGAN/Batik Liong/*')\n",
        "Motif_jlamprang = glob.glob('/content/drive/MyDrive/Deep Learning/Dataset/augmented/PEKALONGAN/Jlamprang/*')\n",
        "Motif_terangBulan = glob.glob('/content/drive/MyDrive/Deep Learning/Dataset/augmented/PEKALONGAN/Terang Bulan/*')\n",
        "Motif_tujuhRupa = glob.glob('/content/drive/MyDrive/Deep Learning/Dataset/PEKALONGAN/train/Tujuh Rupa/*')\n",
        "Motif_other = glob.glob('/content/drive/MyDrive/Deep Learning/Dataset/augmented/JAWA TENGAH/Parang/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKOtaNXHo3OA"
      },
      "outputs": [],
      "source": [
        "print(len(Motif_liong))\n",
        "print(len(Motif_jlamprang))\n",
        "print(len(Motif_terangBulan))\n",
        "print(len(Motif_tujuhRupa))\n",
        "print(len(Motif_other))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3HJ5S0bo3La"
      },
      "outputs": [],
      "source": [
        "len(PIL.Image.open(str(Motif_liong[50])).getbands())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUilcS8-o3I4"
      },
      "outputs": [],
      "source": [
        "liong = 0\n",
        "jlamprang = 0\n",
        "terangbulan = 0\n",
        "tujuhrupa = 0\n",
        "other = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMeMTG21o3GW"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "X_test = []\n",
        "Y_test = []\n",
        "#class 1\n",
        "for i in range(470):\n",
        "  if len(PIL.Image.open(str(Motif_liong[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_liong[i]))))\n",
        "    Y_train.append([1])\n",
        "    liong+=1\n",
        "for i in range(470,500):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(Motif_liong[i]))))\n",
        "  Y_test.append([1])\n",
        "\n",
        "#class 2\n",
        "for i in range(470):\n",
        "  if len(PIL.Image.open(str(Motif_jlamprang[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_jlamprang[i]))))\n",
        "    Y_train.append([2])\n",
        "    jlamprang+=1\n",
        "for i in range(470,500):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(Motif_jlamprang[i]))))\n",
        "  Y_test.append([2])\n",
        "\n",
        "#class 3\n",
        "for i in range(470):\n",
        "  if len(PIL.Image.open(str(Motif_terangBulan[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_terangBulan[i]))))\n",
        "    Y_train.append([3])\n",
        "    terangbulan+=1\n",
        "for i in range(470,500):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(Motif_terangBulan[i]))))\n",
        "  Y_test.append([3])\n",
        "\n",
        "#class 4\n",
        "for i in range(473):\n",
        "  if len(PIL.Image.open(str(Motif_tujuhRupa[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_tujuhRupa[i]))))\n",
        "    Y_train.append([4])\n",
        "    tujuhrupa+=1\n",
        "for i in range(473,503):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(Motif_tujuhRupa[i]))))\n",
        "  Y_test.append([4])\n",
        "\n",
        "#class 5\n",
        "for i in range(470):\n",
        "  if len(PIL.Image.open(str(Motif_other[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_other[i]))))\n",
        "    Y_train.append([5])\n",
        "    other+=1\n",
        "for i in range(470,500):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(Motif_other[i]))))\n",
        "  Y_test.append([5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upZ4_VOVo3Dv"
      },
      "outputs": [],
      "source": [
        "print(liong)\n",
        "print(jlamprang)\n",
        "print(terangbulan)\n",
        "print(tujuhrupa)\n",
        "print(other)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WfaIQaFo3BF"
      },
      "outputs": [],
      "source": [
        "Motif_liong[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4zgIlgOo2-e"
      },
      "outputs": [],
      "source": [
        "# Drawing sample\n",
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu_bVew5o278"
      },
      "outputs": [],
      "source": [
        "import PIL.ImageOps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5q3kWzxo25Z"
      },
      "outputs": [],
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i] = np.asarray(PIL.ImageOps.fit(PIL.Image.fromarray(np.uint8(X_train[i])), size=(200,200)))\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i] = np.asarray(PIL.ImageOps.fit(PIL.Image.fromarray(np.uint8(X_test[i])), size=(200,200)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGk3uQVMo221"
      },
      "outputs": [],
      "source": [
        "# Drawing sample\n",
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIHoQnD0o20G"
      },
      "outputs": [],
      "source": [
        "Y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN44e33so2xi"
      },
      "outputs": [],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU3S4jKqo2u9"
      },
      "outputs": [],
      "source": [
        "X_flip_train = []\n",
        "Y_flip_train = []\n",
        "X_flip_test = []\n",
        "Y_flip_test = []\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  X_flip_train.append(X_train[i])\n",
        "  Y_flip_train.append(Y_train[i])\n",
        "  X_flip_train.append(np.asarray(PIL.ImageOps.mirror(PIL.Image.fromarray(np.uint8(X_train[i])))))\n",
        "  Y_flip_train.append(Y_train[i])\n",
        "for i in range(len(X_test)):\n",
        "  X_flip_test.append(X_test[i])\n",
        "  Y_flip_test.append(Y_test[i])\n",
        "  X_flip_test.append(np.asarray(PIL.ImageOps.mirror(PIL.Image.fromarray(np.uint8(X_test[i])))))\n",
        "  Y_flip_test.append(Y_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lIo9g2Yo2sW"
      },
      "outputs": [],
      "source": [
        "Y_flip_train[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ709Fdno2p0"
      },
      "outputs": [],
      "source": [
        "# Normalize the data.\n",
        "X_train = np.array(X_train, dtype='float32')\n",
        "X_test = np.array(X_test, dtype='float32')\n",
        "X_flip_train = np.array(X_flip_train, dtype='float32')\n",
        "X_flip_test = np.array(X_flip_test, dtype='float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "X_flip_train /= 255.0\n",
        "X_flip_test /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "926Fg1LYo2iV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2,shuffle = True)\n",
        "X_flip_train, X_flip_val, Y_flip_train, Y_flip_val = train_test_split(X_flip_train, Y_flip_train, test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyaL4EORpOOp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(Y_train)\n",
        "Y_train = encoder.transform(Y_train).toarray()\n",
        "Y_test = encoder.transform(Y_test).toarray()\n",
        "Y_flip_train = encoder.transform(Y_flip_train).toarray()\n",
        "Y_flip_test = encoder.transform(Y_flip_test).toarray()\n",
        "Y_val =  encoder.transform(Y_val).toarray()\n",
        "Y_flip_val = encoder.transform(Y_flip_val).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j_lcOjSpOMX"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "aug = ImageDataGenerator(horizontal_flip=True, width_shift_range=0.05,\n",
        "                              height_shift_range=0.05)\n",
        "aug.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46BIgLkppWMX"
      },
      "source": [
        "**Implement ResNet-18 model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlGW78yIpOJx"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ResNet-18\n",
        "Reference:\n",
        "[1] K. He et al. Deep Residual Learning for Image Recognition. CVPR, 2016\n",
        "[2] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers:\n",
        "Surpassing human-level performance on imagenet classification. In\n",
        "ICCV, 2015.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Add, Activation, Input, MaxPooling2D, ZeroPadding2D, AveragePooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras import layers, activations \n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "class ResnetBlock(Model):\n",
        "    \"\"\"\n",
        "    A standard resnet block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, down_sample=False):\n",
        "        \"\"\"\n",
        "        channels: same as number of convolution kernels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "\n",
        "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_1 = BatchNormalization()\n",
        "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_2 = BatchNormalization()\n",
        "        self.merge = Add()\n",
        "\n",
        "        if self.__down_sample:\n",
        "            # perform down sampling using stride of 2, according to [1].\n",
        "            self.res_conv = Conv2D(\n",
        "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            self.res_bn = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "\n",
        "        # if not perform down sample, then add a shortcut directly\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.init_bn = BatchNormalization()\n",
        "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(128)\n",
        "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(256)\n",
        "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_4_2 = ResnetBlock(512)\n",
        "        self.dropout = Dropout(0.15)\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.flat = Flatten()\n",
        "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
        "            out = res_block(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEJTJBW5pOHP"
      },
      "outputs": [],
      "source": [
        "# model = ResNet18(5)\n",
        "# model.build(input_shape = (None,250,250,3))\n",
        "# #use categorical_crossentropy since the label is one-hot encoded\n",
        "# #from keras.optimizers import SGD\n",
        "# #opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "# #tf.keras.optimizers.SGD()\n",
        "# model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwMOSzyCpOE2"
      },
      "outputs": [],
      "source": [
        "# gpus = tf.config.list_physical_devices('GPU')\n",
        "# if gpus:\n",
        "#   # Restrict TensorFlow to only use the first GPU\n",
        "#   try:\n",
        "#     tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "#     logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "#   except RuntimeError as e:\n",
        "#     # Visible devices must be set before GPUs have been initialized\n",
        "#     print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJnGcbXypN85"
      },
      "outputs": [],
      "source": [
        "# from keras.callbacks import EarlyStopping\n",
        "\n",
        "# es = EarlyStopping(patience= 6, restore_best_weights=True, monitor=\"val_accuracy\")\n",
        "# #I did not use cross validation, so the validate performance is not accurate.\n",
        "# STEPS = len(X_train) / 32\n",
        "# history = model.fit(X_train, Y_train, batch_size = 32, steps_per_epoch=np.float32(STEPS), epochs=50, validation_data=(X_val, Y_val), callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKFZzJYKpN6a"
      },
      "outputs": [],
      "source": [
        "# ## Evaluation\n",
        "\n",
        "# ModelLoss, ModelAccuracy = model.evaluate(X_train, Y_train)\n",
        "\n",
        "# print('Model Loss is {}'.format(ModelLoss))\n",
        "# print('Model Accuracy is {}'.format(ModelAccuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gim_oaiNpN3v"
      },
      "outputs": [],
      "source": [
        "# Y_pred = []\n",
        "# for i in range(len(X_test)):\n",
        "#   Y_pred.append(model.predict(X_test[i:i+1]).tolist()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dELgTM4ppN1M"
      },
      "outputs": [],
      "source": [
        "# test_class = np.argmax(Y_test, axis=1)\n",
        "# Y_true = test_class.tolist()\n",
        "# pred_class = np.argmax(Y_pred, axis=1)\n",
        "# Y_pred = pred_class.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb0BDN3xphg4"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXjGvOCzphb2"
      },
      "outputs": [],
      "source": [
        "# accuracy_score(y_true=Y_true, y_pred=Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy5ZoiecpheW"
      },
      "outputs": [],
      "source": [
        "# conf_matrix = confusion_matrix(y_true=Y_true, y_pred=Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmyPNgKhphZW"
      },
      "outputs": [],
      "source": [
        "# accuracy = accuracy_score(y_true=Y_true, y_pred=Y_pred)\n",
        "# accuracy *= 100\n",
        "# print(\"Accuracy : \" , accuracy , \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-SaY5YJphW1"
      },
      "outputs": [],
      "source": [
        "# fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "# ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "# for i in range(conf_matrix.shape[0]):\n",
        "#     for j in range(conf_matrix.shape[1]):\n",
        "#         ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "# plt.xlabel('Predictions', fontsize=18)\n",
        "# plt.ylabel('Actuals', fontsize=18)\n",
        "# plt.title('Confusion Matrix', fontsize=18)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_flip = ResNet18(5)\n",
        "model_flip.build(input_shape = (None,200,200,3))\n",
        "#use categorical_crossentropy since the label is one-hot encoded\n",
        "#from keras.optimizers import SGD\n",
        "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "model_flip.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001),loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
        "model_flip.summary()"
      ],
      "metadata": {
        "id": "EPJsclXfKIwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "nzSqRcznKLTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(patience= 6, restore_best_weights=True, monitor=\"val_accuracy\")\n",
        "history_flip = model_flip.fit(X_flip_train, Y_flip_train, batch_size = 16, epochs=50, steps_per_epoch=np.float32(len(X_flip_train)/16), validation_data=(X_flip_test, Y_flip_test), callbacks=[es])"
      ],
      "metadata": {
        "id": "VZDKdiEzKNRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_flip_pred = []\n",
        "for i in range(len(X_flip_test)):\n",
        "  Y_flip_pred.append(model_flip.predict(X_flip_test[i:i+1]).tolist()[0])"
      ],
      "metadata": {
        "id": "MyJUooOWKQEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_flip_class = np.argmax(Y_flip_test, axis=1)\n",
        "Y_flip_true = test_flip_class.tolist()\n",
        "pred_flip_class = np.argmax(Y_flip_pred, axis=1)\n",
        "Y_flip_pred = pred_flip_class.tolist()"
      ],
      "metadata": {
        "id": "IM9X0SLLKQDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "accuracy_score(y_true=Y_flip_true, y_pred=Y_flip_pred)"
      ],
      "metadata": {
        "id": "edfdtoRLKQCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_flip_matrix = confusion_matrix(y_true=Y_flip_true, y_pred=Y_flip_pred)"
      ],
      "metadata": {
        "id": "iYijVFlxKQBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(conf_flip_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_flip_matrix.shape[0]):\n",
        "    for j in range(conf_flip_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_flip_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lGRxhQDOKQAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batik = ['Liong', 'Jlamprang', 'Terang bulan', 'Tujuh Rupa', 'Parang']\n",
        "plt.imshow(X_flip_test[60])\n",
        "print(\"true label: \", batik[Y_flip_true[60]])\n",
        "print(\"predicted label: \", batik[Y_flip_pred[60]])"
      ],
      "metadata": {
        "id": "lR_QMiFaKP7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batik = ['Liong', 'Jlamprang', 'Terang bulan', 'Tujuh Rupa', 'Parang']\n",
        "plt.imshow(X_flip_test[78])\n",
        "print(\"true label: \", batik[Y_flip_true[78]])\n",
        "print(\"predicted label: \", batik[Y_flip_pred[78]])"
      ],
      "metadata": {
        "id": "aQYHqDFRgWrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batik = ['Liong', 'Jlamprang', 'Terang bulan', 'Tujuh Rupa', 'Parang']\n",
        "plt.imshow(X_flip_test[150])\n",
        "print(\"true label: \", batik[Y_flip_true[150]])\n",
        "print(\"predicted label: \", batik[Y_flip_pred[150]])"
      ],
      "metadata": {
        "id": "M7vvIKpTgbwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batik = ['Liong', 'Jlamprang', 'Terang bulan', 'Tujuh Rupa', 'Parang']\n",
        "plt.imshow(X_flip_test[85])\n",
        "print(\"true label: \", batik[Y_flip_true[85]])\n",
        "print(\"predicted label: \", batik[Y_flip_pred[85]])"
      ],
      "metadata": {
        "id": "yX-eqKMAglQe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Resnet18_5 Kelas_Final.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}