{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KKWYNnLUlmk4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FoLro5zlzIq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_RvaiG3Wl0FP"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "not-ZoU3hLRx"
      },
      "source": [
        "**Load Data Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YslWoO3cmI_X"
      },
      "outputs": [],
      "source": [
        "Motif_liong = glob.glob('/content/drive/MyDrive/PEKALONGAN/train/Liong/*')\n",
        "Motif_jlamprang = glob.glob('/content/drive/MyDrive/PEKALONGAN/train/Jlamprang/*')\n",
        "Motif_terangBulan = glob.glob('/content/drive/MyDrive/PEKALONGAN/train/Terang Bulan/*')\n",
        "Motif_tujuhRupa = glob.glob('/content/drive/MyDrive/PEKALONGAN/train/Tujuh Rupa/*')\n",
        "Motif_other = glob.glob('/content/drive/MyDrive/JAWA TENGAH/Parang/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYf5tmI_mXF6"
      },
      "outputs": [],
      "source": [
        "print(len(Motif_liong))\n",
        "print(len(Motif_jlamprang))\n",
        "print(len(Motif_terangBulan))\n",
        "print(len(Motif_tujuhRupa))\n",
        "print(len(Motif_other))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRs9yEfvyZ0C"
      },
      "outputs": [],
      "source": [
        "len(PIL.Image.open(str(Motif_liong[50])).getbands())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NtBrlY8wwNij"
      },
      "outputs": [],
      "source": [
        "liong = 0\n",
        "jlamprang = 0\n",
        "terangbulan = 0\n",
        "tujuhrupa = 0\n",
        "other = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uNZNcWhdBAPo"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "X_test = []\n",
        "Y_test = []\n",
        "#class 1\n",
        "for i in range(460):\n",
        "  if len(PIL.Image.open(str(Motif_liong[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_liong[i]))))\n",
        "    Y_train.append([1])\n",
        "    liong+=1\n",
        "for i in range(460,500):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(Motif_liong[i]))))\n",
        "  Y_test.append([1])\n",
        "\n",
        "#class 2\n",
        "for i in range(460):\n",
        "  if len(PIL.Image.open(str(Motif_jlamprang[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_jlamprang[i]))))\n",
        "    Y_train.append([2])\n",
        "    jlamprang+=1\n",
        "for i in range(460,500):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(Motif_jlamprang[i]))))\n",
        "  Y_test.append([2])\n",
        "\n",
        "#class 3\n",
        "for i in range(460):\n",
        "  if len(PIL.Image.open(str(Motif_terangBulan[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_terangBulan[i]))))\n",
        "    Y_train.append([3])\n",
        "    terangbulan+=1\n",
        "for i in range(460,500):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(Motif_terangBulan[i]))))\n",
        "  Y_test.append([3])\n",
        "\n",
        "#class 4\n",
        "for i in range(463):\n",
        "  if len(PIL.Image.open(str(Motif_tujuhRupa[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_tujuhRupa[i]))))\n",
        "    Y_train.append([4])\n",
        "    tujuhrupa+=1\n",
        "for i in range(463,503):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(Motif_tujuhRupa[i]))))\n",
        "  Y_test.append([4])\n",
        "\n",
        "#class 5\n",
        "for i in range(460):\n",
        "  if len(PIL.Image.open(str(Motif_other[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_other[i]))))\n",
        "    Y_train.append([5])\n",
        "    other+=1\n",
        "for i in range(460,500):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(Motif_other[i]))))\n",
        "  Y_test.append([5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aXzHjonwVDd"
      },
      "outputs": [],
      "source": [
        "print(liong)\n",
        "print(jlamprang)\n",
        "print(terangbulan)\n",
        "print(tujuhrupa)\n",
        "print(other)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuT1_rSJmT1d"
      },
      "outputs": [],
      "source": [
        "Motif_liong[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46CdqxxqpfHD"
      },
      "outputs": [],
      "source": [
        "# Drawing sample\n",
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "29XOnsoMpj8V"
      },
      "outputs": [],
      "source": [
        "import PIL.ImageOps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tF-GdEkwpoZi"
      },
      "outputs": [],
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i] = np.asarray(PIL.ImageOps.fit(PIL.Image.fromarray(np.uint8(X_train[i])), size=(250,250)))\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i] = np.asarray(PIL.ImageOps.fit(PIL.Image.fromarray(np.uint8(X_test[i])), size=(250,250)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmqctFnrpsHj"
      },
      "outputs": [],
      "source": [
        "# Drawing sample\n",
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ77EhFgpyJK"
      },
      "outputs": [],
      "source": [
        "Y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db8FIr99rRz0"
      },
      "outputs": [],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Kud2X0gmp5aG"
      },
      "outputs": [],
      "source": [
        "X_flip_train = []\n",
        "Y_flip_train = []\n",
        "X_flip_test = []\n",
        "Y_flip_test = []\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  X_flip_train.append(X_train[i])\n",
        "  Y_flip_train.append(Y_train[i])\n",
        "  X_flip_train.append(np.asarray(PIL.ImageOps.mirror(PIL.Image.fromarray(np.uint8(X_train[i])))))\n",
        "  Y_flip_train.append(Y_train[i])\n",
        "for i in range(len(X_test)):\n",
        "  X_flip_test.append(X_test[i])\n",
        "  Y_flip_test.append(Y_test[i])\n",
        "  X_flip_test.append(np.asarray(PIL.ImageOps.mirror(PIL.Image.fromarray(np.uint8(X_test[i])))))\n",
        "  Y_flip_test.append(Y_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "At9NFZwZqHOl"
      },
      "outputs": [],
      "source": [
        "Y_flip_train[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IOHpMdzWqJeD"
      },
      "outputs": [],
      "source": [
        "# Normalize the data.\n",
        "X_train = np.array(X_train, dtype='float32')\n",
        "X_test = np.array(X_test, dtype='float32')\n",
        "X_flip_train = np.array(X_flip_train, dtype='float32')\n",
        "X_flip_test = np.array(X_flip_test, dtype='float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "X_flip_train /= 255.0\n",
        "X_flip_test /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tkn3hT7rqMiK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2,shuffle = True)\n",
        "X_flip_train, X_flip_val, Y_flip_train, Y_flip_val = train_test_split(X_flip_train, Y_flip_train, test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oPUwbBO_qPgO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(Y_train)\n",
        "Y_train = encoder.transform(Y_train).toarray()\n",
        "Y_test = encoder.transform(Y_test).toarray()\n",
        "Y_flip_train = encoder.transform(Y_flip_train).toarray()\n",
        "Y_flip_test = encoder.transform(Y_flip_test).toarray()\n",
        "Y_val =  encoder.transform(Y_val).toarray()\n",
        "Y_flip_val = encoder.transform(Y_flip_val).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cgfXBAlLqQM-"
      },
      "outputs": [],
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# aug = ImageDataGenerator(horizontal_flip=True, width_shift_range=0.05,\n",
        "#                               height_shift_range=0.05)\n",
        "# aug.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4hBJx_jAqQLj"
      },
      "outputs": [],
      "source": [
        "# aug.flow(X_train, Y_train, batch_size=len(X_train))[0][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoEN1rHrQ8tQ"
      },
      "source": [
        "**Implement ResNet-18 model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "akAzJFP9qQHq"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ResNet-18\n",
        "Reference:\n",
        "[1] K. He et al. Deep Residual Learning for Image Recognition. CVPR, 2016\n",
        "[2] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers:\n",
        "Surpassing human-level performance on imagenet classification. In\n",
        "ICCV, 2015.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Add, Activation, Input, MaxPooling2D, ZeroPadding2D, AveragePooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras import layers, activations \n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "class ResnetBlock(Model):\n",
        "    \"\"\"\n",
        "    A standard resnet block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, down_sample=False):\n",
        "        \"\"\"\n",
        "        channels: same as number of convolution kernels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "\n",
        "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_1 = BatchNormalization()\n",
        "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_2 = BatchNormalization()\n",
        "        self.merge = Add()\n",
        "\n",
        "        if self.__down_sample:\n",
        "            # perform down sampling using stride of 2, according to [1].\n",
        "            self.res_conv = Conv2D(\n",
        "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            self.res_bn = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "\n",
        "        # if not perform down sample, then add a shortcut directly\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.init_bn = BatchNormalization()\n",
        "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(128)\n",
        "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(256)\n",
        "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_4_2 = ResnetBlock(512)\n",
        "        self.dropout = Dropout(0.2)\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.flat = Flatten()\n",
        "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
        "            out = res_block(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KxazyGH4qQDD"
      },
      "outputs": [],
      "source": [
        "model = ResNet18(5)\n",
        "model.build(input_shape = (None,250,250,3))\n",
        "#use categorical_crossentropy since the label is one-hot encoded\n",
        "#from keras.optimizers import SGD\n",
        "#opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "#tf.keras.optimizers.SGD()\n",
        "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "AC4Dy_5VqP93"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dU5HQNtLq8ls"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(patience= 8, restore_best_weights=True, monitor=\"val_accuracy\")\n",
        "#I did not use cross validation, so the validate performance is not accurate.\n",
        "STEPS = len(X_train) / 32\n",
        "history = model.fit(X_train, Y_train, batch_size = 32, steps_per_epoch=np.float32(STEPS), epochs=50, validation_data=(X_val, Y_val), callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XF9fAPvarUwn"
      },
      "outputs": [],
      "source": [
        "Y_pred = []\n",
        "for i in range(len(X_test)):\n",
        "  Y_pred.append(model.predict(X_test[i:i+1]).tolist()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "AbATd-cHrVex"
      },
      "outputs": [],
      "source": [
        "test_class = np.argmax(Y_test, axis=1)\n",
        "Y_true = test_class.tolist()\n",
        "pred_class = np.argmax(Y_pred, axis=1)\n",
        "Y_pred = pred_class.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-ihsU-cKrVcK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "w-FN5iOYrVZx"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_true=Y_true, y_pred=Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qvh8NtV3rVXA"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_true=Y_true, y_pred=Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "z-iH3PIhrVUU"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batik = ['Liong', 'Jlamprang', 'Terang bulan', 'Tujuh Rupa', 'Parang']\n",
        "plt.imshow(X_test[60])\n",
        "print(\"true label: \", batik[Y_true[60]])\n",
        "print(\"predicted label: \", batik[Y_pred[60]])"
      ],
      "metadata": {
        "id": "tQ_xsIjywW32"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_flip = ResNet18(5)\n",
        "model_flip.build(input_shape = (None,250,250,3))\n",
        "#use categorical_crossentropy since the label is one-hot encoded\n",
        "#from keras.optimizers import SGD\n",
        "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "model_flip.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001),loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
        "model_flip.summary()"
      ],
      "metadata": {
        "id": "AfIxFQimwWhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "_bw-CDDTwWU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(patience= 10, restore_best_weights=True, monitor=\"val_accuracy\")\n",
        "history_flip = model_flip.fit(X_flip_train, Y_flip_train, batch_size = 32, epochs=50, steps_per_epoch=np.float32(len(X_flip_train)/32), validation_data=(X_flip_test, Y_flip_test), callbacks=[es])"
      ],
      "metadata": {
        "id": "5ZdvQ-82xe3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_flip_pred = []\n",
        "for i in range(len(X_flip_test)):\n",
        "  Y_flip_pred.append(model_flip.predict(X_flip_test[i:i+1]).tolist()[0])"
      ],
      "metadata": {
        "id": "nrPi0KU4xe0I"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_flip_class = np.argmax(Y_flip_test, axis=1)\n",
        "Y_flip_true = test_flip_class.tolist()\n",
        "pred_flip_class = np.argmax(Y_flip_pred, axis=1)\n",
        "Y_flip_pred = pred_flip_class.tolist()"
      ],
      "metadata": {
        "id": "QsHYFPeFxexr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "accuracy_score(y_true=Y_flip_true, y_pred=Y_flip_pred)"
      ],
      "metadata": {
        "id": "0-KWq54nxeu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_flip_matrix = confusion_matrix(y_true=Y_flip_true, y_pred=Y_flip_pred)"
      ],
      "metadata": {
        "id": "ucxSlMcYxesi"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(conf_flip_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_flip_matrix.shape[0]):\n",
        "    for j in range(conf_flip_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_flip_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zQuRgH5qxv_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batik = ['Liong', 'Jlamprang', 'Terang bulan', 'Tujuh Rupa', 'Parang']\n",
        "plt.imshow(X_flip_test[205])\n",
        "print(\"true label: \", batik[Y_flip_true[205]])\n",
        "print(\"predicted label: \", batik[Y_flip_pred[205]])"
      ],
      "metadata": {
        "id": "VdWvMlAAxwjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XUKWshOfGKd8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Resnet18_5 Kelas_Final.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}