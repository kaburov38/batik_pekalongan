{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaburov38/batik_pekalongan/blob/main/resnet18_4_kelas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnmfH_CX5tjL"
      },
      "outputs": [],
      "source": [
        "#Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft8z1MYAGlRJ",
        "outputId": "c251b6f0-9a78-49d0-e76a-34b8b96f8b34"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GJPAbZcItCw"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3OdEgo_JK4L"
      },
      "outputs": [],
      "source": [
        "Motif_liong = glob.glob('/content/drive/MyDrive/PEKALONGAN/train/Liong/*')\n",
        "Motif_jlamprang = glob.glob('/content/drive/MyDrive/PEKALONGAN/train/Jlamprang/*')\n",
        "Motif_terangBulan = glob.glob('/content/drive/MyDrive/PEKALONGAN/train/Terang Bulan/*')\n",
        "Motif_tujuhRupa = glob.glob('/content/drive/MyDrive/PEKALONGAN/train/Tujuh Rupa/*')\n",
        "test_liong = glob.glob('/content/drive/MyDrive/PEKALONGAN/test/Liong/*')\n",
        "test_jlamprang = glob.glob('/content/drive/MyDrive/PEKALONGAN/test/Jlamprang/*')\n",
        "test_terangBulan = glob.glob('/content/drive/MyDrive/PEKALONGAN/test/Terang Bulan/*')\n",
        "test_tujuhRupa = glob.glob('/content/drive/MyDrive/PEKALONGAN/test/Tujuh Rupa/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SecXVlPQKGNh",
        "outputId": "3d420bfd-5925-4281-b0ad-b72ed77805f4"
      },
      "outputs": [],
      "source": [
        "len(Motif_liong)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbXr2h0dJ7qQ"
      },
      "outputs": [],
      "source": [
        "liong = 0\n",
        "jlamprang = 0\n",
        "terangbulan = 0\n",
        "tujuhrupa = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FgmXibPJcvX"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "X_test = []\n",
        "Y_test = []\n",
        "#class 1\n",
        "for i in range(480):\n",
        "  if len(PIL.Image.open(str(Motif_liong[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_liong[i]))))\n",
        "    Y_train.append([1])\n",
        "    liong+=1\n",
        "for i in range(480,500):\n",
        "  if len(PIL.Image.open(str(Motif_liong[i])).getbands()) == 3:\n",
        "    X_test.append(np.asarray(PIL.Image.open(str(Motif_liong[i]))))\n",
        "    Y_test.append([1])\n",
        "    liong+=1\n",
        "for i in range(len(test_liong)):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(test_liong[i]))))\n",
        "  Y_test.append([1])\n",
        "\n",
        "#class 2\n",
        "for i in range(480):\n",
        "  if len(PIL.Image.open(str(Motif_jlamprang[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_jlamprang[i]))))\n",
        "    Y_train.append([2])\n",
        "    jlamprang+=1\n",
        "for i in range(480,500):\n",
        "  if len(PIL.Image.open(str(Motif_jlamprang[i])).getbands()) == 3:\n",
        "    X_test.append(np.asarray(PIL.Image.open(str(Motif_jlamprang[i]))))\n",
        "    Y_test.append([2])\n",
        "    jlamprang+=1\n",
        "for i in range(len(test_jlamprang)):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(test_jlamprang[i]))))\n",
        "  Y_test.append([2])\n",
        "\n",
        "#class 3\n",
        "for i in range(480):\n",
        "  if len(PIL.Image.open(str(Motif_terangBulan[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_terangBulan[i]))))\n",
        "    Y_train.append([3])\n",
        "    terangbulan+=1\n",
        "for i in range(480,500):\n",
        "  if len(PIL.Image.open(str(Motif_terangBulan[i])).getbands()) == 3:\n",
        "    X_test.append(np.asarray(PIL.Image.open(str(Motif_terangBulan[i]))))\n",
        "    Y_test.append([3])\n",
        "    terangbulan+=1\n",
        "for i in range(len(test_terangBulan)):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(test_terangBulan[i]))))\n",
        "  Y_test.append([3])\n",
        "\n",
        "#class 4\n",
        "for i in range(483):\n",
        "  if len(PIL.Image.open(str(Motif_tujuhRupa[i])).getbands()) == 3:\n",
        "    X_train.append(np.asarray(PIL.Image.open(str(Motif_tujuhRupa[i]))))\n",
        "    Y_train.append([4])\n",
        "    tujuhrupa+=1\n",
        "for i in range(483,503):\n",
        "  if len(PIL.Image.open(str(Motif_tujuhRupa[i])).getbands()) == 3:\n",
        "    X_test.append(np.asarray(PIL.Image.open(str(Motif_tujuhRupa[i]))))\n",
        "    Y_test.append([4])\n",
        "    tujuhrupa+=1\n",
        "for i in range(len(test_tujuhRupa)):\n",
        "  X_test.append(np.asarray(PIL.Image.open(str(test_tujuhRupa[i]))))\n",
        "  Y_test.append([4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "GVo8GMda59te",
        "outputId": "20d99e2c-c33a-4c19-a98c-d51626bc71af"
      },
      "outputs": [],
      "source": [
        "# Drawing sample . \n",
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYIJt3n0OE7u"
      },
      "outputs": [],
      "source": [
        "import PIL.ImageOps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWtUYLXiOMwu"
      },
      "outputs": [],
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i] = np.asarray(PIL.ImageOps.fit(PIL.Image.fromarray(np.uint8(X_train[i])), size=(250,250)))\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i] = np.asarray(PIL.ImageOps.fit(PIL.Image.fromarray(np.uint8(X_test[i])), size=(250,250)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "gmZ-2IVYeBYy",
        "outputId": "7163e9ab-f301-4bf1-d73c-e463575a7ad8"
      },
      "outputs": [],
      "source": [
        "# Drawing sample . \n",
        "plt.imshow(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUki6osHvojv",
        "outputId": "74120faf-12e7-491d-a5eb-9016a852de97"
      },
      "outputs": [],
      "source": [
        "Y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPBU2wtjznR0"
      },
      "outputs": [],
      "source": [
        "X_flip_train = []\n",
        "Y_flip_train = []\n",
        "X_flip_test = []\n",
        "Y_flip_test = []\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  X_flip_train.append(X_train[i])\n",
        "  Y_flip_train.append(Y_train[i])\n",
        "  X_flip_train.append(np.asarray(PIL.ImageOps.mirror(PIL.Image.fromarray(np.uint8(X_train[i])))))\n",
        "  Y_flip_train.append(Y_train[i])\n",
        "for i in range(len(X_test)):\n",
        "  X_flip_test.append(X_test[i])\n",
        "  Y_flip_test.append(Y_test[i])\n",
        "  X_flip_test.append(np.asarray(PIL.ImageOps.mirror(PIL.Image.fromarray(np.uint8(X_test[i])))))\n",
        "  Y_flip_test.append(Y_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "VPCafLRWztzF",
        "outputId": "3096ff5e-ebfb-42c3-c164-4da2e86eec1d"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_flip_train[91])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JxGA7dpz1W9",
        "outputId": "192ff2c9-2621-4360-ce59-0cb6cc3f5e0b"
      },
      "outputs": [],
      "source": [
        "Y_flip_train[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecf5tajN5_i-"
      },
      "outputs": [],
      "source": [
        "# Normalize the data.\n",
        "X_train = np.array(X_train, dtype='float32')\n",
        "X_test = np.array(X_test, dtype='float32')\n",
        "X_flip_train = np.array(X_flip_train, dtype='float32')\n",
        "X_flip_test = np.array(X_flip_test, dtype='float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "X_flip_train /= 255.0\n",
        "X_flip_test /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUuqp4ke6BRQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2,shuffle = True)\n",
        "X_flip_train, X_flip_val, Y_flip_train, Y_flip_val = train_test_split(X_flip_train, Y_flip_train, test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDZcUn7m6C4p"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(Y_train)\n",
        "Y_train = encoder.transform(Y_train).toarray()\n",
        "Y_test = encoder.transform(Y_test).toarray()\n",
        "Y_flip_train = encoder.transform(Y_flip_train).toarray()\n",
        "Y_flip_test = encoder.transform(Y_flip_test).toarray()\n",
        "Y_val =  encoder.transform(Y_val).toarray()\n",
        "Y_flip_val = encoder.transform(Y_flip_val).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVsmEC0M6F_v"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ResNet-18\n",
        "Reference:\n",
        "[1] K. He et al. Deep Residual Learning for Image Recognition. CVPR, 2016\n",
        "[2] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers:\n",
        "Surpassing human-level performance on imagenet classification. In\n",
        "ICCV, 2015.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Add, Activation, Input, MaxPooling2D, ZeroPadding2D, AveragePooling2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras import layers, activations \n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "class ResnetBlock(Model):\n",
        "    \"\"\"\n",
        "    A standard resnet block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, down_sample=False):\n",
        "        \"\"\"\n",
        "        channels: same as number of convolution kernels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "\n",
        "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_1 = BatchNormalization()\n",
        "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_2 = BatchNormalization()\n",
        "        self.merge = Add()\n",
        "\n",
        "        if self.__down_sample:\n",
        "            # perform down sampling using stride of 2, according to [1].\n",
        "            self.res_conv = Conv2D(\n",
        "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            self.res_bn = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "\n",
        "        # if not perform down sample, then add a shortcut directly\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.init_bn = BatchNormalization()\n",
        "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(128)\n",
        "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(256)\n",
        "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_4_2 = ResnetBlock(512)\n",
        "        self.dropout = Dropout(0.5)\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.flat = Flatten()\n",
        "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
        "            out = res_block(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO5v5mWkO3JL",
        "outputId": "1efb8d1e-fd66-43bd-ec72-fe9ea9754c7a"
      },
      "outputs": [],
      "source": [
        "# model = ResNet18(4)\n",
        "# model.build(input_shape = (None,250,250,3))\n",
        "# #use categorical_crossentropy since the label is one-hot encoded\n",
        "# #from keras.optimizers import SGD\n",
        "# #opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "# #tf.keras.optimizers.SGD()\n",
        "# model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3momFSwUkh1",
        "outputId": "dcea9440-1fe9-4f01-85c0-856430032d44"
      },
      "outputs": [],
      "source": [
        "# gpus = tf.config.list_physical_devices('GPU')\n",
        "# if gpus:\n",
        "#   # Restrict TensorFlow to only use the first GPU\n",
        "#   try:\n",
        "#     tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "#     logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "#   except RuntimeError as e:\n",
        "#     # Visible devices must be set before GPUs have been initialized\n",
        "#     print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYEmNOjZ6JF3",
        "outputId": "02239abd-f7c5-47d0-8c6f-05a8dd51975b"
      },
      "outputs": [],
      "source": [
        "# from keras.callbacks import EarlyStopping\n",
        "\n",
        "# es = EarlyStopping(patience= 6, restore_best_weights=True, monitor=\"val_accuracy\")\n",
        "# #I did not use cross validation, so the validate performance is not accurate.\n",
        "# STEPS = len(X_train) / 16\n",
        "# history = model.fit(X_train, Y_train, batch_size = 16, steps_per_epoch=np.float32(STEPS), epochs=50, validation_data=(X_val, Y_val), callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5ZR0KWNRM9M"
      },
      "outputs": [],
      "source": [
        "# Y_pred = []\n",
        "# for i in range(len(X_test)):\n",
        "#   Y_pred.append(model.predict(X_test[i:i+1]).tolist()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0l84gz-R9NU"
      },
      "outputs": [],
      "source": [
        "# test_class = np.argmax(Y_test, axis=1)\n",
        "# Y_true = test_class.tolist()\n",
        "# pred_class = np.argmax(Y_pred, axis=1)\n",
        "# Y_pred = pred_class.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cpRxOrFR_E0"
      },
      "outputs": [],
      "source": [
        "#from sklearn.metrics import confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmyjnGSdSApt",
        "outputId": "2888bcf5-1900-4881-8079-2beb22a4ad28"
      },
      "outputs": [],
      "source": [
        "#accuracy_score(y_true=Y_true, y_pred=Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV1emyyxSDtI"
      },
      "outputs": [],
      "source": [
        "#conf_matrix = confusion_matrix(y_true=Y_true, y_pred=Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "OiMykZQpSEb8",
        "outputId": "6994ec50-a6fd-4c94-db32-b6ad0eea67dd"
      },
      "outputs": [],
      "source": [
        "# fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "# ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "# for i in range(conf_matrix.shape[0]):\n",
        "#     for j in range(conf_matrix.shape[1]):\n",
        "#         ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "# plt.xlabel('Predictions', fontsize=18)\n",
        "# plt.ylabel('Actuals', fontsize=18)\n",
        "# plt.title('Confusion Matrix', fontsize=18)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zCrXeeedZBq"
      },
      "outputs": [],
      "source": [
        "#batik = ['Liong', 'Jlamprang', 'Terang bulan', 'Tujuh Rupa']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "VCUnihqgc-PC",
        "outputId": "b36c1aa5-6c61-49d6-bfcb-8313ce1428c4"
      },
      "outputs": [],
      "source": [
        "#plt.imshow(X_test[15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHxVO1UodGeP",
        "outputId": "ffeeb027-fae2-4d77-ad6a-cfb5b2860564"
      },
      "outputs": [],
      "source": [
        "#print(\"true label: \", batik[Y_true[15]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgd62LzrdWgi",
        "outputId": "b8d60da0-c495-4ff7-f2a2-c4fa4a2bfd6f"
      },
      "outputs": [],
      "source": [
        "#print(\"predicted label: \", batik[Y_pred[15]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp29HqwtzbQx",
        "outputId": "62341f50-8098-4b2a-ce36-47e326b76ee0"
      },
      "outputs": [],
      "source": [
        "model_flip = ResNet18(4)\n",
        "model_flip.build(input_shape = (None,250,250,3))\n",
        "#use categorical_crossentropy since the label is one-hot encoded\n",
        "#from keras.optimizers import SGD\n",
        "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "model_flip.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001),loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
        "model_flip.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmRORGfh24Pk",
        "outputId": "a7c16d0a-1f16-452c-f4eb-7a4c168883ea"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PAsssTl1GpU",
        "outputId": "11c7739c-26ae-4d31-c1a0-7c82e887651b"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(patience= 6, restore_best_weights=True, monitor=\"val_accuracy\")\n",
        "history_flip = model_flip.fit(X_flip_train, Y_flip_train, batch_size = 32, epochs=50, steps_per_epoch=np.float32(len(X_flip_train)/32), validation_data=(X_flip_test, Y_flip_test), callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5Ir3nF02vaG"
      },
      "outputs": [],
      "source": [
        "Y_flip_pred = []\n",
        "for i in range(len(X_flip_test)):\n",
        "  Y_flip_pred.append(model_flip.predict(X_flip_test[i:i+1]).tolist()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0FEnBMZVuOn"
      },
      "outputs": [],
      "source": [
        "test_flip_class = np.argmax(Y_flip_test, axis=1)\n",
        "Y_flip_true = test_flip_class.tolist()\n",
        "pred_flip_class = np.argmax(Y_flip_pred, axis=1)\n",
        "Y_flip_pred = pred_flip_class.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RQuTcJhV9J5",
        "outputId": "d276896c-ed95-46ff-9153-445c561f8704"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "batik = ['Liong', 'Jlamprang', 'Terang bulan', 'Tujuh Rupa']\n",
        "accuracy_score(y_true=Y_flip_true, y_pred=Y_flip_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QYL_bBAVW9x"
      },
      "outputs": [],
      "source": [
        "conf_flip_matrix = confusion_matrix(y_true=Y_flip_true, y_pred=Y_flip_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "LoC9vMNDVb--",
        "outputId": "42128e67-cec6-4eac-fb29-80ebd0af683f"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(conf_flip_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_flip_matrix.shape[0]):\n",
        "    for j in range(conf_flip_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_flip_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "CC-rwtTXeaTI",
        "outputId": "21ac57c1-3e36-44a4-d818-02f4a41a3a94"
      },
      "outputs": [],
      "source": [
        "batik = ['Liong', 'Jlamprang', 'Terang bulan', 'Tujuh Rupa']\n",
        "plt.imshow(X_flip_test[85])\n",
        "print(\"true label: \", batik[Y_flip_true[85]])\n",
        "print(\"predicted label: \", batik[Y_flip_pred[85]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1QKrd5Z_083"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "resnet18 4 kelas.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
