{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xyalPcwY1WO",
        "outputId": "65d2e76c-6a3d-446a-e9d0-87bff649c8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import Dataset\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import os\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from keras.applications.xception import preprocess_input\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import drive\n",
        "\n",
        "# Accessing My Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Ewrz5ZgaY1WQ"
      },
      "outputs": [],
      "source": [
        "# Location Path\n",
        "train_path  = 'drive/My Drive/data pekalongan/2 kelas/train'\n",
        "valid_path  = 'drive/My Drive/data pekalongan/2 kelas/valid'\n",
        "test_path  = 'drive/My Drive/data pekalongan/2 kelas/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKHn3IwRY1WQ",
        "outputId": "96ceb006-f023-46ee-dc46-99a2e6b6b0e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3360 images belonging to 2 classes.\n",
            "Found 320 images belonging to 2 classes.\n",
            "Found 320 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rescale=1./127.5-1.,\n",
        ")\n",
        "\n",
        "# Train, Test, Validation\n",
        "train_batches = datagen.flow_from_directory(\n",
        "    train_path, target_size=(299,299), batch_size=10)\n",
        "valid_batches = datagen.flow_from_directory(\n",
        "    valid_path, target_size=(299,299), batch_size=15)\n",
        "test_batches = datagen.flow_from_directory(\n",
        "    test_path, target_size=(299,299), batch_size=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aL1hquC-Q5D",
        "outputId": "88cb8991-4a1e-4056-a6e2-52ad4a4d191f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([(0, 1680), (1, 1680)])\n",
            "3360\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "samples = Counter(train_batches.classes)\n",
        "\n",
        "print(samples.items()) # dict_items([(0, 1648), (1, 3614)])\n",
        "\n",
        "training_examples = 0;\n",
        "for item in samples.items():\n",
        "    training_examples += item[1]\n",
        "\n",
        "print(training_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "I5HE-0el3iXp"
      },
      "outputs": [],
      "source": [
        "def entry_flow(inputs):\n",
        "\n",
        "  x = layers.Conv2D(32, 3, strides=2, padding='same')(inputs)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  previous_block_activation = x  # Set aside residual\n",
        "  \n",
        "  # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "  for size in [128, 256, 728]:\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "    \n",
        "    residual = layers.Conv2D(  # Project residual\n",
        "        size, 1, strides=2, padding='same')(previous_block_activation)           \n",
        "    x = layers.add([x, residual])  # Add back residual\n",
        "    previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "def middle_flow(x, num_blocks=8):\n",
        "  \n",
        "  previous_block_activation = x\n",
        "\n",
        "  for _ in range(num_blocks):\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.add([x, previous_block_activation])  # Add back residual\n",
        "    previous_block_activation = x  # Set aside next residual\n",
        "    \n",
        "  return x\n",
        "\n",
        "\n",
        "def exit_flow(x, num_classes=1000):\n",
        "  \n",
        "  previous_block_activation = x\n",
        "\n",
        "  x = layers.Activation('relu')(x)\n",
        "  x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "\n",
        "  x = layers.Activation('relu')(x)\n",
        "  x = layers.SeparableConv2D(1024, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  \n",
        "  x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "  residual = layers.Conv2D(  # Project residual\n",
        "      1024, 1, strides=2, padding='same')(previous_block_activation)\n",
        "  x = layers.add([x, residual])  # Add back residual\n",
        "  \n",
        "  x = layers.SeparableConv2D(1536, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "  \n",
        "  x = layers.SeparableConv2D(2048, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "  \n",
        "  x = layers.GlobalAveragePooling2D()(x)\n",
        "  x = layers.Dropout(0.4)(x)\n",
        "  if num_classes == 1:\n",
        "    activation = 'sigmoid'\n",
        "  else:\n",
        "    activation = 'softmax'\n",
        "  return layers.Dense(num_classes, activation=activation)(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "d4_96LWHY1WU"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "# Create Xception by chaining the 3 flows\n",
        "inputs = keras.Input(shape=(299, 299, 3))\n",
        "outputs = exit_flow(middle_flow(entry_flow(inputs), num_blocks=8), num_classes=2)\n",
        "xception = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "E9_jGuo9sPYi"
      },
      "outputs": [],
      "source": [
        "# Custom Early Stopping\n",
        "# Expected behavior: EarlyStopping should restore weights on end of training regardless it stop training early or after the last epoch\n",
        "\n",
        "class CustomEarlyStopping(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, patience=0):\n",
        "        super(CustomEarlyStopping, self).__init__()\n",
        "        self.patience = patience\n",
        "        self.best_weights = None\n",
        "        \n",
        "    def on_train_begin(self, logs=None):\n",
        "        # The number of epoch it has waited when loss is no longer minimum.\n",
        "        self.wait = 0\n",
        "        # The epoch the training stops at.\n",
        "        self.stopped_epoch = 0\n",
        "        # Initialize the best as infinity.\n",
        "        self.best_val_loss = np.Inf\n",
        "        self.best_loss = np.Inf\n",
        "        self.best_val_accuracy = 0.0\n",
        "        self.best_accuracy = 0.0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        val_loss = logs.get('val_loss')\n",
        "        loss = logs.get('loss')\n",
        "        val_accuracy = logs.get('val_accuracy')\n",
        "        accuracy = logs.get('accuracy')\n",
        "\n",
        "        # if np.less(val_loss, self.best_val_loss) and np.greater(map10, self.best_map10):\n",
        "        if np.greater_equal(val_accuracy, self.best_val_accuracy) and np.greater_equal(accuracy, self.best_accuracy) and np.greater_equal(accuracy, val_accuracy):\n",
        "            self.best_val_loss = val_loss\n",
        "            self.best_loss = loss\n",
        "            self.best_val_accuracy = val_accuracy\n",
        "            self.best_accuracy = accuracy\n",
        "            self.wait = 0\n",
        "\n",
        "            # Record the best weights if current results is better.\n",
        "            print(\"Saving the best weight at epoch {}\".format(epoch + 1))\n",
        "            self.best_weights = self.model.get_weights()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                print(\"Training stop early. Restoring model weights from the end of the best epoch.\")\n",
        "                self.model.set_weights(self.best_weights)\n",
        "                \n",
        "    def on_train_end(self, logs=None):\n",
        "        # EarlyStopping will restore weights after the last epoch only if it is not stop early\n",
        "        if self.stopped_epoch > 0:\n",
        "            print(\"Epoch {}: early stopping\".format(self.stopped_epoch + 1))\n",
        "        else:\n",
        "            print(\"Training stop after the last epoch. Restoring model weights from the end of the best epoch.\")\n",
        "            self.model.set_weights(self.best_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "dg2toYR8Y1WV"
      },
      "outputs": [],
      "source": [
        "xception.compile(RMSprop(learning_rate=3e-4), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp-gJ4L7Y1WW",
        "outputId": "d0fbd699-5096-4977-800f-a43a1dc9f50d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "4/4 - 12s - loss: 0.8262 - accuracy: 0.6500 - val_loss: 0.6946 - val_accuracy: 0.4000 - 12s/epoch - 3s/step\n",
            "Epoch 2/1000\n",
            "4/4 - 2s - loss: 0.9742 - accuracy: 0.5000 - val_loss: 0.6908 - val_accuracy: 0.6667 - 2s/epoch - 573ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 2s - loss: 0.7539 - accuracy: 0.5500 - val_loss: 0.6915 - val_accuracy: 0.6333 - 2s/epoch - 526ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 2s - loss: 0.5032 - accuracy: 0.8000 - val_loss: 0.6931 - val_accuracy: 0.5000 - 2s/epoch - 531ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 2s - loss: 0.6188 - accuracy: 0.7000 - val_loss: 0.6932 - val_accuracy: 0.3333 - 2s/epoch - 538ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 2s - loss: 0.6348 - accuracy: 0.7500 - val_loss: 0.6931 - val_accuracy: 0.5333 - 2s/epoch - 556ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 2s - loss: 0.6727 - accuracy: 0.6500 - val_loss: 0.6931 - val_accuracy: 0.5000 - 2s/epoch - 542ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 2s - loss: 0.6923 - accuracy: 0.6250 - val_loss: 0.6929 - val_accuracy: 0.5667 - 2s/epoch - 546ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 2s - loss: 0.5792 - accuracy: 0.7250 - val_loss: 0.6931 - val_accuracy: 0.5000 - 2s/epoch - 537ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 2s - loss: 0.6933 - accuracy: 0.7250 - val_loss: 0.6931 - val_accuracy: 0.6000 - 2s/epoch - 604ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 2s - loss: 0.7841 - accuracy: 0.5500 - val_loss: 0.6931 - val_accuracy: 0.5000 - 2s/epoch - 539ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 2s - loss: 0.6032 - accuracy: 0.7250 - val_loss: 0.6931 - val_accuracy: 0.5333 - 2s/epoch - 598ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 2s - loss: 0.7896 - accuracy: 0.6000 - val_loss: 0.6929 - val_accuracy: 0.5667 - 2s/epoch - 597ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 2s - loss: 0.7532 - accuracy: 0.5500 - val_loss: 0.6929 - val_accuracy: 0.5333 - 2s/epoch - 595ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 2s - loss: 0.6522 - accuracy: 0.6500 - val_loss: 0.6929 - val_accuracy: 0.5333 - 2s/epoch - 592ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 2s - loss: 0.6939 - accuracy: 0.5250 - val_loss: 0.6937 - val_accuracy: 0.2667 - 2s/epoch - 519ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 2s - loss: 0.6294 - accuracy: 0.6250 - val_loss: 0.6935 - val_accuracy: 0.4000 - 2s/epoch - 588ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 2s - loss: 0.6411 - accuracy: 0.5500 - val_loss: 0.6927 - val_accuracy: 0.6000 - 2s/epoch - 520ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 2s - loss: 0.6887 - accuracy: 0.6000 - val_loss: 0.6928 - val_accuracy: 0.6000 - 2s/epoch - 513ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 2s - loss: 0.6683 - accuracy: 0.7000 - val_loss: 0.6937 - val_accuracy: 0.3667 - 2s/epoch - 515ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 2s - loss: 0.6994 - accuracy: 0.6250 - val_loss: 0.6931 - val_accuracy: 0.5333 - 2s/epoch - 584ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 2s - loss: 0.6369 - accuracy: 0.5750 - val_loss: 0.6935 - val_accuracy: 0.4000 - 2s/epoch - 582ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 2s - loss: 0.7869 - accuracy: 0.6000 - val_loss: 0.6928 - val_accuracy: 0.5333 - 2s/epoch - 515ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 2s - loss: 0.7074 - accuracy: 0.6000 - val_loss: 0.6928 - val_accuracy: 0.5333 - 2s/epoch - 583ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 2s - loss: 0.6313 - accuracy: 0.6250 - val_loss: 0.6932 - val_accuracy: 0.4667 - 2s/epoch - 507ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 2s - loss: 0.5551 - accuracy: 0.7250 - val_loss: 0.6935 - val_accuracy: 0.4000 - 2s/epoch - 511ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 2s - loss: 0.8179 - accuracy: 0.5750 - val_loss: 0.6929 - val_accuracy: 0.5667 - 2s/epoch - 512ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 2s - loss: 0.5442 - accuracy: 0.8000 - val_loss: 0.6933 - val_accuracy: 0.4000 - 2s/epoch - 516ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 2s - loss: 0.5784 - accuracy: 0.8250 - val_loss: 0.6936 - val_accuracy: 0.4333 - 2s/epoch - 577ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 2s - loss: 0.5761 - accuracy: 0.7000 - val_loss: 0.6910 - val_accuracy: 0.6000 - 2s/epoch - 518ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 2s - loss: 0.3760 - accuracy: 0.8750 - val_loss: 0.6947 - val_accuracy: 0.3667 - 2s/epoch - 515ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 2s - loss: 0.6898 - accuracy: 0.7500 - val_loss: 0.6940 - val_accuracy: 0.4667 - 2s/epoch - 578ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 2s - loss: 0.6926 - accuracy: 0.6750 - val_loss: 0.6909 - val_accuracy: 0.5667 - 2s/epoch - 586ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 2s - loss: 0.6377 - accuracy: 0.7750 - val_loss: 0.6920 - val_accuracy: 0.5333 - 2s/epoch - 578ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 2s - loss: 0.5388 - accuracy: 0.7000 - val_loss: 0.6928 - val_accuracy: 0.5000 - 2s/epoch - 515ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 2s - loss: 0.6088 - accuracy: 0.6250 - val_loss: 0.6961 - val_accuracy: 0.4333 - 2s/epoch - 515ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 2s - loss: 0.7540 - accuracy: 0.5000 - val_loss: 0.6918 - val_accuracy: 0.5333 - 2s/epoch - 517ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 2s - loss: 0.4550 - accuracy: 0.8000 - val_loss: 0.6947 - val_accuracy: 0.4667 - 2s/epoch - 582ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 2s - loss: 0.4275 - accuracy: 0.8500 - val_loss: 0.6980 - val_accuracy: 0.4333 - 2s/epoch - 580ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 2s - loss: 0.5519 - accuracy: 0.7000 - val_loss: 0.7063 - val_accuracy: 0.3000 - 2s/epoch - 522ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 2s - loss: 0.4008 - accuracy: 0.8500 - val_loss: 0.6963 - val_accuracy: 0.4667 - 2s/epoch - 584ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 2s - loss: 0.8049 - accuracy: 0.6000 - val_loss: 0.6887 - val_accuracy: 0.5667 - 2s/epoch - 549ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 2s - loss: 0.5571 - accuracy: 0.7000 - val_loss: 0.6850 - val_accuracy: 0.6000 - 2s/epoch - 542ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 2s - loss: 0.6934 - accuracy: 0.6500 - val_loss: 0.6936 - val_accuracy: 0.5000 - 2s/epoch - 595ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 2s - loss: 0.6794 - accuracy: 0.6750 - val_loss: 0.6962 - val_accuracy: 0.4667 - 2s/epoch - 521ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 2s - loss: 0.4563 - accuracy: 0.8250 - val_loss: 0.7041 - val_accuracy: 0.3667 - 2s/epoch - 530ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 2s - loss: 0.6320 - accuracy: 0.7500 - val_loss: 0.7007 - val_accuracy: 0.4333 - 2s/epoch - 589ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 2s - loss: 0.4868 - accuracy: 0.8250 - val_loss: 0.6897 - val_accuracy: 0.5333 - 2s/epoch - 611ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 2s - loss: 0.6723 - accuracy: 0.7500 - val_loss: 0.6902 - val_accuracy: 0.5333 - 2s/epoch - 587ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 2s - loss: 0.7543 - accuracy: 0.7250 - val_loss: 0.6985 - val_accuracy: 0.4333 - 2s/epoch - 535ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 2s - loss: 0.3536 - accuracy: 0.8750 - val_loss: 0.6835 - val_accuracy: 0.5667 - 2s/epoch - 556ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 2s - loss: 0.5134 - accuracy: 0.7500 - val_loss: 0.6765 - val_accuracy: 0.6333 - 2s/epoch - 544ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 2s - loss: 0.6233 - accuracy: 0.7500 - val_loss: 0.6706 - val_accuracy: 0.6667 - 2s/epoch - 546ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 2s - loss: 0.6973 - accuracy: 0.6750 - val_loss: 0.6978 - val_accuracy: 0.4667 - 2s/epoch - 589ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 2s - loss: 0.5492 - accuracy: 0.7000 - val_loss: 0.6892 - val_accuracy: 0.5333 - 2s/epoch - 520ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 2s - loss: 0.5161 - accuracy: 0.7250 - val_loss: 0.6890 - val_accuracy: 0.5333 - 2s/epoch - 584ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 2s - loss: 0.5923 - accuracy: 0.7750 - val_loss: 0.7079 - val_accuracy: 0.4000 - 2s/epoch - 588ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 2s - loss: 0.6724 - accuracy: 0.6000 - val_loss: 0.6854 - val_accuracy: 0.5667 - 2s/epoch - 520ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 2s - loss: 0.5390 - accuracy: 0.7750 - val_loss: 0.7104 - val_accuracy: 0.4000 - 2s/epoch - 580ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 2s - loss: 0.5361 - accuracy: 0.7750 - val_loss: 0.7255 - val_accuracy: 0.3000 - 2s/epoch - 588ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 2s - loss: 0.5037 - accuracy: 0.8000 - val_loss: 0.6830 - val_accuracy: 0.5667 - 2s/epoch - 520ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 2s - loss: 0.4604 - accuracy: 0.8000 - val_loss: 0.7189 - val_accuracy: 0.3667 - 2s/epoch - 523ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 2s - loss: 0.4675 - accuracy: 0.7750 - val_loss: 0.7163 - val_accuracy: 0.3667 - 2s/epoch - 525ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 2s - loss: 0.4592 - accuracy: 0.8250 - val_loss: 0.6712 - val_accuracy: 0.6333 - 2s/epoch - 584ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 2s - loss: 0.5797 - accuracy: 0.7250 - val_loss: 0.6906 - val_accuracy: 0.4667 - 2s/epoch - 517ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 2s - loss: 0.3754 - accuracy: 0.8250 - val_loss: 0.6723 - val_accuracy: 0.6000 - 2s/epoch - 507ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 2s - loss: 0.4635 - accuracy: 0.7500 - val_loss: 0.6813 - val_accuracy: 0.5667 - 2s/epoch - 517ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 2s - loss: 0.5549 - accuracy: 0.7750 - val_loss: 0.7280 - val_accuracy: 0.3333 - 2s/epoch - 533ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 2s - loss: 0.3659 - accuracy: 0.8250 - val_loss: 0.6837 - val_accuracy: 0.5333 - 2s/epoch - 521ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 2s - loss: 0.4816 - accuracy: 0.8500 - val_loss: 0.6912 - val_accuracy: 0.5000 - 2s/epoch - 582ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 2s - loss: 0.4799 - accuracy: 0.8500 - val_loss: 0.6978 - val_accuracy: 0.4667 - 2s/epoch - 581ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 2s - loss: 0.5693 - accuracy: 0.7000 - val_loss: 0.6912 - val_accuracy: 0.5000 - 2s/epoch - 515ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 2s - loss: 0.4764 - accuracy: 0.7750 - val_loss: 0.6886 - val_accuracy: 0.5333 - 2s/epoch - 512ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 2s - loss: 0.7510 - accuracy: 0.5750 - val_loss: 0.7314 - val_accuracy: 0.3333 - 2s/epoch - 528ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 2s - loss: 0.5686 - accuracy: 0.6750 - val_loss: 0.7020 - val_accuracy: 0.4667 - 2s/epoch - 524ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 2s - loss: 0.4958 - accuracy: 0.7750 - val_loss: 0.7074 - val_accuracy: 0.4667 - 2s/epoch - 581ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 2s - loss: 0.6336 - accuracy: 0.6750 - val_loss: 0.6970 - val_accuracy: 0.4667 - 2s/epoch - 588ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 2s - loss: 0.7103 - accuracy: 0.6500 - val_loss: 0.7200 - val_accuracy: 0.4000 - 2s/epoch - 517ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 2s - loss: 0.4463 - accuracy: 0.7750 - val_loss: 0.6966 - val_accuracy: 0.4667 - 2s/epoch - 511ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 2s - loss: 0.7683 - accuracy: 0.5750 - val_loss: 0.6914 - val_accuracy: 0.5000 - 2s/epoch - 580ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 2s - loss: 0.4424 - accuracy: 0.8500 - val_loss: 0.6805 - val_accuracy: 0.5333 - 2s/epoch - 591ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 2s - loss: 0.7675 - accuracy: 0.6250 - val_loss: 0.6818 - val_accuracy: 0.5333 - 2s/epoch - 583ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 2s - loss: 0.5448 - accuracy: 0.7750 - val_loss: 0.6698 - val_accuracy: 0.6000 - 2s/epoch - 618ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 2s - loss: 0.5001 - accuracy: 0.8250 - val_loss: 0.7331 - val_accuracy: 0.3333 - 2s/epoch - 591ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 2s - loss: 0.5621 - accuracy: 0.7000 - val_loss: 0.7367 - val_accuracy: 0.3667 - 2s/epoch - 519ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 2s - loss: 0.5472 - accuracy: 0.7250 - val_loss: 0.6927 - val_accuracy: 0.5000 - 2s/epoch - 588ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 2s - loss: 0.6963 - accuracy: 0.5750 - val_loss: 0.7023 - val_accuracy: 0.5000 - 2s/epoch - 517ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 2s - loss: 0.4756 - accuracy: 0.7750 - val_loss: 0.6818 - val_accuracy: 0.5333 - 2s/epoch - 587ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 2s - loss: 0.6990 - accuracy: 0.5750 - val_loss: 0.6652 - val_accuracy: 0.6000 - 2s/epoch - 547ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 2s - loss: 0.4813 - accuracy: 0.7500 - val_loss: 0.6844 - val_accuracy: 0.5333 - 2s/epoch - 524ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 2s - loss: 0.5023 - accuracy: 0.7250 - val_loss: 0.6644 - val_accuracy: 0.6000 - 2s/epoch - 612ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 2s - loss: 0.7332 - accuracy: 0.6250 - val_loss: 0.7089 - val_accuracy: 0.4333 - 2s/epoch - 515ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 2s - loss: 0.4615 - accuracy: 0.8500 - val_loss: 0.6765 - val_accuracy: 0.5333 - 2s/epoch - 585ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 2s - loss: 0.7223 - accuracy: 0.6250 - val_loss: 0.7048 - val_accuracy: 0.4667 - 2s/epoch - 584ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 2s - loss: 0.4016 - accuracy: 0.8250 - val_loss: 0.7284 - val_accuracy: 0.3667 - 2s/epoch - 521ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 2s - loss: 0.6533 - accuracy: 0.7000 - val_loss: 0.6698 - val_accuracy: 0.5667 - 2s/epoch - 521ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 2s - loss: 0.6225 - accuracy: 0.6750 - val_loss: 0.6794 - val_accuracy: 0.5000 - 2s/epoch - 528ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 2s - loss: 0.5108 - accuracy: 0.7500 - val_loss: 0.6897 - val_accuracy: 0.5000 - 2s/epoch - 521ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 2s - loss: 0.5402 - accuracy: 0.6750 - val_loss: 0.6704 - val_accuracy: 0.5000 - 2s/epoch - 585ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 2s - loss: 0.5376 - accuracy: 0.7250 - val_loss: 0.7266 - val_accuracy: 0.4000 - 2s/epoch - 523ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 2s - loss: 0.5497 - accuracy: 0.7000 - val_loss: 0.6952 - val_accuracy: 0.5000 - 2s/epoch - 588ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 2s - loss: 0.5372 - accuracy: 0.7500 - val_loss: 0.6777 - val_accuracy: 0.5333 - 2s/epoch - 583ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 2s - loss: 0.3770 - accuracy: 0.8250 - val_loss: 0.6090 - val_accuracy: 0.8333 - 2s/epoch - 547ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 2s - loss: 0.7236 - accuracy: 0.6750 - val_loss: 0.6219 - val_accuracy: 0.6333 - 2s/epoch - 582ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 2s - loss: 0.4935 - accuracy: 0.7500 - val_loss: 0.6837 - val_accuracy: 0.5333 - 2s/epoch - 526ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 2s - loss: 0.4586 - accuracy: 0.7750 - val_loss: 0.7004 - val_accuracy: 0.5333 - 2s/epoch - 532ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 2s - loss: 0.4282 - accuracy: 0.8500 - val_loss: 0.6205 - val_accuracy: 0.7667 - 2s/epoch - 584ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 2s - loss: 0.4884 - accuracy: 0.7750 - val_loss: 0.5942 - val_accuracy: 0.7000 - 2s/epoch - 613ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 2s - loss: 0.6074 - accuracy: 0.6750 - val_loss: 0.6432 - val_accuracy: 0.6000 - 2s/epoch - 529ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 2s - loss: 0.4096 - accuracy: 0.8250 - val_loss: 0.6596 - val_accuracy: 0.6000 - 2s/epoch - 522ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 2s - loss: 0.5073 - accuracy: 0.7500 - val_loss: 0.6408 - val_accuracy: 0.6000 - 2s/epoch - 514ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 2s - loss: 0.4611 - accuracy: 0.8000 - val_loss: 0.6347 - val_accuracy: 0.7667 - 2s/epoch - 583ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 2s - loss: 0.5748 - accuracy: 0.6750 - val_loss: 0.5878 - val_accuracy: 0.7667 - 2s/epoch - 560ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 2s - loss: 0.4118 - accuracy: 0.8000 - val_loss: 0.5844 - val_accuracy: 0.7667 - 2s/epoch - 549ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 2s - loss: 0.3477 - accuracy: 0.8000 - val_loss: 0.5917 - val_accuracy: 0.7333 - 2s/epoch - 527ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 2s - loss: 0.8225 - accuracy: 0.7250 - val_loss: 0.6981 - val_accuracy: 0.5333 - 2s/epoch - 516ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 2s - loss: 0.4614 - accuracy: 0.8000 - val_loss: 0.6368 - val_accuracy: 0.6667 - 2s/epoch - 513ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 2s - loss: 0.7051 - accuracy: 0.7250 - val_loss: 0.6753 - val_accuracy: 0.5333 - 2s/epoch - 523ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 2s - loss: 0.5643 - accuracy: 0.8000 - val_loss: 0.7022 - val_accuracy: 0.5333 - 2s/epoch - 582ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 2s - loss: 0.4595 - accuracy: 0.7500 - val_loss: 0.6085 - val_accuracy: 0.7333 - 2s/epoch - 588ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 2s - loss: 0.6591 - accuracy: 0.6250 - val_loss: 0.6973 - val_accuracy: 0.5333 - 2s/epoch - 583ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 2s - loss: 0.5748 - accuracy: 0.7000 - val_loss: 0.7718 - val_accuracy: 0.4000 - 2s/epoch - 585ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 2s - loss: 0.5383 - accuracy: 0.7750 - val_loss: 0.6970 - val_accuracy: 0.6000 - 2s/epoch - 527ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 2s - loss: 0.4645 - accuracy: 0.7750 - val_loss: 0.6050 - val_accuracy: 0.6000 - 2s/epoch - 531ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 2s - loss: 0.6228 - accuracy: 0.6750 - val_loss: 0.6077 - val_accuracy: 0.7000 - 2s/epoch - 519ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 2s - loss: 0.5828 - accuracy: 0.7500 - val_loss: 0.6673 - val_accuracy: 0.6333 - 2s/epoch - 584ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 2s - loss: 0.4649 - accuracy: 0.8000 - val_loss: 0.5783 - val_accuracy: 0.7333 - 2s/epoch - 543ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 2s - loss: 0.4577 - accuracy: 0.8250 - val_loss: 0.5788 - val_accuracy: 0.7333 - 2s/epoch - 514ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 2s - loss: 0.5955 - accuracy: 0.7500 - val_loss: 0.5914 - val_accuracy: 0.7000 - 2s/epoch - 589ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 2s - loss: 0.3610 - accuracy: 0.9000 - val_loss: 0.6505 - val_accuracy: 0.6000 - 2s/epoch - 520ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 2s - loss: 0.5445 - accuracy: 0.7750 - val_loss: 0.6571 - val_accuracy: 0.6000 - 2s/epoch - 583ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 2s - loss: 0.6374 - accuracy: 0.6250 - val_loss: 0.5834 - val_accuracy: 0.8333 - 2s/epoch - 521ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 2s - loss: 0.4326 - accuracy: 0.8500 - val_loss: 0.6937 - val_accuracy: 0.5667 - 2s/epoch - 518ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 2s - loss: 0.5015 - accuracy: 0.8000 - val_loss: 0.5483 - val_accuracy: 0.8000 - 2s/epoch - 553ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 2s - loss: 0.4631 - accuracy: 0.7750 - val_loss: 0.5357 - val_accuracy: 0.7667 - 2s/epoch - 547ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 2s - loss: 0.4379 - accuracy: 0.8000 - val_loss: 0.6440 - val_accuracy: 0.6333 - 2s/epoch - 516ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 2s - loss: 0.3441 - accuracy: 0.9000 - val_loss: 0.5469 - val_accuracy: 0.7333 - 2s/epoch - 531ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 2s - loss: 0.4754 - accuracy: 0.7750 - val_loss: 0.6346 - val_accuracy: 0.6333 - 2s/epoch - 583ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 2s - loss: 0.6920 - accuracy: 0.6250 - val_loss: 0.6124 - val_accuracy: 0.6667 - 2s/epoch - 517ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 2s - loss: 0.4343 - accuracy: 0.8000 - val_loss: 0.6236 - val_accuracy: 0.6000 - 2s/epoch - 587ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 2s - loss: 0.3709 - accuracy: 0.8500 - val_loss: 0.5017 - val_accuracy: 0.7667 - 2s/epoch - 613ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 2s - loss: 0.5786 - accuracy: 0.7000 - val_loss: 0.6513 - val_accuracy: 0.5333 - 2s/epoch - 524ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 2s - loss: 0.3696 - accuracy: 0.8250 - val_loss: 0.5086 - val_accuracy: 0.8000 - 2s/epoch - 514ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 2s - loss: 0.3525 - accuracy: 0.7500 - val_loss: 0.6673 - val_accuracy: 0.6333 - 2s/epoch - 595ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 2s - loss: 0.6690 - accuracy: 0.6750 - val_loss: 0.6397 - val_accuracy: 0.6000 - 2s/epoch - 536ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 2s - loss: 0.3719 - accuracy: 0.8000 - val_loss: 0.6191 - val_accuracy: 0.7000 - 2s/epoch - 523ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 2s - loss: 0.3654 - accuracy: 0.8250 - val_loss: 0.5099 - val_accuracy: 0.7667 - 2s/epoch - 536ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 2s - loss: 0.3796 - accuracy: 0.7750 - val_loss: 0.7193 - val_accuracy: 0.5333 - 2s/epoch - 583ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 2s - loss: 0.3158 - accuracy: 0.8750 - val_loss: 0.4632 - val_accuracy: 0.8000 - 2s/epoch - 550ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 2s - loss: 0.6628 - accuracy: 0.7250 - val_loss: 0.6527 - val_accuracy: 0.7000 - 2s/epoch - 587ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 2s - loss: 0.6264 - accuracy: 0.7250 - val_loss: 0.6785 - val_accuracy: 0.5667 - 2s/epoch - 587ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 2s - loss: 0.4430 - accuracy: 0.8250 - val_loss: 0.6060 - val_accuracy: 0.6333 - 2s/epoch - 586ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 2s - loss: 0.4128 - accuracy: 0.8000 - val_loss: 0.5649 - val_accuracy: 0.6333 - 2s/epoch - 524ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 2s - loss: 0.5390 - accuracy: 0.7250 - val_loss: 0.4586 - val_accuracy: 0.7667 - 2s/epoch - 542ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 2s - loss: 0.5173 - accuracy: 0.7250 - val_loss: 0.5940 - val_accuracy: 0.6333 - 2s/epoch - 590ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 2s - loss: 0.4451 - accuracy: 0.8000 - val_loss: 0.6119 - val_accuracy: 0.6667 - 2s/epoch - 518ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 2s - loss: 0.4828 - accuracy: 0.8750 - val_loss: 0.5030 - val_accuracy: 0.8000 - 2s/epoch - 580ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 2s - loss: 0.5938 - accuracy: 0.6500 - val_loss: 0.5419 - val_accuracy: 0.7333 - 2s/epoch - 521ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 2s - loss: 0.4943 - accuracy: 0.8000 - val_loss: 0.5104 - val_accuracy: 0.8333 - 2s/epoch - 523ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 2s - loss: 0.3436 - accuracy: 0.8500 - val_loss: 0.4779 - val_accuracy: 0.8000 - 2s/epoch - 524ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 2s - loss: 0.4461 - accuracy: 0.7250 - val_loss: 0.5713 - val_accuracy: 0.7667 - 2s/epoch - 586ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 2s - loss: 0.2908 - accuracy: 0.9000 - val_loss: 0.5260 - val_accuracy: 0.6000 - 2s/epoch - 529ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 2s - loss: 0.4228 - accuracy: 0.8000 - val_loss: 0.3571 - val_accuracy: 0.9000 - 2s/epoch - 554ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 2s - loss: 0.5186 - accuracy: 0.8000 - val_loss: 0.4376 - val_accuracy: 0.8000 - 2s/epoch - 588ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 2s - loss: 0.5457 - accuracy: 0.7250 - val_loss: 0.5621 - val_accuracy: 0.7667 - 2s/epoch - 522ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 2s - loss: 0.4953 - accuracy: 0.7500 - val_loss: 0.3101 - val_accuracy: 0.9000 - 2s/epoch - 547ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 2s - loss: 0.4419 - accuracy: 0.8500 - val_loss: 0.6395 - val_accuracy: 0.6667 - 2s/epoch - 584ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 2s - loss: 0.5321 - accuracy: 0.7250 - val_loss: 0.5522 - val_accuracy: 0.7000 - 2s/epoch - 525ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 2s - loss: 0.4542 - accuracy: 0.8250 - val_loss: 0.4977 - val_accuracy: 0.7667 - 2s/epoch - 520ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 2s - loss: 0.5547 - accuracy: 0.7250 - val_loss: 0.5995 - val_accuracy: 0.7333 - 2s/epoch - 585ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 2s - loss: 0.3974 - accuracy: 0.9000 - val_loss: 0.4978 - val_accuracy: 0.7333 - 2s/epoch - 535ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 2s - loss: 0.3850 - accuracy: 0.8500 - val_loss: 0.4974 - val_accuracy: 0.7667 - 2s/epoch - 585ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 2s - loss: 0.5645 - accuracy: 0.8250 - val_loss: 0.5051 - val_accuracy: 0.8000 - 2s/epoch - 522ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 2s - loss: 0.4964 - accuracy: 0.7750 - val_loss: 0.6128 - val_accuracy: 0.7333 - 2s/epoch - 525ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 2s - loss: 0.5482 - accuracy: 0.6750 - val_loss: 0.5091 - val_accuracy: 0.7667 - 2s/epoch - 608ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 2s - loss: 0.3158 - accuracy: 0.9250 - val_loss: 0.5874 - val_accuracy: 0.6333 - 2s/epoch - 522ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 2s - loss: 0.3756 - accuracy: 0.8250 - val_loss: 0.7285 - val_accuracy: 0.6000 - 2s/epoch - 527ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 2s - loss: 0.4619 - accuracy: 0.8000 - val_loss: 0.4782 - val_accuracy: 0.7000 - 2s/epoch - 522ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 2s - loss: 0.2589 - accuracy: 0.9000 - val_loss: 0.9221 - val_accuracy: 0.7000 - 2s/epoch - 518ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 2s - loss: 0.4397 - accuracy: 0.8750 - val_loss: 1.2980 - val_accuracy: 0.5333 - 2s/epoch - 518ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 2s - loss: 0.4100 - accuracy: 0.8500 - val_loss: 1.0940 - val_accuracy: 0.6667 - 2s/epoch - 593ms/step\n",
            "Epoch 182/1000\n",
            "4/4 - 2s - loss: 0.5482 - accuracy: 0.7000 - val_loss: 0.7786 - val_accuracy: 0.6333 - 2s/epoch - 587ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 2s - loss: 0.3521 - accuracy: 0.8250 - val_loss: 0.9657 - val_accuracy: 0.6000 - 2s/epoch - 586ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 2s - loss: 0.1975 - accuracy: 0.9250 - val_loss: 0.7642 - val_accuracy: 0.7667 - 2s/epoch - 584ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 2s - loss: 0.4709 - accuracy: 0.8750 - val_loss: 0.6088 - val_accuracy: 0.7333 - 2s/epoch - 590ms/step\n",
            "Epoch 186/1000\n",
            "4/4 - 2s - loss: 0.1508 - accuracy: 0.9750 - val_loss: 0.3476 - val_accuracy: 0.8333 - 2s/epoch - 599ms/step\n",
            "Epoch 187/1000\n",
            "4/4 - 2s - loss: 0.7404 - accuracy: 0.6750 - val_loss: 0.6168 - val_accuracy: 0.7667 - 2s/epoch - 588ms/step\n",
            "Epoch 188/1000\n",
            "4/4 - 2s - loss: 0.5353 - accuracy: 0.7500 - val_loss: 0.5216 - val_accuracy: 0.7667 - 2s/epoch - 584ms/step\n",
            "Epoch 189/1000\n",
            "4/4 - 2s - loss: 0.3295 - accuracy: 0.8750 - val_loss: 0.5657 - val_accuracy: 0.8333 - 2s/epoch - 520ms/step\n",
            "Epoch 190/1000\n",
            "4/4 - 2s - loss: 0.4095 - accuracy: 0.8250 - val_loss: 0.5191 - val_accuracy: 0.7667 - 2s/epoch - 585ms/step\n",
            "Epoch 191/1000\n",
            "4/4 - 2s - loss: 0.3630 - accuracy: 0.8000 - val_loss: 0.7884 - val_accuracy: 0.6333 - 2s/epoch - 586ms/step\n",
            "Epoch 192/1000\n",
            "4/4 - 2s - loss: 0.4077 - accuracy: 0.8000 - val_loss: 0.8049 - val_accuracy: 0.6667 - 2s/epoch - 517ms/step\n",
            "Epoch 193/1000\n",
            "4/4 - 2s - loss: 0.4856 - accuracy: 0.7750 - val_loss: 0.4530 - val_accuracy: 0.8333 - 2s/epoch - 529ms/step\n",
            "Epoch 194/1000\n",
            "4/4 - 2s - loss: 0.4556 - accuracy: 0.8000 - val_loss: 0.4557 - val_accuracy: 0.7667 - 2s/epoch - 519ms/step\n",
            "Epoch 195/1000\n",
            "4/4 - 2s - loss: 0.3203 - accuracy: 0.8500 - val_loss: 0.5016 - val_accuracy: 0.8667 - 2s/epoch - 526ms/step\n",
            "Epoch 196/1000\n",
            "4/4 - 2s - loss: 0.4738 - accuracy: 0.8250 - val_loss: 0.5588 - val_accuracy: 0.8333 - 2s/epoch - 517ms/step\n",
            "Epoch 197/1000\n",
            "4/4 - 2s - loss: 0.5207 - accuracy: 0.7500 - val_loss: 0.5187 - val_accuracy: 0.7333 - 2s/epoch - 530ms/step\n",
            "Epoch 198/1000\n",
            "4/4 - 2s - loss: 0.4225 - accuracy: 0.7750 - val_loss: 0.5808 - val_accuracy: 0.7000 - 2s/epoch - 529ms/step\n",
            "Epoch 199/1000\n",
            "4/4 - 2s - loss: 0.5057 - accuracy: 0.7500 - val_loss: 0.4546 - val_accuracy: 0.8333 - 2s/epoch - 525ms/step\n",
            "Epoch 200/1000\n",
            "4/4 - 2s - loss: 0.4728 - accuracy: 0.8000 - val_loss: 0.4977 - val_accuracy: 0.7667 - 2s/epoch - 528ms/step\n",
            "Epoch 201/1000\n",
            "4/4 - 2s - loss: 0.3324 - accuracy: 0.9000 - val_loss: 0.6163 - val_accuracy: 0.7000 - 2s/epoch - 582ms/step\n",
            "Epoch 202/1000\n",
            "4/4 - 2s - loss: 0.5435 - accuracy: 0.7750 - val_loss: 0.6833 - val_accuracy: 0.7667 - 2s/epoch - 584ms/step\n",
            "Epoch 203/1000\n",
            "4/4 - 2s - loss: 0.4378 - accuracy: 0.8500 - val_loss: 0.8139 - val_accuracy: 0.6667 - 2s/epoch - 587ms/step\n",
            "Epoch 204/1000\n",
            "4/4 - 2s - loss: 0.2537 - accuracy: 0.9500 - val_loss: 0.9709 - val_accuracy: 0.5000 - 2s/epoch - 590ms/step\n",
            "Epoch 205/1000\n",
            "4/4 - 2s - loss: 0.3150 - accuracy: 0.8500 - val_loss: 0.5460 - val_accuracy: 0.7667 - 2s/epoch - 588ms/step\n",
            "Epoch 206/1000\n",
            "4/4 - 2s - loss: 0.3936 - accuracy: 0.8250 - val_loss: 1.1164 - val_accuracy: 0.7000 - 2s/epoch - 522ms/step\n",
            "Epoch 207/1000\n",
            "4/4 - 2s - loss: 0.2450 - accuracy: 0.9250 - val_loss: 1.0688 - val_accuracy: 0.6333 - 2s/epoch - 522ms/step\n",
            "Epoch 208/1000\n",
            "4/4 - 2s - loss: 0.4978 - accuracy: 0.8000 - val_loss: 1.1188 - val_accuracy: 0.6333 - 2s/epoch - 525ms/step\n",
            "Epoch 209/1000\n",
            "4/4 - 2s - loss: 0.3187 - accuracy: 0.8750 - val_loss: 0.5217 - val_accuracy: 0.8000 - 2s/epoch - 519ms/step\n",
            "Epoch 210/1000\n",
            "4/4 - 2s - loss: 0.3971 - accuracy: 0.8750 - val_loss: 0.6746 - val_accuracy: 0.7667 - 2s/epoch - 517ms/step\n",
            "Epoch 211/1000\n",
            "4/4 - 2s - loss: 0.4959 - accuracy: 0.7750 - val_loss: 0.5206 - val_accuracy: 0.8000 - 2s/epoch - 519ms/step\n",
            "Epoch 212/1000\n",
            "4/4 - 2s - loss: 0.5018 - accuracy: 0.7500 - val_loss: 0.3116 - val_accuracy: 0.9000 - 2s/epoch - 592ms/step\n",
            "Epoch 213/1000\n",
            "4/4 - 2s - loss: 0.4341 - accuracy: 0.8500 - val_loss: 0.5007 - val_accuracy: 0.8000 - 2s/epoch - 586ms/step\n",
            "Epoch 214/1000\n",
            "4/4 - 2s - loss: 0.4501 - accuracy: 0.8750 - val_loss: 0.6297 - val_accuracy: 0.8000 - 2s/epoch - 511ms/step\n",
            "Epoch 215/1000\n",
            "4/4 - 2s - loss: 0.4264 - accuracy: 0.8250 - val_loss: 0.3457 - val_accuracy: 0.8333 - 2s/epoch - 527ms/step\n",
            "Epoch 216/1000\n",
            "4/4 - 2s - loss: 0.2414 - accuracy: 0.9250 - val_loss: 0.9570 - val_accuracy: 0.6000 - 2s/epoch - 532ms/step\n",
            "Epoch 217/1000\n",
            "4/4 - 2s - loss: 0.5059 - accuracy: 0.8250 - val_loss: 0.5077 - val_accuracy: 0.8000 - 2s/epoch - 537ms/step\n",
            "Epoch 218/1000\n",
            "4/4 - 2s - loss: 0.4130 - accuracy: 0.8250 - val_loss: 0.3620 - val_accuracy: 0.8667 - 2s/epoch - 518ms/step\n",
            "Epoch 219/1000\n",
            "4/4 - 2s - loss: 0.3027 - accuracy: 0.8750 - val_loss: 0.3582 - val_accuracy: 0.8333 - 2s/epoch - 522ms/step\n",
            "Epoch 220/1000\n",
            "4/4 - 2s - loss: 0.3482 - accuracy: 0.8500 - val_loss: 0.5207 - val_accuracy: 0.7667 - 2s/epoch - 522ms/step\n",
            "Epoch 221/1000\n",
            "4/4 - 2s - loss: 0.2903 - accuracy: 0.9250 - val_loss: 1.4207 - val_accuracy: 0.6667 - 2s/epoch - 525ms/step\n",
            "Epoch 222/1000\n",
            "4/4 - 2s - loss: 0.4861 - accuracy: 0.8500 - val_loss: 0.6561 - val_accuracy: 0.7667 - 2s/epoch - 526ms/step\n",
            "Epoch 223/1000\n",
            "4/4 - 2s - loss: 0.2003 - accuracy: 0.9250 - val_loss: 1.4349 - val_accuracy: 0.7000 - 2s/epoch - 527ms/step\n",
            "Epoch 224/1000\n",
            "4/4 - 2s - loss: 0.2728 - accuracy: 0.8750 - val_loss: 0.5442 - val_accuracy: 0.7667 - 2s/epoch - 530ms/step\n",
            "Epoch 225/1000\n",
            "4/4 - 2s - loss: 0.2842 - accuracy: 0.9000 - val_loss: 0.9455 - val_accuracy: 0.5333 - 2s/epoch - 523ms/step\n",
            "Epoch 226/1000\n",
            "4/4 - 2s - loss: 0.5248 - accuracy: 0.7750 - val_loss: 0.7402 - val_accuracy: 0.7333 - 2s/epoch - 594ms/step\n",
            "Epoch 227/1000\n",
            "4/4 - 2s - loss: 0.4798 - accuracy: 0.7250 - val_loss: 0.9716 - val_accuracy: 0.6667 - 2s/epoch - 535ms/step\n",
            "Epoch 228/1000\n",
            "4/4 - 2s - loss: 0.4460 - accuracy: 0.8000 - val_loss: 0.4102 - val_accuracy: 0.8667 - 2s/epoch - 582ms/step\n",
            "Epoch 229/1000\n",
            "4/4 - 2s - loss: 0.3722 - accuracy: 0.9000 - val_loss: 0.5492 - val_accuracy: 0.6667 - 2s/epoch - 584ms/step\n",
            "Epoch 230/1000\n",
            "4/4 - 2s - loss: 0.2536 - accuracy: 0.9000 - val_loss: 0.4365 - val_accuracy: 0.8667 - 2s/epoch - 512ms/step\n",
            "Epoch 231/1000\n",
            "4/4 - 2s - loss: 0.3018 - accuracy: 0.9000 - val_loss: 0.1470 - val_accuracy: 0.9333 - 2s/epoch - 614ms/step\n",
            "Epoch 232/1000\n",
            "4/4 - 2s - loss: 0.3436 - accuracy: 0.9250 - val_loss: 0.5827 - val_accuracy: 0.8333 - 2s/epoch - 521ms/step\n",
            "Epoch 233/1000\n",
            "4/4 - 2s - loss: 0.4233 - accuracy: 0.7750 - val_loss: 0.6783 - val_accuracy: 0.7333 - 2s/epoch - 592ms/step\n",
            "Epoch 234/1000\n",
            "4/4 - 2s - loss: 0.2925 - accuracy: 0.9250 - val_loss: 0.2712 - val_accuracy: 0.9000 - 2s/epoch - 524ms/step\n",
            "Epoch 235/1000\n",
            "4/4 - 2s - loss: 0.2781 - accuracy: 0.8750 - val_loss: 0.4131 - val_accuracy: 0.7333 - 2s/epoch - 529ms/step\n",
            "Epoch 236/1000\n",
            "4/4 - 2s - loss: 0.2765 - accuracy: 0.9000 - val_loss: 0.5913 - val_accuracy: 0.8333 - 2s/epoch - 589ms/step\n",
            "Epoch 237/1000\n",
            "4/4 - 2s - loss: 0.4427 - accuracy: 0.8750 - val_loss: 0.3841 - val_accuracy: 0.8000 - 2s/epoch - 584ms/step\n",
            "Epoch 238/1000\n",
            "4/4 - 2s - loss: 0.3450 - accuracy: 0.8500 - val_loss: 0.5083 - val_accuracy: 0.7667 - 2s/epoch - 586ms/step\n",
            "Epoch 239/1000\n",
            "4/4 - 2s - loss: 0.3135 - accuracy: 0.8750 - val_loss: 0.7699 - val_accuracy: 0.8667 - 2s/epoch - 585ms/step\n",
            "Epoch 240/1000\n",
            "4/4 - 2s - loss: 0.7151 - accuracy: 0.7250 - val_loss: 0.7273 - val_accuracy: 0.7333 - 2s/epoch - 589ms/step\n",
            "Epoch 241/1000\n",
            "4/4 - 2s - loss: 0.4791 - accuracy: 0.8500 - val_loss: 0.3297 - val_accuracy: 0.8333 - 2s/epoch - 585ms/step\n",
            "Epoch 242/1000\n",
            "4/4 - 2s - loss: 0.4436 - accuracy: 0.8250 - val_loss: 0.4117 - val_accuracy: 0.8333 - 2s/epoch - 523ms/step\n",
            "Epoch 243/1000\n",
            "4/4 - 2s - loss: 0.3861 - accuracy: 0.7750 - val_loss: 0.4215 - val_accuracy: 0.8333 - 2s/epoch - 526ms/step\n",
            "Epoch 244/1000\n",
            "4/4 - 2s - loss: 0.2804 - accuracy: 0.8500 - val_loss: 0.5436 - val_accuracy: 0.7000 - 2s/epoch - 522ms/step\n",
            "Epoch 245/1000\n",
            "4/4 - 2s - loss: 0.2491 - accuracy: 0.9000 - val_loss: 0.3866 - val_accuracy: 0.9000 - 2s/epoch - 516ms/step\n",
            "Epoch 246/1000\n",
            "4/4 - 2s - loss: 0.1869 - accuracy: 0.9250 - val_loss: 1.2821 - val_accuracy: 0.7333 - 2s/epoch - 527ms/step\n",
            "Epoch 247/1000\n",
            "4/4 - 2s - loss: 0.2548 - accuracy: 0.8750 - val_loss: 0.6453 - val_accuracy: 0.7333 - 2s/epoch - 519ms/step\n",
            "Epoch 248/1000\n",
            "4/4 - 2s - loss: 0.4598 - accuracy: 0.7250 - val_loss: 0.6155 - val_accuracy: 0.7667 - 2s/epoch - 518ms/step\n",
            "Epoch 249/1000\n",
            "4/4 - 2s - loss: 0.4146 - accuracy: 0.8500 - val_loss: 0.3095 - val_accuracy: 0.8333 - 2s/epoch - 590ms/step\n",
            "Epoch 250/1000\n",
            "4/4 - 2s - loss: 0.3784 - accuracy: 0.8250 - val_loss: 1.8084 - val_accuracy: 0.6333 - 2s/epoch - 531ms/step\n",
            "Epoch 251/1000\n",
            "4/4 - 2s - loss: 0.7086 - accuracy: 0.7250 - val_loss: 1.1927 - val_accuracy: 0.7333 - 2s/epoch - 525ms/step\n",
            "Epoch 252/1000\n",
            "4/4 - 2s - loss: 0.5555 - accuracy: 0.6750 - val_loss: 0.5467 - val_accuracy: 0.7000 - 2s/epoch - 525ms/step\n",
            "Epoch 253/1000\n",
            "4/4 - 2s - loss: 0.4634 - accuracy: 0.8250 - val_loss: 0.9328 - val_accuracy: 0.6333 - 2s/epoch - 527ms/step\n",
            "Epoch 254/1000\n",
            "4/4 - 2s - loss: 0.3174 - accuracy: 0.8750 - val_loss: 0.4030 - val_accuracy: 0.9000 - 2s/epoch - 510ms/step\n",
            "Epoch 255/1000\n",
            "4/4 - 2s - loss: 0.3695 - accuracy: 0.8250 - val_loss: 0.6627 - val_accuracy: 0.6333 - 2s/epoch - 585ms/step\n",
            "Epoch 256/1000\n",
            "4/4 - 2s - loss: 0.5755 - accuracy: 0.7750 - val_loss: 1.0773 - val_accuracy: 0.5667 - 2s/epoch - 521ms/step\n",
            "Epoch 257/1000\n",
            "4/4 - 2s - loss: 0.3006 - accuracy: 0.8750 - val_loss: 0.7322 - val_accuracy: 0.7333 - 2s/epoch - 589ms/step\n",
            "Epoch 258/1000\n",
            "4/4 - 2s - loss: 0.2458 - accuracy: 0.8750 - val_loss: 0.4793 - val_accuracy: 0.7667 - 2s/epoch - 518ms/step\n",
            "Epoch 259/1000\n",
            "4/4 - 2s - loss: 0.2084 - accuracy: 0.9500 - val_loss: 0.3306 - val_accuracy: 0.9000 - 2s/epoch - 526ms/step\n",
            "Epoch 260/1000\n",
            "4/4 - 2s - loss: 0.3971 - accuracy: 0.8750 - val_loss: 0.8420 - val_accuracy: 0.6667 - 2s/epoch - 586ms/step\n",
            "Epoch 261/1000\n",
            "4/4 - 2s - loss: 0.2166 - accuracy: 0.9250 - val_loss: 0.9421 - val_accuracy: 0.6333 - 2s/epoch - 520ms/step\n",
            "Epoch 262/1000\n",
            "4/4 - 2s - loss: 0.5435 - accuracy: 0.8000 - val_loss: 0.2796 - val_accuracy: 0.9000 - 2s/epoch - 589ms/step\n",
            "Epoch 263/1000\n",
            "4/4 - 2s - loss: 0.4651 - accuracy: 0.8000 - val_loss: 0.2710 - val_accuracy: 0.8667 - 2s/epoch - 518ms/step\n",
            "Epoch 264/1000\n",
            "4/4 - 2s - loss: 0.2407 - accuracy: 0.9000 - val_loss: 1.4150 - val_accuracy: 0.7000 - 2s/epoch - 515ms/step\n",
            "Epoch 265/1000\n",
            "4/4 - 2s - loss: 0.2355 - accuracy: 0.8750 - val_loss: 1.0315 - val_accuracy: 0.7667 - 2s/epoch - 581ms/step\n",
            "Epoch 266/1000\n",
            "4/4 - 2s - loss: 0.3530 - accuracy: 0.8750 - val_loss: 0.4165 - val_accuracy: 0.7667 - 2s/epoch - 520ms/step\n",
            "Epoch 267/1000\n",
            "4/4 - 2s - loss: 0.4286 - accuracy: 0.7250 - val_loss: 0.4966 - val_accuracy: 0.8333 - 2s/epoch - 588ms/step\n",
            "Epoch 268/1000\n",
            "4/4 - 2s - loss: 0.2876 - accuracy: 0.9000 - val_loss: 0.6797 - val_accuracy: 0.7000 - 2s/epoch - 591ms/step\n",
            "Epoch 269/1000\n",
            "4/4 - 2s - loss: 0.2470 - accuracy: 0.9000 - val_loss: 0.7010 - val_accuracy: 0.7333 - 2s/epoch - 582ms/step\n",
            "Epoch 270/1000\n",
            "4/4 - 2s - loss: 0.4153 - accuracy: 0.8500 - val_loss: 0.6569 - val_accuracy: 0.8000 - 2s/epoch - 524ms/step\n",
            "Epoch 271/1000\n",
            "4/4 - 2s - loss: 0.3655 - accuracy: 0.8250 - val_loss: 0.3126 - val_accuracy: 0.8000 - 2s/epoch - 585ms/step\n",
            "Epoch 272/1000\n",
            "4/4 - 2s - loss: 0.3124 - accuracy: 0.8750 - val_loss: 0.4537 - val_accuracy: 0.7667 - 2s/epoch - 517ms/step\n",
            "Epoch 273/1000\n",
            "4/4 - 2s - loss: 0.2756 - accuracy: 0.9250 - val_loss: 0.9855 - val_accuracy: 0.7000 - 2s/epoch - 584ms/step\n",
            "Epoch 274/1000\n",
            "4/4 - 2s - loss: 0.3669 - accuracy: 0.8000 - val_loss: 0.6373 - val_accuracy: 0.7333 - 2s/epoch - 587ms/step\n",
            "Epoch 275/1000\n",
            "4/4 - 2s - loss: 0.2731 - accuracy: 0.8750 - val_loss: 0.3970 - val_accuracy: 0.8000 - 2s/epoch - 529ms/step\n",
            "Epoch 276/1000\n",
            "4/4 - 2s - loss: 0.1583 - accuracy: 0.9250 - val_loss: 1.1963 - val_accuracy: 0.6333 - 2s/epoch - 519ms/step\n",
            "Epoch 277/1000\n",
            "4/4 - 2s - loss: 0.2848 - accuracy: 0.8500 - val_loss: 0.6527 - val_accuracy: 0.8000 - 2s/epoch - 522ms/step\n",
            "Epoch 278/1000\n",
            "4/4 - 2s - loss: 0.2625 - accuracy: 0.8750 - val_loss: 0.7573 - val_accuracy: 0.7333 - 2s/epoch - 519ms/step\n",
            "Epoch 279/1000\n",
            "4/4 - 2s - loss: 0.2715 - accuracy: 0.9000 - val_loss: 0.6295 - val_accuracy: 0.8333 - 2s/epoch - 525ms/step\n",
            "Epoch 280/1000\n",
            "4/4 - 2s - loss: 0.3959 - accuracy: 0.8500 - val_loss: 0.8568 - val_accuracy: 0.7333 - 2s/epoch - 583ms/step\n",
            "Epoch 281/1000\n",
            "4/4 - 2s - loss: 0.1430 - accuracy: 0.9750 - val_loss: 0.3539 - val_accuracy: 0.9000 - 2s/epoch - 599ms/step\n",
            "Epoch 282/1000\n",
            "4/4 - 2s - loss: 0.1825 - accuracy: 0.9500 - val_loss: 1.3158 - val_accuracy: 0.6667 - 2s/epoch - 537ms/step\n",
            "Epoch 283/1000\n",
            "4/4 - 2s - loss: 0.4527 - accuracy: 0.8750 - val_loss: 0.6423 - val_accuracy: 0.7333 - 2s/epoch - 537ms/step\n",
            "Epoch 284/1000\n",
            "4/4 - 2s - loss: 0.4429 - accuracy: 0.8000 - val_loss: 0.4453 - val_accuracy: 0.8667 - 2s/epoch - 593ms/step\n",
            "Epoch 285/1000\n",
            "4/4 - 2s - loss: 0.2817 - accuracy: 0.9000 - val_loss: 1.1372 - val_accuracy: 0.6333 - 2s/epoch - 586ms/step\n",
            "Epoch 286/1000\n",
            "4/4 - 2s - loss: 0.2129 - accuracy: 0.9000 - val_loss: 0.6038 - val_accuracy: 0.8000 - 2s/epoch - 587ms/step\n",
            "Epoch 287/1000\n",
            "4/4 - 2s - loss: 0.2921 - accuracy: 0.8750 - val_loss: 1.0454 - val_accuracy: 0.7000 - 2s/epoch - 585ms/step\n",
            "Epoch 288/1000\n",
            "4/4 - 2s - loss: 0.2026 - accuracy: 0.9000 - val_loss: 0.5711 - val_accuracy: 0.7667 - 2s/epoch - 586ms/step\n",
            "Epoch 289/1000\n",
            "4/4 - 2s - loss: 0.3378 - accuracy: 0.8750 - val_loss: 0.6160 - val_accuracy: 0.7667 - 2s/epoch - 521ms/step\n",
            "Epoch 290/1000\n",
            "4/4 - 2s - loss: 0.2941 - accuracy: 0.8500 - val_loss: 0.2564 - val_accuracy: 0.9000 - 2s/epoch - 585ms/step\n",
            "Epoch 291/1000\n",
            "4/4 - 2s - loss: 0.3646 - accuracy: 0.8250 - val_loss: 0.7041 - val_accuracy: 0.8333 - 2s/epoch - 519ms/step\n",
            "Epoch 292/1000\n",
            "4/4 - 2s - loss: 0.2964 - accuracy: 0.9250 - val_loss: 0.7367 - val_accuracy: 0.6333 - 2s/epoch - 529ms/step\n",
            "Epoch 293/1000\n",
            "4/4 - 2s - loss: 0.2669 - accuracy: 0.9250 - val_loss: 0.7546 - val_accuracy: 0.7667 - 2s/epoch - 515ms/step\n",
            "Epoch 294/1000\n",
            "4/4 - 2s - loss: 0.0976 - accuracy: 1.0000 - val_loss: 0.9831 - val_accuracy: 0.6667 - 2s/epoch - 583ms/step\n",
            "Epoch 295/1000\n",
            "4/4 - 2s - loss: 0.1138 - accuracy: 0.9500 - val_loss: 1.3921 - val_accuracy: 0.6667 - 2s/epoch - 584ms/step\n",
            "Epoch 296/1000\n",
            "4/4 - 2s - loss: 0.5283 - accuracy: 0.8250 - val_loss: 0.3432 - val_accuracy: 0.8667 - 2s/epoch - 582ms/step\n",
            "Epoch 297/1000\n",
            "4/4 - 2s - loss: 0.3049 - accuracy: 0.8500 - val_loss: 0.6191 - val_accuracy: 0.8000 - 2s/epoch - 528ms/step\n",
            "Epoch 298/1000\n",
            "4/4 - 2s - loss: 0.2437 - accuracy: 0.9250 - val_loss: 0.4947 - val_accuracy: 0.8333 - 2s/epoch - 530ms/step\n",
            "Epoch 299/1000\n",
            "4/4 - 2s - loss: 0.5028 - accuracy: 0.8750 - val_loss: 0.6346 - val_accuracy: 0.7000 - 2s/epoch - 582ms/step\n",
            "Epoch 300/1000\n",
            "4/4 - 2s - loss: 0.1071 - accuracy: 0.9750 - val_loss: 0.3540 - val_accuracy: 0.9000 - 2s/epoch - 590ms/step\n",
            "Epoch 301/1000\n",
            "4/4 - 2s - loss: 0.2473 - accuracy: 0.8750 - val_loss: 0.9112 - val_accuracy: 0.7000 - 2s/epoch - 520ms/step\n",
            "Epoch 302/1000\n",
            "4/4 - 2s - loss: 0.2681 - accuracy: 0.9000 - val_loss: 0.6813 - val_accuracy: 0.7000 - 2s/epoch - 582ms/step\n",
            "Epoch 303/1000\n",
            "4/4 - 2s - loss: 0.1758 - accuracy: 0.9000 - val_loss: 0.8432 - val_accuracy: 0.8667 - 2s/epoch - 522ms/step\n",
            "Epoch 304/1000\n",
            "4/4 - 2s - loss: 0.3859 - accuracy: 0.8750 - val_loss: 0.5447 - val_accuracy: 0.8333 - 2s/epoch - 587ms/step\n",
            "Epoch 305/1000\n",
            "4/4 - 2s - loss: 0.2256 - accuracy: 0.9000 - val_loss: 0.4982 - val_accuracy: 0.8000 - 2s/epoch - 584ms/step\n",
            "Epoch 306/1000\n",
            "4/4 - 2s - loss: 0.3635 - accuracy: 0.8500 - val_loss: 1.2185 - val_accuracy: 0.6667 - 2s/epoch - 527ms/step\n",
            "Epoch 307/1000\n",
            "4/4 - 2s - loss: 0.3520 - accuracy: 0.8000 - val_loss: 0.4185 - val_accuracy: 0.8000 - 2s/epoch - 524ms/step\n",
            "Epoch 308/1000\n",
            "4/4 - 2s - loss: 0.1725 - accuracy: 0.9250 - val_loss: 0.2424 - val_accuracy: 0.9333 - 2s/epoch - 582ms/step\n",
            "Epoch 309/1000\n",
            "4/4 - 2s - loss: 0.3335 - accuracy: 0.9000 - val_loss: 0.7281 - val_accuracy: 0.7333 - 2s/epoch - 579ms/step\n",
            "Epoch 310/1000\n",
            "4/4 - 2s - loss: 0.3565 - accuracy: 0.8750 - val_loss: 0.9901 - val_accuracy: 0.7000 - 2s/epoch - 585ms/step\n",
            "Epoch 311/1000\n",
            "Restoring model weights from the end of the best epoch: 231.\n",
            "4/4 - 2s - loss: 0.5090 - accuracy: 0.7750 - val_loss: 0.5018 - val_accuracy: 0.8000 - 2s/epoch - 611ms/step\n",
            "Epoch 311: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Callback to save the current best model\n",
        "epochs = 1000\n",
        "patience = epochs\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=80, mode='min', verbose=1, restore_best_weights=True),\n",
        "    #CustomEarlyStopping(patience=patience),\n",
        "    #tf.keras.callbacks.ModelCheckpoint(filepath='batik-recognition-model.{epoch:03d}.hdf5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=False),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "]\n",
        "\n",
        "# Using Batch Gradient Descent (batch_size = training_examples) because data is less than 2000\n",
        "# Stochastic Gradient Descent (batch_size = 1)\n",
        "# Mini-Batch Gradient Descent (batch_size = 1 < number_power_of_2 < training_examples)\n",
        "# steps per epoch = 18\n",
        "# validation steps = 3\n",
        "history = xception.fit(train_batches, \n",
        "                        steps_per_epoch=4, \n",
        "                        batch_size=training_examples, \n",
        "                        validation_data=valid_batches, \n",
        "                        validation_steps=2, \n",
        "                        epochs=epochs, verbose=2, \n",
        "                        callbacks=my_callbacks,\n",
        "                        shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "_YjotpcCY1WW"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path):\n",
        "    data = load_files(path)\n",
        "    paths = np.array(data['filenames'])\n",
        "    targets = np_utils.to_categorical(np.array(data['target']))\n",
        "    return paths, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "2e-ZFqEaY1WX"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "\n",
        "test_files, test_targets = load_dataset(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "YZTRmdooUOCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91446891-4b43-42bc-852d-7eb3613680b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 320/320 [00:01<00:00, 200.19it/s]\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import image  \n",
        "from tqdm import tqdm\n",
        "\n",
        "def path_to_tensor(img_path):\n",
        "    img = image.load_img(img_path, target_size=(299, 299))\n",
        "    x = image.img_to_array(img)\n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "def paths_to_tensor(img_paths):\n",
        "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
        "    return np.vstack(list_of_tensors)\n",
        "\n",
        "test_tensors = preprocess_input(paths_to_tensor(test_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "UNOvbJI0UQyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfc245f-33ea-46c5-b4c3-28cc3d0bf6d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 4s 318ms/step - loss: 1.1289 - accuracy: 0.5656\n",
            "\n",
            "Testing loss: 1.1289\n",
            "Testing accuracy: 0.5656\n"
          ]
        }
      ],
      "source": [
        "# Model Testing\n",
        "# if you want to select the model yourself, uncomment the next line and change the filename as the one you choose\n",
        "# new_model.load_weights('filename.hdf5')\n",
        "\n",
        "print('\\nTesting loss: {:.4f}\\nTesting accuracy: {:.4f}'.format(*xception.evaluate(test_tensors, test_targets)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "RrCuxDCuUTW6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "31c10a60-a5af-4e34-d297-8390344d64e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Confussion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm_labels = ['Pekalongan', 'Bukan Pekalongan']\n",
        "\n",
        "y_true = np.argmax(test_targets, axis=1)\n",
        "y_pred = np.argmax(xception.predict(test_tensors), axis=1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "indexes = np.arange(len(cm_labels))\n",
        "for i in indexes:\n",
        "    for j in indexes:\n",
        "        plt.text(j, i, cm[i, j])\n",
        "plt.xticks(indexes, cm_labels, rotation=90)\n",
        "plt.xlabel('Predicted label')\n",
        "plt.yticks(indexes, cm_labels)\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix, Early Stopping Best Model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "EsqYNyL1UYkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8460b836-d21d-4b52-ed5b-70fbd43a09ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "      Pekalongan       0.67      0.26      0.37       160\n",
            "Bukan Pekalongan       0.54      0.88      0.67       160\n",
            "\n",
            "        accuracy                           0.57       320\n",
            "       macro avg       0.61      0.57      0.52       320\n",
            "    weighted avg       0.61      0.57      0.52       320\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.argmax(test_targets, axis=1), np.argmax(xception.predict(test_tensors), axis=1), target_names=cm_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "cuRuiTk340rK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb3509a-c24a-4cde-8f93-2f3e51f4cb20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.47351742, 0.47351742])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# Geometric Mean\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "geometric_mean_score(y_true, y_pred, pos_label=1, average=None, correction=0.0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Xception_2_Kelas.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "55b315c3dbf10ef7f12b59bd8ad1fda37f03e8048b8c0ccbc36f7a976bce2219"
    },
    "kernelspec": {
      "display_name": "Python 3.8.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}