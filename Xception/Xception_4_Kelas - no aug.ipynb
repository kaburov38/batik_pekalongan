{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xyalPcwY1WO",
        "outputId": "bda74ed8-bd4a-4bb7-941e-3cc3ffef9d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import Dataset\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import os\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from keras.applications.xception import preprocess_input\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import drive\n",
        "\n",
        "# Accessing My Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Ewrz5ZgaY1WQ"
      },
      "outputs": [],
      "source": [
        "# Location Path\n",
        "train_path  = 'drive/My Drive/data pekalongan/raw/train'\n",
        "valid_path  = 'drive/My Drive/data pekalongan/raw/valid'\n",
        "test_path  = 'drive/My Drive/data pekalongan/raw/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKHn3IwRY1WQ",
        "outputId": "edc9675f-3af7-4e96-be25-b080ed259ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1844 images belonging to 4 classes.\n",
            "Found 160 images belonging to 4 classes.\n",
            "Found 160 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    #rotation_range=30,\n",
        "    #width_shift_range=0.2,\n",
        "    #height_shift_range=0.2,\n",
        "    #shear_range=0.1,\n",
        "    #zoom_range=0.3,\n",
        "    #horizontal_flip=True,\n",
        "    #vertical_flip=True,\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rescale=1./127.5-1.,\n",
        ")\n",
        "\n",
        "# Train, Test, Validation\n",
        "train_batches = datagen.flow_from_directory(\n",
        "    train_path, target_size=(299,299), batch_size=10)\n",
        "valid_batches = datagen.flow_from_directory(\n",
        "    valid_path, target_size=(299,299), batch_size=15)\n",
        "test_batches = datagen.flow_from_directory(\n",
        "    test_path, target_size=(299,299), batch_size=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aL1hquC-Q5D",
        "outputId": "3e16c067-a4bc-43d4-e960-ce8903da16b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([(0, 456), (1, 470), (2, 460), (3, 458)])\n",
            "1844\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "samples = Counter(train_batches.classes)\n",
        "\n",
        "print(samples.items()) # dict_items([(0, 1648), (1, 3614)])\n",
        "\n",
        "training_examples = 0;\n",
        "for item in samples.items():\n",
        "    training_examples += item[1]\n",
        "\n",
        "print(training_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "I5HE-0el3iXp"
      },
      "outputs": [],
      "source": [
        "def entry_flow(inputs):\n",
        "\n",
        "  x = layers.Conv2D(32, 3, strides=2, padding='same')(inputs)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  previous_block_activation = x  # Set aside residual\n",
        "  \n",
        "  # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "  for size in [128, 256, 728]:\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "    \n",
        "    residual = layers.Conv2D(  # Project residual\n",
        "        size, 1, strides=2, padding='same')(previous_block_activation)           \n",
        "    x = layers.add([x, residual])  # Add back residual\n",
        "    previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "def middle_flow(x, num_blocks=8):\n",
        "  \n",
        "  previous_block_activation = x\n",
        "\n",
        "  for _ in range(num_blocks):\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.add([x, previous_block_activation])  # Add back residual\n",
        "    previous_block_activation = x  # Set aside next residual\n",
        "    \n",
        "  return x\n",
        "\n",
        "\n",
        "def exit_flow(x, num_classes=1000):\n",
        "  \n",
        "  previous_block_activation = x\n",
        "\n",
        "  x = layers.Activation('relu')(x)\n",
        "  x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "\n",
        "  x = layers.Activation('relu')(x)\n",
        "  x = layers.SeparableConv2D(1024, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  \n",
        "  x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "  residual = layers.Conv2D(  # Project residual\n",
        "      1024, 1, strides=2, padding='same')(previous_block_activation)\n",
        "  x = layers.add([x, residual])  # Add back residual\n",
        "  \n",
        "  x = layers.SeparableConv2D(1536, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "  \n",
        "  x = layers.SeparableConv2D(2048, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "  \n",
        "  x = layers.GlobalAveragePooling2D()(x)\n",
        "  if num_classes == 1:\n",
        "    activation = 'sigmoid'\n",
        "  else:\n",
        "    activation = 'softmax'\n",
        "  return layers.Dense(num_classes, activation=activation)(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "d4_96LWHY1WU"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "# Create Xception by chaining the 3 flows\n",
        "inputs = keras.Input(shape=(299, 299, 3))\n",
        "outputs = exit_flow(middle_flow(entry_flow(inputs), num_blocks=8), num_classes=4)\n",
        "xception = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "E9_jGuo9sPYi"
      },
      "outputs": [],
      "source": [
        "# Custom Early Stopping\n",
        "# Expected behavior: EarlyStopping should restore weights on end of training regardless it stop training early or after the last epoch\n",
        "\n",
        "class CustomEarlyStopping(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, patience=0):\n",
        "        super(CustomEarlyStopping, self).__init__()\n",
        "        self.patience = patience\n",
        "        self.best_weights = None\n",
        "        \n",
        "    def on_train_begin(self, logs=None):\n",
        "        # The number of epoch it has waited when loss is no longer minimum.\n",
        "        self.wait = 0\n",
        "        # The epoch the training stops at.\n",
        "        self.stopped_epoch = 0\n",
        "        # Initialize the best as infinity.\n",
        "        self.best_val_loss = np.Inf\n",
        "        self.best_loss = np.Inf\n",
        "        self.best_val_accuracy = 0.0\n",
        "        self.best_accuracy = 0.0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        val_loss = logs.get('val_loss')\n",
        "        loss = logs.get('loss')\n",
        "        val_accuracy = logs.get('val_accuracy')\n",
        "        accuracy = logs.get('accuracy')\n",
        "\n",
        "        # if np.less(val_loss, self.best_val_loss) and np.greater(map10, self.best_map10):\n",
        "        if np.greater_equal(val_accuracy, self.best_val_accuracy) and np.greater_equal(accuracy, self.best_accuracy) and np.greater_equal(accuracy, val_accuracy):\n",
        "            self.best_val_loss = val_loss\n",
        "            self.best_loss = loss\n",
        "            self.best_val_accuracy = val_accuracy\n",
        "            self.best_accuracy = accuracy\n",
        "            self.wait = 0\n",
        "\n",
        "            # Record the best weights if current results is better.\n",
        "            print(\"Saving the best weight at epoch {}\".format(epoch + 1))\n",
        "            self.best_weights = self.model.get_weights()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                print(\"Training stop early. Restoring model weights from the end of the best epoch.\")\n",
        "                self.model.set_weights(self.best_weights)\n",
        "                \n",
        "    def on_train_end(self, logs=None):\n",
        "        # EarlyStopping will restore weights after the last epoch only if it is not stop early\n",
        "        if self.stopped_epoch > 0:\n",
        "            print(\"Epoch {}: early stopping\".format(self.stopped_epoch + 1))\n",
        "        else:\n",
        "            print(\"Training stop after the last epoch. Restoring model weights from the end of the best epoch.\")\n",
        "            self.model.set_weights(self.best_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "dg2toYR8Y1WV"
      },
      "outputs": [],
      "source": [
        "xception.compile(RMSprop(learning_rate=3e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp-gJ4L7Y1WW",
        "outputId": "ef4766ca-2225-4d65-9351-3874326a0d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "4/4 - 12s - loss: 3.0030 - accuracy: 0.2250 - val_loss: 1.3865 - val_accuracy: 0.1667 - 12s/epoch - 3s/step\n",
            "Epoch 2/1000\n",
            "4/4 - 2s - loss: 2.1796 - accuracy: 0.2000 - val_loss: 1.3838 - val_accuracy: 0.3667 - 2s/epoch - 605ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 2s - loss: 1.7986 - accuracy: 0.4000 - val_loss: 1.3864 - val_accuracy: 0.1667 - 2s/epoch - 522ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 2s - loss: 1.6971 - accuracy: 0.3500 - val_loss: 1.3863 - val_accuracy: 0.1000 - 2s/epoch - 520ms/step\n",
            "Epoch 5/1000\n",
            "4/4 - 2s - loss: 1.4499 - accuracy: 0.3250 - val_loss: 1.3871 - val_accuracy: 0.1667 - 2s/epoch - 523ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 2s - loss: 1.2942 - accuracy: 0.4250 - val_loss: 1.3868 - val_accuracy: 0.2667 - 2s/epoch - 513ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 2s - loss: 1.3878 - accuracy: 0.4250 - val_loss: 1.3874 - val_accuracy: 0.2000 - 2s/epoch - 566ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 2s - loss: 1.6007 - accuracy: 0.3250 - val_loss: 1.3854 - val_accuracy: 0.2667 - 2s/epoch - 566ms/step\n",
            "Epoch 9/1000\n",
            "4/4 - 2s - loss: 1.4861 - accuracy: 0.3500 - val_loss: 1.3870 - val_accuracy: 0.2333 - 2s/epoch - 515ms/step\n",
            "Epoch 10/1000\n",
            "4/4 - 2s - loss: 1.4244 - accuracy: 0.4000 - val_loss: 1.3863 - val_accuracy: 0.2333 - 2s/epoch - 525ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 2s - loss: 1.3228 - accuracy: 0.4250 - val_loss: 1.3854 - val_accuracy: 0.2333 - 2s/epoch - 524ms/step\n",
            "Epoch 12/1000\n",
            "4/4 - 2s - loss: 1.0859 - accuracy: 0.5750 - val_loss: 1.3859 - val_accuracy: 0.2667 - 2s/epoch - 516ms/step\n",
            "Epoch 13/1000\n",
            "4/4 - 2s - loss: 1.4115 - accuracy: 0.4000 - val_loss: 1.3838 - val_accuracy: 0.3333 - 2s/epoch - 598ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 2s - loss: 1.4261 - accuracy: 0.4000 - val_loss: 1.3857 - val_accuracy: 0.3000 - 2s/epoch - 527ms/step\n",
            "Epoch 15/1000\n",
            "4/4 - 2s - loss: 1.3923 - accuracy: 0.3750 - val_loss: 1.3887 - val_accuracy: 0.1667 - 2s/epoch - 520ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 2s - loss: 1.4828 - accuracy: 0.2500 - val_loss: 1.3924 - val_accuracy: 0.0333 - 2s/epoch - 528ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 2s - loss: 1.5393 - accuracy: 0.2750 - val_loss: 1.3901 - val_accuracy: 0.1333 - 2s/epoch - 533ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 2s - loss: 1.4964 - accuracy: 0.3250 - val_loss: 1.3889 - val_accuracy: 0.2333 - 2s/epoch - 524ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 2s - loss: 1.4226 - accuracy: 0.3250 - val_loss: 1.3856 - val_accuracy: 0.2000 - 2s/epoch - 578ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 2s - loss: 1.3514 - accuracy: 0.3500 - val_loss: 1.3861 - val_accuracy: 0.2333 - 2s/epoch - 519ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 2s - loss: 1.3861 - accuracy: 0.3250 - val_loss: 1.3881 - val_accuracy: 0.3000 - 2s/epoch - 515ms/step\n",
            "Epoch 22/1000\n",
            "4/4 - 2s - loss: 1.2443 - accuracy: 0.3000 - val_loss: 1.3904 - val_accuracy: 0.2000 - 2s/epoch - 574ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 2s - loss: 1.2957 - accuracy: 0.4750 - val_loss: 1.3838 - val_accuracy: 0.3000 - 2s/epoch - 524ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 2s - loss: 1.2695 - accuracy: 0.4000 - val_loss: 1.3872 - val_accuracy: 0.2667 - 2s/epoch - 517ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 2s - loss: 1.3186 - accuracy: 0.4250 - val_loss: 1.3849 - val_accuracy: 0.2667 - 2s/epoch - 531ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 2s - loss: 1.3535 - accuracy: 0.4000 - val_loss: 1.3866 - val_accuracy: 0.2000 - 2s/epoch - 573ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 2s - loss: 1.1801 - accuracy: 0.5500 - val_loss: 1.3844 - val_accuracy: 0.3333 - 2s/epoch - 510ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 2s - loss: 1.2909 - accuracy: 0.4250 - val_loss: 1.3845 - val_accuracy: 0.2333 - 2s/epoch - 564ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 2s - loss: 1.2325 - accuracy: 0.3750 - val_loss: 1.3859 - val_accuracy: 0.2000 - 2s/epoch - 518ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 2s - loss: 1.2876 - accuracy: 0.4250 - val_loss: 1.3870 - val_accuracy: 0.2667 - 2s/epoch - 564ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 2s - loss: 1.1276 - accuracy: 0.5250 - val_loss: 1.3869 - val_accuracy: 0.2000 - 2s/epoch - 509ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 2s - loss: 1.2158 - accuracy: 0.4750 - val_loss: 1.3916 - val_accuracy: 0.1667 - 2s/epoch - 570ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 2s - loss: 1.3495 - accuracy: 0.3750 - val_loss: 1.3860 - val_accuracy: 0.2333 - 2s/epoch - 572ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 2s - loss: 1.2416 - accuracy: 0.3500 - val_loss: 1.3873 - val_accuracy: 0.2333 - 2s/epoch - 514ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 2s - loss: 1.2306 - accuracy: 0.4250 - val_loss: 1.3849 - val_accuracy: 0.3000 - 2s/epoch - 565ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 2s - loss: 1.2138 - accuracy: 0.3750 - val_loss: 1.3860 - val_accuracy: 0.2333 - 2s/epoch - 521ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 2s - loss: 1.0245 - accuracy: 0.5500 - val_loss: 1.3939 - val_accuracy: 0.1333 - 2s/epoch - 568ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 2s - loss: 0.9181 - accuracy: 0.6500 - val_loss: 1.3856 - val_accuracy: 0.2000 - 2s/epoch - 517ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 2s - loss: 1.0548 - accuracy: 0.5500 - val_loss: 1.3917 - val_accuracy: 0.2667 - 2s/epoch - 515ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 2s - loss: 1.0590 - accuracy: 0.5250 - val_loss: 1.3837 - val_accuracy: 0.2667 - 2s/epoch - 542ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 2s - loss: 1.1253 - accuracy: 0.5250 - val_loss: 1.3829 - val_accuracy: 0.3333 - 2s/epoch - 543ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 2s - loss: 1.0781 - accuracy: 0.5500 - val_loss: 1.3851 - val_accuracy: 0.2667 - 2s/epoch - 511ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 2s - loss: 1.0045 - accuracy: 0.5750 - val_loss: 1.3814 - val_accuracy: 0.3000 - 2s/epoch - 544ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 2s - loss: 1.3637 - accuracy: 0.4250 - val_loss: 1.3887 - val_accuracy: 0.1000 - 2s/epoch - 566ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 2s - loss: 1.3524 - accuracy: 0.4000 - val_loss: 1.3801 - val_accuracy: 0.3000 - 2s/epoch - 553ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 2s - loss: 1.2680 - accuracy: 0.5250 - val_loss: 1.3821 - val_accuracy: 0.3000 - 2s/epoch - 516ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 2s - loss: 0.9067 - accuracy: 0.7000 - val_loss: 1.3854 - val_accuracy: 0.1667 - 2s/epoch - 574ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 2s - loss: 1.0910 - accuracy: 0.4500 - val_loss: 1.3927 - val_accuracy: 0.1667 - 2s/epoch - 510ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 2s - loss: 1.1838 - accuracy: 0.5250 - val_loss: 1.3842 - val_accuracy: 0.2667 - 2s/epoch - 525ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 2s - loss: 0.8310 - accuracy: 0.6250 - val_loss: 1.3867 - val_accuracy: 0.2333 - 2s/epoch - 544ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 2s - loss: 1.0893 - accuracy: 0.6250 - val_loss: 1.3743 - val_accuracy: 0.3333 - 2s/epoch - 559ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 2s - loss: 0.8871 - accuracy: 0.6176 - val_loss: 1.3826 - val_accuracy: 0.2667 - 2s/epoch - 514ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 2s - loss: 1.2401 - accuracy: 0.5000 - val_loss: 1.3838 - val_accuracy: 0.2667 - 2s/epoch - 513ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 2s - loss: 1.0503 - accuracy: 0.5500 - val_loss: 1.4052 - val_accuracy: 0.2667 - 2s/epoch - 511ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 2s - loss: 1.0812 - accuracy: 0.5250 - val_loss: 1.3728 - val_accuracy: 0.4333 - 2s/epoch - 545ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 2s - loss: 1.0485 - accuracy: 0.5500 - val_loss: 1.3841 - val_accuracy: 0.2333 - 2s/epoch - 567ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 2s - loss: 0.9517 - accuracy: 0.6250 - val_loss: 1.3992 - val_accuracy: 0.1667 - 2s/epoch - 507ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 2s - loss: 1.1607 - accuracy: 0.4750 - val_loss: 1.3896 - val_accuracy: 0.3333 - 2s/epoch - 514ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 2s - loss: 1.2127 - accuracy: 0.6000 - val_loss: 1.3839 - val_accuracy: 0.2000 - 2s/epoch - 574ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 2s - loss: 1.2128 - accuracy: 0.3500 - val_loss: 1.3848 - val_accuracy: 0.2333 - 2s/epoch - 515ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 2s - loss: 1.1719 - accuracy: 0.5000 - val_loss: 1.4013 - val_accuracy: 0.1000 - 2s/epoch - 577ms/step\n",
            "Epoch 62/1000\n",
            "4/4 - 2s - loss: 1.1609 - accuracy: 0.4000 - val_loss: 1.3750 - val_accuracy: 0.2667 - 2s/epoch - 517ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 2s - loss: 1.0576 - accuracy: 0.6750 - val_loss: 1.3721 - val_accuracy: 0.2667 - 2s/epoch - 540ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 2s - loss: 0.9593 - accuracy: 0.6000 - val_loss: 1.3955 - val_accuracy: 0.1667 - 2s/epoch - 515ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 2s - loss: 1.1919 - accuracy: 0.5250 - val_loss: 1.4357 - val_accuracy: 0.1000 - 2s/epoch - 512ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 2s - loss: 0.9648 - accuracy: 0.6500 - val_loss: 1.3726 - val_accuracy: 0.3667 - 2s/epoch - 525ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 2s - loss: 1.0161 - accuracy: 0.5000 - val_loss: 1.4224 - val_accuracy: 0.3333 - 2s/epoch - 563ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 2s - loss: 1.2677 - accuracy: 0.3750 - val_loss: 1.4249 - val_accuracy: 0.1667 - 2s/epoch - 564ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 2s - loss: 0.9990 - accuracy: 0.5750 - val_loss: 1.4272 - val_accuracy: 0.1667 - 2s/epoch - 521ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 2s - loss: 0.9775 - accuracy: 0.5750 - val_loss: 1.3701 - val_accuracy: 0.2333 - 2s/epoch - 551ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 2s - loss: 0.9742 - accuracy: 0.5750 - val_loss: 1.3721 - val_accuracy: 0.3000 - 2s/epoch - 573ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 2s - loss: 1.0745 - accuracy: 0.5250 - val_loss: 1.3849 - val_accuracy: 0.3000 - 2s/epoch - 572ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 2s - loss: 1.0496 - accuracy: 0.6000 - val_loss: 1.3877 - val_accuracy: 0.2000 - 2s/epoch - 509ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 2s - loss: 0.7385 - accuracy: 0.6750 - val_loss: 1.4041 - val_accuracy: 0.2000 - 2s/epoch - 565ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 2s - loss: 0.9465 - accuracy: 0.6000 - val_loss: 1.3640 - val_accuracy: 0.2333 - 2s/epoch - 554ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 2s - loss: 1.0349 - accuracy: 0.6000 - val_loss: 1.3944 - val_accuracy: 0.3000 - 2s/epoch - 575ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 2s - loss: 1.0460 - accuracy: 0.6000 - val_loss: 1.3859 - val_accuracy: 0.1667 - 2s/epoch - 583ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 2s - loss: 0.6538 - accuracy: 0.7250 - val_loss: 1.3819 - val_accuracy: 0.3000 - 2s/epoch - 526ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 2s - loss: 1.0913 - accuracy: 0.4750 - val_loss: 1.3571 - val_accuracy: 0.3333 - 2s/epoch - 598ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 2s - loss: 0.9594 - accuracy: 0.6750 - val_loss: 1.4380 - val_accuracy: 0.2333 - 2s/epoch - 503ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 2s - loss: 0.8857 - accuracy: 0.5750 - val_loss: 1.3853 - val_accuracy: 0.2333 - 2s/epoch - 568ms/step\n",
            "Epoch 82/1000\n",
            "4/4 - 2s - loss: 0.9342 - accuracy: 0.5500 - val_loss: 1.3884 - val_accuracy: 0.3000 - 2s/epoch - 511ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 2s - loss: 0.8319 - accuracy: 0.7353 - val_loss: 1.3817 - val_accuracy: 0.2000 - 2s/epoch - 503ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 2s - loss: 0.9622 - accuracy: 0.6250 - val_loss: 1.4568 - val_accuracy: 0.1000 - 2s/epoch - 570ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 2s - loss: 0.8899 - accuracy: 0.7000 - val_loss: 1.4228 - val_accuracy: 0.2667 - 2s/epoch - 567ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 2s - loss: 0.7387 - accuracy: 0.7000 - val_loss: 1.4390 - val_accuracy: 0.2667 - 2s/epoch - 569ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 2s - loss: 0.7672 - accuracy: 0.7000 - val_loss: 1.5245 - val_accuracy: 0.1333 - 2s/epoch - 506ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 2s - loss: 0.8136 - accuracy: 0.5750 - val_loss: 1.4519 - val_accuracy: 0.1333 - 2s/epoch - 567ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 2s - loss: 1.0912 - accuracy: 0.6750 - val_loss: 1.4143 - val_accuracy: 0.3333 - 2s/epoch - 575ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 2s - loss: 1.1819 - accuracy: 0.4412 - val_loss: 1.3809 - val_accuracy: 0.2667 - 2s/epoch - 505ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 2s - loss: 0.9265 - accuracy: 0.6250 - val_loss: 1.4119 - val_accuracy: 0.2667 - 2s/epoch - 558ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 2s - loss: 0.8449 - accuracy: 0.7250 - val_loss: 1.4558 - val_accuracy: 0.2000 - 2s/epoch - 512ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 2s - loss: 1.1495 - accuracy: 0.4250 - val_loss: 1.3907 - val_accuracy: 0.2333 - 2s/epoch - 569ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 2s - loss: 0.9830 - accuracy: 0.6250 - val_loss: 1.4481 - val_accuracy: 0.2667 - 2s/epoch - 572ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 2s - loss: 0.7151 - accuracy: 0.7250 - val_loss: 1.3505 - val_accuracy: 0.3667 - 2s/epoch - 542ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 2s - loss: 0.5764 - accuracy: 0.7000 - val_loss: 1.5249 - val_accuracy: 0.1667 - 2s/epoch - 511ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 2s - loss: 0.7814 - accuracy: 0.6750 - val_loss: 1.2382 - val_accuracy: 0.4333 - 2s/epoch - 543ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 2s - loss: 0.9952 - accuracy: 0.5500 - val_loss: 1.4574 - val_accuracy: 0.3000 - 2s/epoch - 503ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 2s - loss: 0.8327 - accuracy: 0.5750 - val_loss: 1.4244 - val_accuracy: 0.2000 - 2s/epoch - 509ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 2s - loss: 0.6558 - accuracy: 0.7500 - val_loss: 1.4954 - val_accuracy: 0.1667 - 2s/epoch - 563ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 2s - loss: 0.8788 - accuracy: 0.6750 - val_loss: 1.3612 - val_accuracy: 0.3000 - 2s/epoch - 529ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 2s - loss: 0.7853 - accuracy: 0.7250 - val_loss: 1.2592 - val_accuracy: 0.4000 - 2s/epoch - 520ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 2s - loss: 0.7292 - accuracy: 0.6750 - val_loss: 1.4892 - val_accuracy: 0.2333 - 2s/epoch - 524ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 2s - loss: 0.8427 - accuracy: 0.6500 - val_loss: 1.5596 - val_accuracy: 0.1667 - 2s/epoch - 507ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 2s - loss: 0.4898 - accuracy: 0.7750 - val_loss: 1.3124 - val_accuracy: 0.3333 - 2s/epoch - 524ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 2s - loss: 0.6391 - accuracy: 0.7250 - val_loss: 1.5911 - val_accuracy: 0.2667 - 2s/epoch - 509ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 2s - loss: 0.8719 - accuracy: 0.6000 - val_loss: 1.6253 - val_accuracy: 0.2000 - 2s/epoch - 523ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 2s - loss: 0.5876 - accuracy: 0.8250 - val_loss: 1.4681 - val_accuracy: 0.2667 - 2s/epoch - 511ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 2s - loss: 0.6669 - accuracy: 0.7250 - val_loss: 1.3729 - val_accuracy: 0.3333 - 2s/epoch - 518ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 2s - loss: 0.6830 - accuracy: 0.7000 - val_loss: 1.5125 - val_accuracy: 0.2000 - 2s/epoch - 522ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 2s - loss: 0.6980 - accuracy: 0.7250 - val_loss: 1.5970 - val_accuracy: 0.2000 - 2s/epoch - 511ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 2s - loss: 0.5714 - accuracy: 0.7500 - val_loss: 1.4140 - val_accuracy: 0.2000 - 2s/epoch - 569ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 2s - loss: 0.3977 - accuracy: 0.8750 - val_loss: 1.4938 - val_accuracy: 0.3333 - 2s/epoch - 535ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 2s - loss: 0.7422 - accuracy: 0.7250 - val_loss: 1.5097 - val_accuracy: 0.4333 - 2s/epoch - 509ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 2s - loss: 0.9645 - accuracy: 0.5750 - val_loss: 1.6975 - val_accuracy: 0.2667 - 2s/epoch - 509ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 2s - loss: 0.6688 - accuracy: 0.7750 - val_loss: 2.0045 - val_accuracy: 0.1333 - 2s/epoch - 516ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 2s - loss: 0.4312 - accuracy: 0.8529 - val_loss: 1.5887 - val_accuracy: 0.2667 - 2s/epoch - 511ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 2s - loss: 0.8819 - accuracy: 0.7000 - val_loss: 1.5506 - val_accuracy: 0.3000 - 2s/epoch - 522ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 2s - loss: 0.6859 - accuracy: 0.6750 - val_loss: 1.4607 - val_accuracy: 0.3000 - 2s/epoch - 520ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 2s - loss: 0.6509 - accuracy: 0.7500 - val_loss: 1.5575 - val_accuracy: 0.3000 - 2s/epoch - 505ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 2s - loss: 0.7367 - accuracy: 0.7250 - val_loss: 1.6760 - val_accuracy: 0.2333 - 2s/epoch - 508ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 2s - loss: 0.5510 - accuracy: 0.7500 - val_loss: 1.4566 - val_accuracy: 0.3333 - 2s/epoch - 525ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 2s - loss: 0.9279 - accuracy: 0.6250 - val_loss: 1.3141 - val_accuracy: 0.4000 - 2s/epoch - 534ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 2s - loss: 0.7384 - accuracy: 0.6750 - val_loss: 1.7552 - val_accuracy: 0.3333 - 2s/epoch - 569ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 2s - loss: 0.6275 - accuracy: 0.7000 - val_loss: 1.5407 - val_accuracy: 0.3000 - 2s/epoch - 567ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 2s - loss: 0.3911 - accuracy: 0.8500 - val_loss: 1.4450 - val_accuracy: 0.4000 - 2s/epoch - 524ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 2s - loss: 1.0330 - accuracy: 0.4750 - val_loss: 2.0854 - val_accuracy: 0.2667 - 2s/epoch - 509ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 2s - loss: 0.6666 - accuracy: 0.6750 - val_loss: 1.2817 - val_accuracy: 0.4667 - 2s/epoch - 521ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 2s - loss: 0.6558 - accuracy: 0.7750 - val_loss: 1.9065 - val_accuracy: 0.2667 - 2s/epoch - 508ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 2s - loss: 0.6915 - accuracy: 0.7250 - val_loss: 1.6206 - val_accuracy: 0.3333 - 2s/epoch - 569ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 2s - loss: 0.5236 - accuracy: 0.8500 - val_loss: 1.4166 - val_accuracy: 0.3000 - 2s/epoch - 573ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 2s - loss: 0.4545 - accuracy: 0.7750 - val_loss: 1.4733 - val_accuracy: 0.3667 - 2s/epoch - 525ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 2s - loss: 0.5786 - accuracy: 0.8000 - val_loss: 1.4445 - val_accuracy: 0.4000 - 2s/epoch - 515ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 2s - loss: 0.4454 - accuracy: 0.8250 - val_loss: 1.5417 - val_accuracy: 0.4333 - 2s/epoch - 524ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 2s - loss: 0.4062 - accuracy: 0.8750 - val_loss: 1.7600 - val_accuracy: 0.3333 - 2s/epoch - 504ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 2s - loss: 0.6242 - accuracy: 0.7750 - val_loss: 1.3862 - val_accuracy: 0.4667 - 2s/epoch - 518ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 2s - loss: 0.4949 - accuracy: 0.8000 - val_loss: 1.5168 - val_accuracy: 0.5667 - 2s/epoch - 513ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 2s - loss: 0.4249 - accuracy: 0.9000 - val_loss: 1.5831 - val_accuracy: 0.3667 - 2s/epoch - 565ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 2s - loss: 0.5669 - accuracy: 0.7500 - val_loss: 1.4790 - val_accuracy: 0.4000 - 2s/epoch - 565ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 2s - loss: 0.7494 - accuracy: 0.7000 - val_loss: 1.1767 - val_accuracy: 0.5667 - 2s/epoch - 557ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 2s - loss: 0.7618 - accuracy: 0.6500 - val_loss: 1.6869 - val_accuracy: 0.4000 - 2s/epoch - 525ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 2s - loss: 0.6504 - accuracy: 0.7750 - val_loss: 1.7483 - val_accuracy: 0.3667 - 2s/epoch - 527ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 2s - loss: 0.4373 - accuracy: 0.8250 - val_loss: 1.5238 - val_accuracy: 0.4333 - 2s/epoch - 511ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 2s - loss: 0.5388 - accuracy: 0.8000 - val_loss: 2.0380 - val_accuracy: 0.3000 - 2s/epoch - 514ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 2s - loss: 0.6082 - accuracy: 0.7500 - val_loss: 1.5529 - val_accuracy: 0.4667 - 2s/epoch - 527ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 2s - loss: 0.8231 - accuracy: 0.6250 - val_loss: 1.1696 - val_accuracy: 0.5333 - 2s/epoch - 540ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 2s - loss: 0.6152 - accuracy: 0.7500 - val_loss: 1.5902 - val_accuracy: 0.4333 - 2s/epoch - 520ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 2s - loss: 0.6014 - accuracy: 0.7000 - val_loss: 1.4484 - val_accuracy: 0.4667 - 2s/epoch - 575ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 2s - loss: 0.7459 - accuracy: 0.7750 - val_loss: 1.5432 - val_accuracy: 0.4333 - 2s/epoch - 516ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 2s - loss: 0.7196 - accuracy: 0.7500 - val_loss: 1.4023 - val_accuracy: 0.5000 - 2s/epoch - 561ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 2s - loss: 0.5181 - accuracy: 0.8750 - val_loss: 1.3702 - val_accuracy: 0.4000 - 2s/epoch - 569ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 2s - loss: 0.8151 - accuracy: 0.7000 - val_loss: 1.3837 - val_accuracy: 0.5000 - 2s/epoch - 519ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 2s - loss: 0.5378 - accuracy: 0.8000 - val_loss: 1.4657 - val_accuracy: 0.4333 - 2s/epoch - 566ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 2s - loss: 0.4796 - accuracy: 0.7500 - val_loss: 1.4650 - val_accuracy: 0.3000 - 2s/epoch - 506ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 2s - loss: 0.5753 - accuracy: 0.8500 - val_loss: 1.5128 - val_accuracy: 0.3000 - 2s/epoch - 511ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 2s - loss: 0.3330 - accuracy: 0.8500 - val_loss: 1.2973 - val_accuracy: 0.3333 - 2s/epoch - 518ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 2s - loss: 0.6720 - accuracy: 0.7250 - val_loss: 1.2820 - val_accuracy: 0.4333 - 2s/epoch - 569ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 2s - loss: 0.5870 - accuracy: 0.7250 - val_loss: 1.0436 - val_accuracy: 0.6000 - 2s/epoch - 547ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 2s - loss: 0.3309 - accuracy: 0.8750 - val_loss: 1.1583 - val_accuracy: 0.6000 - 2s/epoch - 519ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 2s - loss: 0.4006 - accuracy: 0.8500 - val_loss: 1.2007 - val_accuracy: 0.4333 - 2s/epoch - 526ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 2s - loss: 0.6386 - accuracy: 0.8000 - val_loss: 1.0496 - val_accuracy: 0.5333 - 2s/epoch - 572ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 2s - loss: 0.4763 - accuracy: 0.8000 - val_loss: 1.2653 - val_accuracy: 0.6333 - 2s/epoch - 515ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 2s - loss: 0.5533 - accuracy: 0.8000 - val_loss: 1.7231 - val_accuracy: 0.3667 - 2s/epoch - 514ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 2s - loss: 0.5367 - accuracy: 0.8500 - val_loss: 0.8783 - val_accuracy: 0.7000 - 2s/epoch - 594ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 2s - loss: 0.3092 - accuracy: 0.8750 - val_loss: 0.7476 - val_accuracy: 0.7000 - 2s/epoch - 541ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 2s - loss: 0.3804 - accuracy: 0.9000 - val_loss: 0.9360 - val_accuracy: 0.5667 - 2s/epoch - 567ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 2s - loss: 0.5626 - accuracy: 0.8000 - val_loss: 0.6264 - val_accuracy: 0.8333 - 2s/epoch - 537ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 2s - loss: 0.4236 - accuracy: 0.8000 - val_loss: 0.7238 - val_accuracy: 0.6667 - 2s/epoch - 524ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 2s - loss: 0.4348 - accuracy: 0.8500 - val_loss: 0.8407 - val_accuracy: 0.6000 - 2s/epoch - 567ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 2s - loss: 0.4303 - accuracy: 0.8250 - val_loss: 0.6450 - val_accuracy: 0.6667 - 2s/epoch - 517ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 2s - loss: 0.4545 - accuracy: 0.8250 - val_loss: 0.9309 - val_accuracy: 0.5000 - 2s/epoch - 568ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 2s - loss: 0.5193 - accuracy: 0.8500 - val_loss: 0.7394 - val_accuracy: 0.7333 - 2s/epoch - 521ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 2s - loss: 0.3490 - accuracy: 0.8500 - val_loss: 0.7270 - val_accuracy: 0.7667 - 2s/epoch - 577ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 2s - loss: 0.5439 - accuracy: 0.8250 - val_loss: 1.4818 - val_accuracy: 0.4333 - 2s/epoch - 522ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 2s - loss: 0.3755 - accuracy: 0.8500 - val_loss: 0.9232 - val_accuracy: 0.5667 - 2s/epoch - 515ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 2s - loss: 0.4460 - accuracy: 0.8000 - val_loss: 0.7272 - val_accuracy: 0.7000 - 2s/epoch - 513ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 2s - loss: 0.3813 - accuracy: 0.8250 - val_loss: 0.8727 - val_accuracy: 0.5667 - 2s/epoch - 562ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 2s - loss: 0.6538 - accuracy: 0.7500 - val_loss: 0.7887 - val_accuracy: 0.6333 - 2s/epoch - 565ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 2s - loss: 0.5218 - accuracy: 0.7500 - val_loss: 0.4073 - val_accuracy: 0.8000 - 2s/epoch - 542ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 2s - loss: 0.4640 - accuracy: 0.8250 - val_loss: 1.0370 - val_accuracy: 0.6333 - 2s/epoch - 524ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 2s - loss: 0.8003 - accuracy: 0.6750 - val_loss: 0.8073 - val_accuracy: 0.6667 - 2s/epoch - 505ms/step\n",
            "Epoch 182/1000\n",
            "4/4 - 2s - loss: 0.3144 - accuracy: 0.8250 - val_loss: 0.5660 - val_accuracy: 0.8000 - 2s/epoch - 520ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 2s - loss: 0.5817 - accuracy: 0.7250 - val_loss: 0.9168 - val_accuracy: 0.6667 - 2s/epoch - 526ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 2s - loss: 0.4629 - accuracy: 0.8750 - val_loss: 0.9291 - val_accuracy: 0.5333 - 2s/epoch - 522ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 2s - loss: 0.3178 - accuracy: 0.9000 - val_loss: 0.7934 - val_accuracy: 0.6333 - 2s/epoch - 568ms/step\n",
            "Epoch 186/1000\n",
            "4/4 - 2s - loss: 0.7604 - accuracy: 0.7000 - val_loss: 0.7459 - val_accuracy: 0.7333 - 2s/epoch - 575ms/step\n",
            "Epoch 187/1000\n",
            "4/4 - 2s - loss: 0.3536 - accuracy: 0.8500 - val_loss: 0.6950 - val_accuracy: 0.7667 - 2s/epoch - 496ms/step\n",
            "Epoch 188/1000\n",
            "4/4 - 2s - loss: 0.3179 - accuracy: 0.9250 - val_loss: 0.6681 - val_accuracy: 0.7667 - 2s/epoch - 533ms/step\n",
            "Epoch 189/1000\n",
            "4/4 - 2s - loss: 0.3105 - accuracy: 0.9000 - val_loss: 0.4693 - val_accuracy: 0.8000 - 2s/epoch - 578ms/step\n",
            "Epoch 190/1000\n",
            "4/4 - 2s - loss: 0.2666 - accuracy: 0.9000 - val_loss: 0.8991 - val_accuracy: 0.6333 - 2s/epoch - 515ms/step\n",
            "Epoch 191/1000\n",
            "4/4 - 2s - loss: 0.4149 - accuracy: 0.8250 - val_loss: 0.4030 - val_accuracy: 0.8667 - 2s/epoch - 606ms/step\n",
            "Epoch 192/1000\n",
            "4/4 - 2s - loss: 0.4361 - accuracy: 0.8250 - val_loss: 1.1694 - val_accuracy: 0.6000 - 2s/epoch - 512ms/step\n",
            "Epoch 193/1000\n",
            "4/4 - 2s - loss: 0.4923 - accuracy: 0.7750 - val_loss: 0.6717 - val_accuracy: 0.8333 - 2s/epoch - 517ms/step\n",
            "Epoch 194/1000\n",
            "4/4 - 2s - loss: 0.3572 - accuracy: 0.8235 - val_loss: 0.8335 - val_accuracy: 0.7000 - 2s/epoch - 470ms/step\n",
            "Epoch 195/1000\n",
            "4/4 - 2s - loss: 0.4231 - accuracy: 0.8500 - val_loss: 0.7076 - val_accuracy: 0.6667 - 2s/epoch - 522ms/step\n",
            "Epoch 196/1000\n",
            "4/4 - 2s - loss: 0.6145 - accuracy: 0.8000 - val_loss: 0.5812 - val_accuracy: 0.8667 - 2s/epoch - 521ms/step\n",
            "Epoch 197/1000\n",
            "4/4 - 2s - loss: 0.4571 - accuracy: 0.8500 - val_loss: 0.7808 - val_accuracy: 0.8000 - 2s/epoch - 570ms/step\n",
            "Epoch 198/1000\n",
            "4/4 - 2s - loss: 0.5113 - accuracy: 0.8235 - val_loss: 0.9190 - val_accuracy: 0.6000 - 2s/epoch - 456ms/step\n",
            "Epoch 199/1000\n",
            "4/4 - 2s - loss: 0.3929 - accuracy: 0.9118 - val_loss: 1.4667 - val_accuracy: 0.5000 - 2s/epoch - 467ms/step\n",
            "Epoch 200/1000\n",
            "4/4 - 2s - loss: 0.3918 - accuracy: 0.9000 - val_loss: 0.5907 - val_accuracy: 0.8000 - 2s/epoch - 565ms/step\n",
            "Epoch 201/1000\n",
            "4/4 - 2s - loss: 0.5514 - accuracy: 0.8250 - val_loss: 0.8334 - val_accuracy: 0.7667 - 2s/epoch - 511ms/step\n",
            "Epoch 202/1000\n",
            "4/4 - 2s - loss: 0.3628 - accuracy: 0.9250 - val_loss: 1.1417 - val_accuracy: 0.6667 - 2s/epoch - 517ms/step\n",
            "Epoch 203/1000\n",
            "4/4 - 2s - loss: 0.5169 - accuracy: 0.8250 - val_loss: 0.7718 - val_accuracy: 0.7333 - 2s/epoch - 516ms/step\n",
            "Epoch 204/1000\n",
            "4/4 - 2s - loss: 0.4156 - accuracy: 0.8750 - val_loss: 1.0025 - val_accuracy: 0.7333 - 2s/epoch - 517ms/step\n",
            "Epoch 205/1000\n",
            "4/4 - 2s - loss: 0.3909 - accuracy: 0.8250 - val_loss: 1.0280 - val_accuracy: 0.5333 - 2s/epoch - 512ms/step\n",
            "Epoch 206/1000\n",
            "4/4 - 2s - loss: 0.3059 - accuracy: 0.8500 - val_loss: 0.7911 - val_accuracy: 0.7333 - 2s/epoch - 509ms/step\n",
            "Epoch 207/1000\n",
            "4/4 - 2s - loss: 0.5014 - accuracy: 0.8500 - val_loss: 0.4583 - val_accuracy: 0.9000 - 2s/epoch - 521ms/step\n",
            "Epoch 208/1000\n",
            "4/4 - 2s - loss: 0.8169 - accuracy: 0.6500 - val_loss: 0.5627 - val_accuracy: 0.8000 - 2s/epoch - 518ms/step\n",
            "Epoch 209/1000\n",
            "4/4 - 2s - loss: 0.2047 - accuracy: 0.9750 - val_loss: 0.9724 - val_accuracy: 0.6667 - 2s/epoch - 529ms/step\n",
            "Epoch 210/1000\n",
            "4/4 - 2s - loss: 0.1791 - accuracy: 0.9750 - val_loss: 0.9620 - val_accuracy: 0.6333 - 2s/epoch - 575ms/step\n",
            "Epoch 211/1000\n",
            "4/4 - 2s - loss: 0.4475 - accuracy: 0.8000 - val_loss: 0.6044 - val_accuracy: 0.8667 - 2s/epoch - 523ms/step\n",
            "Epoch 212/1000\n",
            "4/4 - 2s - loss: 0.3924 - accuracy: 0.8000 - val_loss: 0.8030 - val_accuracy: 0.6000 - 2s/epoch - 516ms/step\n",
            "Epoch 213/1000\n",
            "4/4 - 2s - loss: 0.5011 - accuracy: 0.8500 - val_loss: 1.2367 - val_accuracy: 0.5667 - 2s/epoch - 507ms/step\n",
            "Epoch 214/1000\n",
            "4/4 - 2s - loss: 0.3944 - accuracy: 0.8250 - val_loss: 0.4634 - val_accuracy: 0.8000 - 2s/epoch - 524ms/step\n",
            "Epoch 215/1000\n",
            "4/4 - 2s - loss: 0.5869 - accuracy: 0.8000 - val_loss: 0.9174 - val_accuracy: 0.7667 - 2s/epoch - 566ms/step\n",
            "Epoch 216/1000\n",
            "4/4 - 2s - loss: 0.5159 - accuracy: 0.9000 - val_loss: 0.5559 - val_accuracy: 0.7667 - 2s/epoch - 572ms/step\n",
            "Epoch 217/1000\n",
            "4/4 - 2s - loss: 0.1546 - accuracy: 0.9500 - val_loss: 0.2964 - val_accuracy: 0.9000 - 2s/epoch - 541ms/step\n",
            "Epoch 218/1000\n",
            "4/4 - 2s - loss: 0.3047 - accuracy: 0.9118 - val_loss: 0.9443 - val_accuracy: 0.7333 - 2s/epoch - 501ms/step\n",
            "Epoch 219/1000\n",
            "4/4 - 2s - loss: 0.3973 - accuracy: 0.8000 - val_loss: 0.7172 - val_accuracy: 0.8000 - 2s/epoch - 530ms/step\n",
            "Epoch 220/1000\n",
            "4/4 - 2s - loss: 0.4231 - accuracy: 0.8750 - val_loss: 0.6566 - val_accuracy: 0.8333 - 2s/epoch - 568ms/step\n",
            "Epoch 221/1000\n",
            "4/4 - 2s - loss: 0.1828 - accuracy: 0.9750 - val_loss: 1.0796 - val_accuracy: 0.6000 - 2s/epoch - 520ms/step\n",
            "Epoch 222/1000\n",
            "4/4 - 2s - loss: 0.7797 - accuracy: 0.7500 - val_loss: 0.6597 - val_accuracy: 0.8333 - 2s/epoch - 500ms/step\n",
            "Epoch 223/1000\n",
            "4/4 - 2s - loss: 0.3165 - accuracy: 0.9000 - val_loss: 1.0519 - val_accuracy: 0.6667 - 2s/epoch - 524ms/step\n",
            "Epoch 224/1000\n",
            "4/4 - 2s - loss: 0.4532 - accuracy: 0.8750 - val_loss: 1.1799 - val_accuracy: 0.6667 - 2s/epoch - 517ms/step\n",
            "Epoch 225/1000\n",
            "4/4 - 2s - loss: 0.3223 - accuracy: 0.8750 - val_loss: 0.8606 - val_accuracy: 0.6333 - 2s/epoch - 524ms/step\n",
            "Epoch 226/1000\n",
            "4/4 - 2s - loss: 0.4170 - accuracy: 0.8500 - val_loss: 0.6200 - val_accuracy: 0.7667 - 2s/epoch - 515ms/step\n",
            "Epoch 227/1000\n",
            "4/4 - 2s - loss: 0.3625 - accuracy: 0.9250 - val_loss: 0.7601 - val_accuracy: 0.7000 - 2s/epoch - 574ms/step\n",
            "Epoch 228/1000\n",
            "4/4 - 2s - loss: 0.2942 - accuracy: 0.8750 - val_loss: 0.5307 - val_accuracy: 0.8333 - 2s/epoch - 567ms/step\n",
            "Epoch 229/1000\n",
            "4/4 - 2s - loss: 0.4030 - accuracy: 0.8750 - val_loss: 1.8455 - val_accuracy: 0.6667 - 2s/epoch - 528ms/step\n",
            "Epoch 230/1000\n",
            "4/4 - 2s - loss: 0.3954 - accuracy: 0.8500 - val_loss: 0.9946 - val_accuracy: 0.7333 - 2s/epoch - 570ms/step\n",
            "Epoch 231/1000\n",
            "4/4 - 2s - loss: 0.2835 - accuracy: 0.9250 - val_loss: 1.1179 - val_accuracy: 0.6667 - 2s/epoch - 513ms/step\n",
            "Epoch 232/1000\n",
            "4/4 - 2s - loss: 0.4172 - accuracy: 0.8500 - val_loss: 0.8179 - val_accuracy: 0.7667 - 2s/epoch - 518ms/step\n",
            "Epoch 233/1000\n",
            "4/4 - 2s - loss: 0.2851 - accuracy: 0.9118 - val_loss: 0.8308 - val_accuracy: 0.7000 - 2s/epoch - 529ms/step\n",
            "Epoch 234/1000\n",
            "4/4 - 2s - loss: 0.3076 - accuracy: 0.9000 - val_loss: 0.9768 - val_accuracy: 0.7000 - 2s/epoch - 512ms/step\n",
            "Epoch 235/1000\n",
            "4/4 - 2s - loss: 0.4281 - accuracy: 0.8000 - val_loss: 1.2472 - val_accuracy: 0.6667 - 2s/epoch - 562ms/step\n",
            "Epoch 236/1000\n",
            "4/4 - 2s - loss: 0.2636 - accuracy: 0.9000 - val_loss: 0.9828 - val_accuracy: 0.7000 - 2s/epoch - 565ms/step\n",
            "Epoch 237/1000\n",
            "4/4 - 2s - loss: 0.2739 - accuracy: 0.8750 - val_loss: 1.2406 - val_accuracy: 0.6000 - 2s/epoch - 524ms/step\n",
            "Epoch 238/1000\n",
            "4/4 - 2s - loss: 0.4003 - accuracy: 0.8250 - val_loss: 1.2757 - val_accuracy: 0.6333 - 2s/epoch - 573ms/step\n",
            "Epoch 239/1000\n",
            "4/4 - 2s - loss: 0.2398 - accuracy: 0.9500 - val_loss: 0.4264 - val_accuracy: 0.9000 - 2s/epoch - 569ms/step\n",
            "Epoch 240/1000\n",
            "4/4 - 2s - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.8667 - 2s/epoch - 547ms/step\n",
            "Epoch 241/1000\n",
            "4/4 - 2s - loss: 0.3840 - accuracy: 0.8750 - val_loss: 0.8908 - val_accuracy: 0.7667 - 2s/epoch - 521ms/step\n",
            "Epoch 242/1000\n",
            "4/4 - 2s - loss: 0.4843 - accuracy: 0.8000 - val_loss: 0.8716 - val_accuracy: 0.8333 - 2s/epoch - 514ms/step\n",
            "Epoch 243/1000\n",
            "4/4 - 2s - loss: 0.4990 - accuracy: 0.8000 - val_loss: 0.5796 - val_accuracy: 0.7667 - 2s/epoch - 567ms/step\n",
            "Epoch 244/1000\n",
            "4/4 - 2s - loss: 0.3806 - accuracy: 0.9000 - val_loss: 0.5442 - val_accuracy: 0.8667 - 2s/epoch - 502ms/step\n",
            "Epoch 245/1000\n",
            "4/4 - 2s - loss: 0.3162 - accuracy: 0.9000 - val_loss: 1.1133 - val_accuracy: 0.6333 - 2s/epoch - 562ms/step\n",
            "Epoch 246/1000\n",
            "4/4 - 2s - loss: 0.3576 - accuracy: 0.9250 - val_loss: 0.6905 - val_accuracy: 0.7000 - 2s/epoch - 519ms/step\n",
            "Epoch 247/1000\n",
            "4/4 - 2s - loss: 0.1792 - accuracy: 0.9500 - val_loss: 0.5925 - val_accuracy: 0.8000 - 2s/epoch - 507ms/step\n",
            "Epoch 248/1000\n",
            "4/4 - 2s - loss: 0.4212 - accuracy: 0.8235 - val_loss: 0.8566 - val_accuracy: 0.6667 - 2s/epoch - 470ms/step\n",
            "Epoch 249/1000\n",
            "4/4 - 2s - loss: 0.2512 - accuracy: 0.9250 - val_loss: 0.8438 - val_accuracy: 0.7333 - 2s/epoch - 569ms/step\n",
            "Epoch 250/1000\n",
            "4/4 - 2s - loss: 0.2187 - accuracy: 0.9250 - val_loss: 0.8950 - val_accuracy: 0.7000 - 2s/epoch - 518ms/step\n",
            "Epoch 251/1000\n",
            "4/4 - 2s - loss: 0.2939 - accuracy: 0.8750 - val_loss: 0.8637 - val_accuracy: 0.6667 - 2s/epoch - 514ms/step\n",
            "Epoch 252/1000\n",
            "4/4 - 2s - loss: 0.4563 - accuracy: 0.9250 - val_loss: 1.7090 - val_accuracy: 0.5000 - 2s/epoch - 513ms/step\n",
            "Epoch 253/1000\n",
            "4/4 - 2s - loss: 0.4378 - accuracy: 0.7750 - val_loss: 1.5185 - val_accuracy: 0.5333 - 2s/epoch - 516ms/step\n",
            "Epoch 254/1000\n",
            "4/4 - 2s - loss: 0.4149 - accuracy: 0.8250 - val_loss: 0.7100 - val_accuracy: 0.8667 - 2s/epoch - 527ms/step\n",
            "Epoch 255/1000\n",
            "4/4 - 2s - loss: 0.5266 - accuracy: 0.8250 - val_loss: 0.8698 - val_accuracy: 0.7333 - 2s/epoch - 499ms/step\n",
            "Epoch 256/1000\n",
            "4/4 - 2s - loss: 0.2693 - accuracy: 0.9250 - val_loss: 0.5881 - val_accuracy: 0.8333 - 2s/epoch - 521ms/step\n",
            "Epoch 257/1000\n",
            "4/4 - 2s - loss: 0.4455 - accuracy: 0.8000 - val_loss: 0.8442 - val_accuracy: 0.7000 - 2s/epoch - 568ms/step\n",
            "Epoch 258/1000\n",
            "4/4 - 2s - loss: 0.4295 - accuracy: 0.8750 - val_loss: 0.8946 - val_accuracy: 0.6333 - 2s/epoch - 514ms/step\n",
            "Epoch 259/1000\n",
            "4/4 - 2s - loss: 0.1801 - accuracy: 0.9750 - val_loss: 1.4949 - val_accuracy: 0.6667 - 2s/epoch - 570ms/step\n",
            "Epoch 260/1000\n",
            "4/4 - 2s - loss: 0.3946 - accuracy: 0.8000 - val_loss: 0.7657 - val_accuracy: 0.8000 - 2s/epoch - 501ms/step\n",
            "Epoch 261/1000\n",
            "4/4 - 2s - loss: 0.1753 - accuracy: 0.9500 - val_loss: 1.4739 - val_accuracy: 0.6667 - 2s/epoch - 568ms/step\n",
            "Epoch 262/1000\n",
            "4/4 - 2s - loss: 0.3604 - accuracy: 0.9250 - val_loss: 0.9566 - val_accuracy: 0.6667 - 2s/epoch - 527ms/step\n",
            "Epoch 263/1000\n",
            "4/4 - 2s - loss: 0.1636 - accuracy: 0.9250 - val_loss: 1.0432 - val_accuracy: 0.6000 - 2s/epoch - 517ms/step\n",
            "Epoch 264/1000\n",
            "4/4 - 2s - loss: 0.2381 - accuracy: 0.9000 - val_loss: 1.2976 - val_accuracy: 0.6333 - 2s/epoch - 567ms/step\n",
            "Epoch 265/1000\n",
            "4/4 - 2s - loss: 0.4518 - accuracy: 0.8250 - val_loss: 1.1323 - val_accuracy: 0.5667 - 2s/epoch - 511ms/step\n",
            "Epoch 266/1000\n",
            "4/4 - 2s - loss: 0.3485 - accuracy: 0.9000 - val_loss: 1.4325 - val_accuracy: 0.7000 - 2s/epoch - 571ms/step\n",
            "Epoch 267/1000\n",
            "4/4 - 2s - loss: 0.2254 - accuracy: 0.9750 - val_loss: 0.7709 - val_accuracy: 0.7000 - 2s/epoch - 566ms/step\n",
            "Epoch 268/1000\n",
            "4/4 - 2s - loss: 0.3395 - accuracy: 0.8500 - val_loss: 1.0468 - val_accuracy: 0.6667 - 2s/epoch - 568ms/step\n",
            "Epoch 269/1000\n",
            "4/4 - 2s - loss: 0.1478 - accuracy: 0.9750 - val_loss: 0.8861 - val_accuracy: 0.6333 - 2s/epoch - 526ms/step\n",
            "Epoch 270/1000\n",
            "4/4 - 2s - loss: 0.2978 - accuracy: 0.9250 - val_loss: 0.5606 - val_accuracy: 0.7667 - 2s/epoch - 525ms/step\n",
            "Epoch 271/1000\n",
            "4/4 - 2s - loss: 0.3109 - accuracy: 0.9000 - val_loss: 0.8979 - val_accuracy: 0.8000 - 2s/epoch - 513ms/step\n",
            "Epoch 272/1000\n",
            "4/4 - 2s - loss: 0.3426 - accuracy: 0.8750 - val_loss: 0.8128 - val_accuracy: 0.7000 - 2s/epoch - 564ms/step\n",
            "Epoch 273/1000\n",
            "4/4 - 2s - loss: 0.5664 - accuracy: 0.8250 - val_loss: 0.9009 - val_accuracy: 0.7333 - 2s/epoch - 507ms/step\n",
            "Epoch 274/1000\n",
            "4/4 - 2s - loss: 0.1869 - accuracy: 0.9500 - val_loss: 0.6514 - val_accuracy: 0.7667 - 2s/epoch - 574ms/step\n",
            "Epoch 275/1000\n",
            "4/4 - 2s - loss: 0.2636 - accuracy: 0.9250 - val_loss: 0.7765 - val_accuracy: 0.7333 - 2s/epoch - 519ms/step\n",
            "Epoch 276/1000\n",
            "4/4 - 2s - loss: 0.2726 - accuracy: 0.9250 - val_loss: 1.0722 - val_accuracy: 0.6333 - 2s/epoch - 527ms/step\n",
            "Epoch 277/1000\n",
            "4/4 - 2s - loss: 0.3477 - accuracy: 0.8000 - val_loss: 0.4292 - val_accuracy: 0.8000 - 2s/epoch - 521ms/step\n",
            "Epoch 278/1000\n",
            "4/4 - 2s - loss: 0.2402 - accuracy: 0.8750 - val_loss: 1.2263 - val_accuracy: 0.6333 - 2s/epoch - 525ms/step\n",
            "Epoch 279/1000\n",
            "4/4 - 2s - loss: 0.1709 - accuracy: 0.9250 - val_loss: 0.7107 - val_accuracy: 0.8000 - 2s/epoch - 524ms/step\n",
            "Epoch 280/1000\n",
            "4/4 - 2s - loss: 0.1775 - accuracy: 0.9250 - val_loss: 0.9968 - val_accuracy: 0.7333 - 2s/epoch - 519ms/step\n",
            "Epoch 281/1000\n",
            "4/4 - 2s - loss: 0.3049 - accuracy: 0.9000 - val_loss: 1.0030 - val_accuracy: 0.7000 - 2s/epoch - 515ms/step\n",
            "Epoch 282/1000\n",
            "4/4 - 2s - loss: 0.4501 - accuracy: 0.9000 - val_loss: 0.7043 - val_accuracy: 0.7667 - 2s/epoch - 565ms/step\n",
            "Epoch 283/1000\n",
            "4/4 - 2s - loss: 0.2123 - accuracy: 0.9000 - val_loss: 0.8367 - val_accuracy: 0.8000 - 2s/epoch - 569ms/step\n",
            "Epoch 284/1000\n",
            "4/4 - 2s - loss: 0.3922 - accuracy: 0.8750 - val_loss: 0.9576 - val_accuracy: 0.7667 - 2s/epoch - 518ms/step\n",
            "Epoch 285/1000\n",
            "4/4 - 2s - loss: 0.2464 - accuracy: 0.9000 - val_loss: 0.6944 - val_accuracy: 0.7333 - 2s/epoch - 517ms/step\n",
            "Epoch 286/1000\n",
            "4/4 - 2s - loss: 0.2518 - accuracy: 0.8750 - val_loss: 1.0202 - val_accuracy: 0.7000 - 2s/epoch - 520ms/step\n",
            "Epoch 287/1000\n",
            "4/4 - 2s - loss: 0.2727 - accuracy: 0.8750 - val_loss: 0.4445 - val_accuracy: 0.8667 - 2s/epoch - 504ms/step\n",
            "Epoch 288/1000\n",
            "4/4 - 2s - loss: 0.1098 - accuracy: 0.9750 - val_loss: 0.4168 - val_accuracy: 0.9000 - 2s/epoch - 564ms/step\n",
            "Epoch 289/1000\n",
            "4/4 - 2s - loss: 0.4458 - accuracy: 0.8250 - val_loss: 1.8128 - val_accuracy: 0.6667 - 2s/epoch - 507ms/step\n",
            "Epoch 290/1000\n",
            "4/4 - 2s - loss: 0.4925 - accuracy: 0.8250 - val_loss: 1.0379 - val_accuracy: 0.6333 - 2s/epoch - 528ms/step\n",
            "Epoch 291/1000\n",
            "4/4 - 2s - loss: 0.1657 - accuracy: 0.9250 - val_loss: 1.2868 - val_accuracy: 0.7000 - 2s/epoch - 516ms/step\n",
            "Epoch 292/1000\n",
            "4/4 - 2s - loss: 0.2537 - accuracy: 0.8750 - val_loss: 1.6039 - val_accuracy: 0.6000 - 2s/epoch - 521ms/step\n",
            "Epoch 293/1000\n",
            "4/4 - 2s - loss: 0.4569 - accuracy: 0.8750 - val_loss: 2.3770 - val_accuracy: 0.5333 - 2s/epoch - 564ms/step\n",
            "Epoch 294/1000\n",
            "4/4 - 2s - loss: 0.4375 - accuracy: 0.8750 - val_loss: 0.7488 - val_accuracy: 0.6667 - 2s/epoch - 526ms/step\n",
            "Epoch 295/1000\n",
            "4/4 - 2s - loss: 0.2646 - accuracy: 0.9000 - val_loss: 0.8024 - val_accuracy: 0.7333 - 2s/epoch - 507ms/step\n",
            "Epoch 296/1000\n",
            "4/4 - 2s - loss: 0.2564 - accuracy: 0.9000 - val_loss: 1.9923 - val_accuracy: 0.5000 - 2s/epoch - 524ms/step\n",
            "Epoch 297/1000\n",
            "4/4 - 2s - loss: 0.1953 - accuracy: 0.9250 - val_loss: 0.5236 - val_accuracy: 0.8333 - 2s/epoch - 515ms/step\n",
            "Epoch 298/1000\n",
            "4/4 - 2s - loss: 0.2161 - accuracy: 0.9500 - val_loss: 0.6758 - val_accuracy: 0.8333 - 2s/epoch - 570ms/step\n",
            "Epoch 299/1000\n",
            "4/4 - 2s - loss: 0.2370 - accuracy: 0.9000 - val_loss: 0.9159 - val_accuracy: 0.8000 - 2s/epoch - 567ms/step\n",
            "Epoch 300/1000\n",
            "4/4 - 2s - loss: 0.1682 - accuracy: 0.9500 - val_loss: 0.5973 - val_accuracy: 0.8333 - 2s/epoch - 570ms/step\n",
            "Epoch 301/1000\n",
            "4/4 - 2s - loss: 0.3143 - accuracy: 0.8750 - val_loss: 0.7905 - val_accuracy: 0.7000 - 2s/epoch - 510ms/step\n",
            "Epoch 302/1000\n",
            "4/4 - 2s - loss: 0.1523 - accuracy: 0.9500 - val_loss: 1.0822 - val_accuracy: 0.7667 - 2s/epoch - 511ms/step\n",
            "Epoch 303/1000\n",
            "4/4 - 2s - loss: 0.1623 - accuracy: 0.9250 - val_loss: 0.3331 - val_accuracy: 0.8667 - 2s/epoch - 498ms/step\n",
            "Epoch 304/1000\n",
            "4/4 - 2s - loss: 0.4437 - accuracy: 0.9000 - val_loss: 0.6682 - val_accuracy: 0.7333 - 2s/epoch - 562ms/step\n",
            "Epoch 305/1000\n",
            "4/4 - 2s - loss: 0.1214 - accuracy: 0.9750 - val_loss: 0.8156 - val_accuracy: 0.7667 - 2s/epoch - 503ms/step\n",
            "Epoch 306/1000\n",
            "4/4 - 2s - loss: 0.2095 - accuracy: 0.9000 - val_loss: 0.9002 - val_accuracy: 0.7667 - 2s/epoch - 509ms/step\n",
            "Epoch 307/1000\n",
            "4/4 - 2s - loss: 0.3490 - accuracy: 0.9000 - val_loss: 0.9175 - val_accuracy: 0.7333 - 2s/epoch - 507ms/step\n",
            "Epoch 308/1000\n",
            "4/4 - 2s - loss: 0.1617 - accuracy: 0.9250 - val_loss: 1.5527 - val_accuracy: 0.6333 - 2s/epoch - 569ms/step\n",
            "Epoch 309/1000\n",
            "4/4 - 2s - loss: 0.1516 - accuracy: 0.9250 - val_loss: 1.2955 - val_accuracy: 0.7000 - 2s/epoch - 516ms/step\n",
            "Epoch 310/1000\n",
            "4/4 - 2s - loss: 0.5240 - accuracy: 0.8750 - val_loss: 1.2896 - val_accuracy: 0.7333 - 2s/epoch - 573ms/step\n",
            "Epoch 311/1000\n",
            "4/4 - 2s - loss: 0.1744 - accuracy: 0.9000 - val_loss: 0.6107 - val_accuracy: 0.7667 - 2s/epoch - 569ms/step\n",
            "Epoch 312/1000\n",
            "4/4 - 2s - loss: 0.1998 - accuracy: 0.9500 - val_loss: 2.0732 - val_accuracy: 0.5667 - 2s/epoch - 520ms/step\n",
            "Epoch 313/1000\n",
            "4/4 - 2s - loss: 0.1552 - accuracy: 0.9500 - val_loss: 1.4389 - val_accuracy: 0.5333 - 2s/epoch - 525ms/step\n",
            "Epoch 314/1000\n",
            "4/4 - 2s - loss: 0.1993 - accuracy: 0.9250 - val_loss: 3.3951 - val_accuracy: 0.3667 - 2s/epoch - 561ms/step\n",
            "Epoch 315/1000\n",
            "4/4 - 2s - loss: 0.2927 - accuracy: 0.8500 - val_loss: 0.9553 - val_accuracy: 0.7333 - 2s/epoch - 568ms/step\n",
            "Epoch 316/1000\n",
            "4/4 - 2s - loss: 0.1710 - accuracy: 0.9500 - val_loss: 1.2731 - val_accuracy: 0.7000 - 2s/epoch - 564ms/step\n",
            "Epoch 317/1000\n",
            "4/4 - 2s - loss: 0.1901 - accuracy: 0.9250 - val_loss: 1.0320 - val_accuracy: 0.7000 - 2s/epoch - 567ms/step\n",
            "Epoch 318/1000\n",
            "4/4 - 2s - loss: 0.2061 - accuracy: 0.9500 - val_loss: 0.5857 - val_accuracy: 0.8333 - 2s/epoch - 515ms/step\n",
            "Epoch 319/1000\n",
            "4/4 - 2s - loss: 0.1853 - accuracy: 0.9412 - val_loss: 0.8333 - val_accuracy: 0.8333 - 2s/epoch - 452ms/step\n",
            "Epoch 320/1000\n",
            "4/4 - 2s - loss: 0.0967 - accuracy: 0.9500 - val_loss: 0.7703 - val_accuracy: 0.7000 - 2s/epoch - 509ms/step\n",
            "Epoch 321/1000\n",
            "4/4 - 2s - loss: 0.1748 - accuracy: 0.9250 - val_loss: 0.3765 - val_accuracy: 0.8000 - 2s/epoch - 507ms/step\n",
            "Epoch 322/1000\n",
            "4/4 - 2s - loss: 0.1102 - accuracy: 0.9750 - val_loss: 2.1967 - val_accuracy: 0.5000 - 2s/epoch - 520ms/step\n",
            "Epoch 323/1000\n",
            "4/4 - 2s - loss: 0.4137 - accuracy: 0.8500 - val_loss: 0.6636 - val_accuracy: 0.7667 - 2s/epoch - 511ms/step\n",
            "Epoch 324/1000\n",
            "4/4 - 2s - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.6438 - val_accuracy: 0.7333 - 2s/epoch - 557ms/step\n",
            "Epoch 325/1000\n",
            "4/4 - 2s - loss: 0.3692 - accuracy: 0.8750 - val_loss: 1.0143 - val_accuracy: 0.7000 - 2s/epoch - 572ms/step\n",
            "Epoch 326/1000\n",
            "4/4 - 2s - loss: 0.2221 - accuracy: 0.9000 - val_loss: 0.8148 - val_accuracy: 0.7333 - 2s/epoch - 568ms/step\n",
            "Epoch 327/1000\n",
            "4/4 - 2s - loss: 0.2427 - accuracy: 0.9250 - val_loss: 1.1679 - val_accuracy: 0.7000 - 2s/epoch - 567ms/step\n",
            "Epoch 328/1000\n",
            "4/4 - 2s - loss: 0.2820 - accuracy: 0.9250 - val_loss: 0.6693 - val_accuracy: 0.7667 - 2s/epoch - 566ms/step\n",
            "Epoch 329/1000\n",
            "4/4 - 2s - loss: 0.1539 - accuracy: 0.9250 - val_loss: 0.6644 - val_accuracy: 0.7333 - 2s/epoch - 524ms/step\n",
            "Epoch 330/1000\n",
            "4/4 - 2s - loss: 0.2693 - accuracy: 0.8500 - val_loss: 1.0270 - val_accuracy: 0.7333 - 2s/epoch - 509ms/step\n",
            "Epoch 331/1000\n",
            "4/4 - 2s - loss: 0.1800 - accuracy: 0.9500 - val_loss: 1.0658 - val_accuracy: 0.7333 - 2s/epoch - 513ms/step\n",
            "Epoch 332/1000\n",
            "4/4 - 2s - loss: 0.1604 - accuracy: 0.9500 - val_loss: 1.3581 - val_accuracy: 0.7000 - 2s/epoch - 512ms/step\n",
            "Epoch 333/1000\n",
            "4/4 - 2s - loss: 0.2063 - accuracy: 0.9250 - val_loss: 0.8438 - val_accuracy: 0.7667 - 2s/epoch - 515ms/step\n",
            "Epoch 334/1000\n",
            "4/4 - 2s - loss: 0.2155 - accuracy: 0.9000 - val_loss: 1.3471 - val_accuracy: 0.5667 - 2s/epoch - 498ms/step\n",
            "Epoch 335/1000\n",
            "4/4 - 2s - loss: 0.1742 - accuracy: 0.9250 - val_loss: 0.4930 - val_accuracy: 0.8000 - 2s/epoch - 513ms/step\n",
            "Epoch 336/1000\n",
            "4/4 - 2s - loss: 0.2244 - accuracy: 0.9500 - val_loss: 0.5540 - val_accuracy: 0.7333 - 2s/epoch - 512ms/step\n",
            "Epoch 337/1000\n",
            "4/4 - 2s - loss: 0.2114 - accuracy: 0.9250 - val_loss: 0.7666 - val_accuracy: 0.7667 - 2s/epoch - 567ms/step\n",
            "Epoch 338/1000\n",
            "4/4 - 2s - loss: 0.5168 - accuracy: 0.8750 - val_loss: 1.3205 - val_accuracy: 0.7000 - 2s/epoch - 514ms/step\n",
            "Epoch 339/1000\n",
            "4/4 - 2s - loss: 0.2920 - accuracy: 0.9000 - val_loss: 2.3694 - val_accuracy: 0.6667 - 2s/epoch - 502ms/step\n",
            "Epoch 340/1000\n",
            "4/4 - 2s - loss: 0.1464 - accuracy: 0.9500 - val_loss: 1.0100 - val_accuracy: 0.6667 - 2s/epoch - 513ms/step\n",
            "Epoch 341/1000\n",
            "4/4 - 2s - loss: 0.2179 - accuracy: 0.9250 - val_loss: 0.9035 - val_accuracy: 0.7667 - 2s/epoch - 516ms/step\n",
            "Epoch 342/1000\n",
            "4/4 - 2s - loss: 0.1258 - accuracy: 0.9750 - val_loss: 1.4984 - val_accuracy: 0.5667 - 2s/epoch - 504ms/step\n",
            "Epoch 343/1000\n",
            "4/4 - 2s - loss: 0.1406 - accuracy: 0.9500 - val_loss: 1.5836 - val_accuracy: 0.7333 - 2s/epoch - 567ms/step\n",
            "Epoch 344/1000\n",
            "4/4 - 2s - loss: 0.3140 - accuracy: 0.8750 - val_loss: 1.1632 - val_accuracy: 0.6000 - 2s/epoch - 516ms/step\n",
            "Epoch 345/1000\n",
            "4/4 - 2s - loss: 0.2075 - accuracy: 0.9250 - val_loss: 1.5697 - val_accuracy: 0.4667 - 2s/epoch - 511ms/step\n",
            "Epoch 346/1000\n",
            "4/4 - 2s - loss: 0.1289 - accuracy: 0.9750 - val_loss: 0.6753 - val_accuracy: 0.8333 - 2s/epoch - 502ms/step\n",
            "Epoch 347/1000\n",
            "4/4 - 2s - loss: 0.2786 - accuracy: 0.9250 - val_loss: 1.1607 - val_accuracy: 0.7000 - 2s/epoch - 506ms/step\n",
            "Epoch 348/1000\n",
            "4/4 - 2s - loss: 0.3772 - accuracy: 0.9000 - val_loss: 0.6399 - val_accuracy: 0.7667 - 2s/epoch - 520ms/step\n",
            "Epoch 349/1000\n",
            "4/4 - 2s - loss: 0.0834 - accuracy: 0.9750 - val_loss: 0.8952 - val_accuracy: 0.7333 - 2s/epoch - 571ms/step\n",
            "Epoch 350/1000\n",
            "4/4 - 2s - loss: 0.2055 - accuracy: 0.9000 - val_loss: 0.9645 - val_accuracy: 0.6333 - 2s/epoch - 563ms/step\n",
            "Epoch 351/1000\n",
            "4/4 - 2s - loss: 0.2933 - accuracy: 0.9000 - val_loss: 0.3098 - val_accuracy: 0.9333 - 2s/epoch - 570ms/step\n",
            "Epoch 352/1000\n",
            "4/4 - 2s - loss: 0.3189 - accuracy: 0.9250 - val_loss: 1.2979 - val_accuracy: 0.7333 - 2s/epoch - 571ms/step\n",
            "Epoch 353/1000\n",
            "4/4 - 2s - loss: 0.1095 - accuracy: 0.9750 - val_loss: 0.8327 - val_accuracy: 0.7667 - 2s/epoch - 565ms/step\n",
            "Epoch 354/1000\n",
            "4/4 - 2s - loss: 0.1817 - accuracy: 0.9250 - val_loss: 0.5201 - val_accuracy: 0.7667 - 2s/epoch - 508ms/step\n",
            "Epoch 355/1000\n",
            "4/4 - 2s - loss: 0.1438 - accuracy: 0.9500 - val_loss: 0.8104 - val_accuracy: 0.7667 - 2s/epoch - 564ms/step\n",
            "Epoch 356/1000\n",
            "4/4 - 2s - loss: 0.2739 - accuracy: 0.8750 - val_loss: 0.7785 - val_accuracy: 0.7000 - 2s/epoch - 515ms/step\n",
            "Epoch 357/1000\n",
            "4/4 - 2s - loss: 0.2505 - accuracy: 0.9250 - val_loss: 1.9115 - val_accuracy: 0.7000 - 2s/epoch - 520ms/step\n",
            "Epoch 358/1000\n",
            "4/4 - 2s - loss: 0.0910 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.6333 - 2s/epoch - 575ms/step\n",
            "Epoch 359/1000\n",
            "4/4 - 2s - loss: 0.3331 - accuracy: 0.9250 - val_loss: 1.4801 - val_accuracy: 0.7667 - 2s/epoch - 566ms/step\n",
            "Epoch 360/1000\n",
            "4/4 - 2s - loss: 0.0403 - accuracy: 1.0000 - val_loss: 1.3072 - val_accuracy: 0.6333 - 2s/epoch - 509ms/step\n",
            "Epoch 361/1000\n",
            "4/4 - 2s - loss: 0.2994 - accuracy: 0.9250 - val_loss: 3.2587 - val_accuracy: 0.5667 - 2s/epoch - 529ms/step\n",
            "Epoch 362/1000\n",
            "4/4 - 2s - loss: 0.3218 - accuracy: 0.8750 - val_loss: 1.5088 - val_accuracy: 0.6667 - 2s/epoch - 505ms/step\n",
            "Epoch 363/1000\n",
            "4/4 - 2s - loss: 0.4059 - accuracy: 0.8250 - val_loss: 0.7976 - val_accuracy: 0.6667 - 2s/epoch - 515ms/step\n",
            "Epoch 364/1000\n",
            "4/4 - 2s - loss: 0.2482 - accuracy: 0.9250 - val_loss: 2.1380 - val_accuracy: 0.6333 - 2s/epoch - 574ms/step\n",
            "Epoch 365/1000\n",
            "4/4 - 2s - loss: 0.1024 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.8000 - 2s/epoch - 572ms/step\n",
            "Epoch 366/1000\n",
            "4/4 - 2s - loss: 0.1077 - accuracy: 0.9750 - val_loss: 1.0727 - val_accuracy: 0.7000 - 2s/epoch - 518ms/step\n",
            "Epoch 367/1000\n",
            "4/4 - 2s - loss: 0.1548 - accuracy: 0.9412 - val_loss: 2.7387 - val_accuracy: 0.7000 - 2s/epoch - 467ms/step\n",
            "Epoch 368/1000\n",
            "4/4 - 2s - loss: 0.1184 - accuracy: 0.9750 - val_loss: 0.6980 - val_accuracy: 0.7333 - 2s/epoch - 568ms/step\n",
            "Epoch 369/1000\n",
            "4/4 - 2s - loss: 0.2186 - accuracy: 0.9250 - val_loss: 3.3559 - val_accuracy: 0.6333 - 2s/epoch - 567ms/step\n",
            "Epoch 370/1000\n",
            "4/4 - 2s - loss: 0.1161 - accuracy: 0.9750 - val_loss: 1.5702 - val_accuracy: 0.7000 - 2s/epoch - 512ms/step\n",
            "Epoch 371/1000\n",
            "4/4 - 2s - loss: 0.1136 - accuracy: 0.9750 - val_loss: 1.8374 - val_accuracy: 0.6000 - 2s/epoch - 559ms/step\n",
            "Epoch 372/1000\n",
            "4/4 - 2s - loss: 0.2527 - accuracy: 0.8750 - val_loss: 1.9072 - val_accuracy: 0.6333 - 2s/epoch - 564ms/step\n",
            "Epoch 373/1000\n",
            "4/4 - 2s - loss: 0.4176 - accuracy: 0.7750 - val_loss: 2.5561 - val_accuracy: 0.6333 - 2s/epoch - 567ms/step\n",
            "Epoch 374/1000\n",
            "4/4 - 2s - loss: 0.1380 - accuracy: 0.9500 - val_loss: 1.3515 - val_accuracy: 0.7000 - 2s/epoch - 566ms/step\n",
            "Epoch 375/1000\n",
            "4/4 - 2s - loss: 0.0604 - accuracy: 1.0000 - val_loss: 3.0431 - val_accuracy: 0.6333 - 2s/epoch - 567ms/step\n",
            "Epoch 376/1000\n",
            "4/4 - 2s - loss: 0.2546 - accuracy: 0.9250 - val_loss: 1.0750 - val_accuracy: 0.7667 - 2s/epoch - 504ms/step\n",
            "Epoch 377/1000\n",
            "4/4 - 2s - loss: 0.1979 - accuracy: 0.9500 - val_loss: 1.0164 - val_accuracy: 0.7333 - 2s/epoch - 509ms/step\n",
            "Epoch 378/1000\n",
            "4/4 - 2s - loss: 0.1259 - accuracy: 0.9750 - val_loss: 0.9040 - val_accuracy: 0.7000 - 2s/epoch - 532ms/step\n",
            "Epoch 379/1000\n",
            "4/4 - 2s - loss: 0.2161 - accuracy: 0.9250 - val_loss: 2.7047 - val_accuracy: 0.6333 - 2s/epoch - 523ms/step\n",
            "Epoch 380/1000\n",
            "4/4 - 2s - loss: 0.4852 - accuracy: 0.7750 - val_loss: 4.0444 - val_accuracy: 0.5000 - 2s/epoch - 563ms/step\n",
            "Epoch 381/1000\n",
            "4/4 - 2s - loss: 0.3510 - accuracy: 0.8500 - val_loss: 1.1013 - val_accuracy: 0.7667 - 2s/epoch - 569ms/step\n",
            "Epoch 382/1000\n",
            "4/4 - 2s - loss: 0.2806 - accuracy: 0.8750 - val_loss: 1.5651 - val_accuracy: 0.6667 - 2s/epoch - 515ms/step\n",
            "Epoch 383/1000\n",
            "4/4 - 2s - loss: 0.3949 - accuracy: 0.9000 - val_loss: 1.3586 - val_accuracy: 0.7000 - 2s/epoch - 571ms/step\n",
            "Epoch 384/1000\n",
            "4/4 - 2s - loss: 0.1116 - accuracy: 0.9750 - val_loss: 0.9452 - val_accuracy: 0.8000 - 2s/epoch - 514ms/step\n",
            "Epoch 385/1000\n",
            "4/4 - 2s - loss: 0.1536 - accuracy: 0.9500 - val_loss: 1.5607 - val_accuracy: 0.6333 - 2s/epoch - 507ms/step\n",
            "Epoch 386/1000\n",
            "4/4 - 2s - loss: 0.1098 - accuracy: 0.9750 - val_loss: 1.6083 - val_accuracy: 0.6667 - 2s/epoch - 520ms/step\n",
            "Epoch 387/1000\n",
            "4/4 - 2s - loss: 0.1864 - accuracy: 0.9500 - val_loss: 2.8125 - val_accuracy: 0.7000 - 2s/epoch - 513ms/step\n",
            "Epoch 388/1000\n",
            "4/4 - 2s - loss: 0.1278 - accuracy: 0.9750 - val_loss: 1.3278 - val_accuracy: 0.6667 - 2s/epoch - 517ms/step\n",
            "Epoch 389/1000\n",
            "4/4 - 2s - loss: 0.0985 - accuracy: 1.0000 - val_loss: 1.1514 - val_accuracy: 0.7000 - 2s/epoch - 530ms/step\n",
            "Epoch 390/1000\n",
            "Restoring model weights from the end of the best epoch: 240.\n",
            "4/4 - 2s - loss: 0.3014 - accuracy: 0.9000 - val_loss: 2.5796 - val_accuracy: 0.5333 - 2s/epoch - 572ms/step\n",
            "Epoch 390: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Callback to save the current best model\n",
        "epochs = 1000\n",
        "patience = epochs\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=150, mode='min', verbose=1, restore_best_weights=True),\n",
        "    #CustomEarlyStopping(patience=patience),\n",
        "    #tf.keras.callbacks.ModelCheckpoint(filepath='batik-recognition-model.{epoch:03d}.hdf5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=False),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "]\n",
        "\n",
        "# Using Batch Gradient Descent (batch_size = training_examples) because data is less than 2000\n",
        "# Stochastic Gradient Descent (batch_size = 1)\n",
        "# Mini-Batch Gradient Descent (batch_size = 1 < number_power_of_2 < training_examples)\n",
        "# steps per epoch = 18\n",
        "# validation steps = 3\n",
        "history = xception.fit(train_batches, \n",
        "                        steps_per_epoch=4, \n",
        "                        batch_size=training_examples, \n",
        "                        validation_data=valid_batches, \n",
        "                        validation_steps=2, \n",
        "                        epochs=epochs, verbose=2, \n",
        "                        callbacks=my_callbacks, \n",
        "                        shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "_YjotpcCY1WW"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path):\n",
        "    data = load_files(path)\n",
        "    paths = np.array(data['filenames'])\n",
        "    targets = np_utils.to_categorical(np.array(data['target']))\n",
        "    return paths, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "2e-ZFqEaY1WX"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "\n",
        "test_files, test_targets = load_dataset(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "YZTRmdooUOCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d85abf-546e-4ae7-9fa4-151dab1530d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 160/160 [00:01<00:00, 152.31it/s]\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import image  \n",
        "from tqdm import tqdm\n",
        "\n",
        "def path_to_tensor(img_path):\n",
        "    img = image.load_img(img_path, target_size=(299, 299))\n",
        "    x = image.img_to_array(img)\n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "def paths_to_tensor(img_paths):\n",
        "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
        "    return np.vstack(list_of_tensors)\n",
        "\n",
        "test_tensors = preprocess_input(paths_to_tensor(test_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "UNOvbJI0UQyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61d4d48-0165-4718-c229-aa71dce000be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 2s 282ms/step - loss: 2.8259 - accuracy: 0.3625\n",
            "\n",
            "Testing loss: 2.8259\n",
            "Testing accuracy: 0.3625\n"
          ]
        }
      ],
      "source": [
        "# Model Testing\n",
        "# if you want to select the model yourself, uncomment the next line and change the filename as the one you choose\n",
        "# new_model.load_weights('filename.hdf5')\n",
        "\n",
        "print('\\nTesting loss: {:.4f}\\nTesting accuracy: {:.4f}'.format(*xception.evaluate(test_tensors, test_targets)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "RrCuxDCuUTW6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "19f0293f-a60c-4650-f1e2-74be63d6aab6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Confussion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm_labels = ['Batik Liong','Jamplrang', 'Terang Bulan', 'Tujuh Rupa']\n",
        "\n",
        "y_true = np.argmax(test_targets, axis=1)\n",
        "y_pred = np.argmax(xception.predict(test_tensors), axis=1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "indexes = np.arange(len(cm_labels))\n",
        "for i in indexes:\n",
        "    for j in indexes:\n",
        "        plt.text(j, i, cm[i, j])\n",
        "plt.xticks(indexes, cm_labels, rotation=90)\n",
        "plt.xlabel('Predicted label')\n",
        "plt.yticks(indexes, cm_labels)\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix, Early Stopping Best Model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "EsqYNyL1UYkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a260b45-17cb-4370-d8b0-cef00786ce4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " Batik Liong       0.52      0.30      0.38        40\n",
            "   Jamplrang       0.30      0.72      0.42        40\n",
            "Terang Bulan       0.44      0.38      0.41        40\n",
            "  Tujuh Rupa       0.33      0.05      0.09        40\n",
            "\n",
            "    accuracy                           0.36       160\n",
            "   macro avg       0.40      0.36      0.32       160\n",
            "weighted avg       0.40      0.36      0.32       160\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.argmax(test_targets, axis=1), np.argmax(xception.predict(test_tensors), axis=1), target_names=cm_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "cuRuiTk340rK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ad0b94-fd24-4243-8a71-22a43b5cf8ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.52201533, 0.56050572, 0.56180513, 0.21984843])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "# Geometric Mean\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "geometric_mean_score(y_true, y_pred, pos_label=1, average=None, correction=0.0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Xception_4_Kelas.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "55b315c3dbf10ef7f12b59bd8ad1fda37f03e8048b8c0ccbc36f7a976bce2219"
    },
    "kernelspec": {
      "display_name": "Python 3.8.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}