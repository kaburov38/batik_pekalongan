{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xyalPcwY1WO",
        "outputId": "dd29e1be-b873-40e8-e959-7870fc4f3322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import Dataset\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import os\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from keras.applications.xception import preprocess_input\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import drive\n",
        "\n",
        "# Accessing My Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Ewrz5ZgaY1WQ"
      },
      "outputs": [],
      "source": [
        "# Location Path\n",
        "train_path  = 'drive/My Drive/data pekalongan/raw/train'\n",
        "valid_path  = 'drive/My Drive/data pekalongan/raw/valid'\n",
        "test_path  = 'drive/My Drive/data pekalongan/raw/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKHn3IwRY1WQ",
        "outputId": "80155098-43fb-4ff9-8d69-d28f1f7405f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1844 images belonging to 4 classes.\n",
            "Found 160 images belonging to 4 classes.\n",
            "Found 160 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rescale=1./127.5-1.,\n",
        ")\n",
        "\n",
        "# Train, Test, Validation\n",
        "train_batches = datagen.flow_from_directory(\n",
        "    train_path, target_size=(299,299), batch_size=10)\n",
        "valid_batches = datagen.flow_from_directory(\n",
        "    valid_path, target_size=(299,299), batch_size=15)\n",
        "test_batches = datagen.flow_from_directory(\n",
        "    test_path, target_size=(299,299), batch_size=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aL1hquC-Q5D",
        "outputId": "c453b855-f409-458d-9cf5-f3b8e162a256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([(0, 456), (1, 470), (2, 460), (3, 458)])\n",
            "1844\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "samples = Counter(train_batches.classes)\n",
        "\n",
        "print(samples.items()) # dict_items([(0, 1648), (1, 3614)])\n",
        "\n",
        "training_examples = 0;\n",
        "for item in samples.items():\n",
        "    training_examples += item[1]\n",
        "\n",
        "print(training_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "I5HE-0el3iXp"
      },
      "outputs": [],
      "source": [
        "def entry_flow(inputs):\n",
        "\n",
        "  x = layers.Conv2D(32, 3, strides=2, padding='same')(inputs)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  previous_block_activation = x  # Set aside residual\n",
        "  \n",
        "  # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "  for size in [128, 256, 728]:\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "    \n",
        "    residual = layers.Conv2D(  # Project residual\n",
        "        size, 1, strides=2, padding='same')(previous_block_activation)           \n",
        "    x = layers.add([x, residual])  # Add back residual\n",
        "    previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "def middle_flow(x, num_blocks=8):\n",
        "  \n",
        "  previous_block_activation = x\n",
        "\n",
        "  for _ in range(num_blocks):\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.add([x, previous_block_activation])  # Add back residual\n",
        "    previous_block_activation = x  # Set aside next residual\n",
        "    \n",
        "  return x\n",
        "\n",
        "\n",
        "def exit_flow(x, num_classes=1000):\n",
        "  \n",
        "  previous_block_activation = x\n",
        "\n",
        "  x = layers.Activation('relu')(x)\n",
        "  x = layers.SeparableConv2D(728, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "\n",
        "  x = layers.Activation('relu')(x)\n",
        "  x = layers.SeparableConv2D(1024, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  \n",
        "  x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "  residual = layers.Conv2D(  # Project residual\n",
        "      1024, 1, strides=2, padding='same')(previous_block_activation)\n",
        "  x = layers.add([x, residual])  # Add back residual\n",
        "  \n",
        "  x = layers.SeparableConv2D(1536, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "  \n",
        "  x = layers.SeparableConv2D(2048, 3, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "  \n",
        "  x = layers.GlobalAveragePooling2D()(x)\n",
        "  if num_classes == 1:\n",
        "    activation = 'sigmoid'\n",
        "  else:\n",
        "    activation = 'softmax'\n",
        "  return layers.Dense(num_classes, activation=activation)(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "d4_96LWHY1WU"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "# Create Xception by chaining the 3 flows\n",
        "inputs = keras.Input(shape=(299, 299, 3))\n",
        "outputs = exit_flow(middle_flow(entry_flow(inputs), num_blocks=8), num_classes=4)\n",
        "xception = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "E9_jGuo9sPYi"
      },
      "outputs": [],
      "source": [
        "# Custom Early Stopping\n",
        "# Expected behavior: EarlyStopping should restore weights on end of training regardless it stop training early or after the last epoch\n",
        "\n",
        "class CustomEarlyStopping(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, patience=0):\n",
        "        super(CustomEarlyStopping, self).__init__()\n",
        "        self.patience = patience\n",
        "        self.best_weights = None\n",
        "        \n",
        "    def on_train_begin(self, logs=None):\n",
        "        # The number of epoch it has waited when loss is no longer minimum.\n",
        "        self.wait = 0\n",
        "        # The epoch the training stops at.\n",
        "        self.stopped_epoch = 0\n",
        "        # Initialize the best as infinity.\n",
        "        self.best_val_loss = np.Inf\n",
        "        self.best_loss = np.Inf\n",
        "        self.best_val_accuracy = 0.0\n",
        "        self.best_accuracy = 0.0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        val_loss = logs.get('val_loss')\n",
        "        loss = logs.get('loss')\n",
        "        val_accuracy = logs.get('val_accuracy')\n",
        "        accuracy = logs.get('accuracy')\n",
        "\n",
        "        # if np.less(val_loss, self.best_val_loss) and np.greater(map10, self.best_map10):\n",
        "        if np.greater_equal(val_accuracy, self.best_val_accuracy) and np.greater_equal(accuracy, self.best_accuracy) and np.greater_equal(accuracy, val_accuracy):\n",
        "            self.best_val_loss = val_loss\n",
        "            self.best_loss = loss\n",
        "            self.best_val_accuracy = val_accuracy\n",
        "            self.best_accuracy = accuracy\n",
        "            self.wait = 0\n",
        "\n",
        "            # Record the best weights if current results is better.\n",
        "            print(\"Saving the best weight at epoch {}\".format(epoch + 1))\n",
        "            self.best_weights = self.model.get_weights()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                print(\"Training stop early. Restoring model weights from the end of the best epoch.\")\n",
        "                self.model.set_weights(self.best_weights)\n",
        "                \n",
        "    def on_train_end(self, logs=None):\n",
        "        # EarlyStopping will restore weights after the last epoch only if it is not stop early\n",
        "        if self.stopped_epoch > 0:\n",
        "            print(\"Epoch {}: early stopping\".format(self.stopped_epoch + 1))\n",
        "        else:\n",
        "            print(\"Training stop after the last epoch. Restoring model weights from the end of the best epoch.\")\n",
        "            self.model.set_weights(self.best_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "dg2toYR8Y1WV"
      },
      "outputs": [],
      "source": [
        "xception.compile(RMSprop(learning_rate=3e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp-gJ4L7Y1WW",
        "outputId": "f5ab3adc-4a02-46e2-e103-25a38a7b9981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "4/4 - 14s - loss: 2.2320 - accuracy: 0.1750 - val_loss: 1.3858 - val_accuracy: 0.2667 - 14s/epoch - 4s/step\n",
            "Epoch 2/1000\n",
            "4/4 - 4s - loss: 2.3658 - accuracy: 0.2250 - val_loss: 1.3864 - val_accuracy: 0.2000 - 4s/epoch - 976ms/step\n",
            "Epoch 3/1000\n",
            "4/4 - 3s - loss: 1.6384 - accuracy: 0.3500 - val_loss: 1.3873 - val_accuracy: 0.2333 - 3s/epoch - 735ms/step\n",
            "Epoch 4/1000\n",
            "4/4 - 4s - loss: 1.6168 - accuracy: 0.3250 - val_loss: 1.3842 - val_accuracy: 0.3333 - 4s/epoch - 1s/step\n",
            "Epoch 5/1000\n",
            "4/4 - 4s - loss: 1.5187 - accuracy: 0.3000 - val_loss: 1.3854 - val_accuracy: 0.3000 - 4s/epoch - 955ms/step\n",
            "Epoch 6/1000\n",
            "4/4 - 4s - loss: 1.2278 - accuracy: 0.4500 - val_loss: 1.3843 - val_accuracy: 0.2333 - 4s/epoch - 920ms/step\n",
            "Epoch 7/1000\n",
            "4/4 - 4s - loss: 1.3211 - accuracy: 0.4000 - val_loss: 1.3868 - val_accuracy: 0.2333 - 4s/epoch - 878ms/step\n",
            "Epoch 8/1000\n",
            "4/4 - 5s - loss: 1.3101 - accuracy: 0.3500 - val_loss: 1.3836 - val_accuracy: 0.3667 - 5s/epoch - 1s/step\n",
            "Epoch 9/1000\n",
            "4/4 - 5s - loss: 1.5389 - accuracy: 0.3250 - val_loss: 1.3891 - val_accuracy: 0.2000 - 5s/epoch - 1s/step\n",
            "Epoch 10/1000\n",
            "4/4 - 3s - loss: 1.4478 - accuracy: 0.3500 - val_loss: 1.3853 - val_accuracy: 0.3667 - 3s/epoch - 841ms/step\n",
            "Epoch 11/1000\n",
            "4/4 - 4s - loss: 1.4430 - accuracy: 0.2750 - val_loss: 1.3850 - val_accuracy: 0.4000 - 4s/epoch - 1s/step\n",
            "Epoch 12/1000\n",
            "4/4 - 4s - loss: 1.3389 - accuracy: 0.3250 - val_loss: 1.3849 - val_accuracy: 0.2000 - 4s/epoch - 1s/step\n",
            "Epoch 13/1000\n",
            "4/4 - 3s - loss: 1.4307 - accuracy: 0.3500 - val_loss: 1.3856 - val_accuracy: 0.2000 - 3s/epoch - 872ms/step\n",
            "Epoch 14/1000\n",
            "4/4 - 4s - loss: 1.3496 - accuracy: 0.4250 - val_loss: 1.3838 - val_accuracy: 0.3000 - 4s/epoch - 1s/step\n",
            "Epoch 15/1000\n",
            "4/4 - 3s - loss: 1.2210 - accuracy: 0.4750 - val_loss: 1.3846 - val_accuracy: 0.3333 - 3s/epoch - 772ms/step\n",
            "Epoch 16/1000\n",
            "4/4 - 3s - loss: 1.4639 - accuracy: 0.2500 - val_loss: 1.3877 - val_accuracy: 0.2000 - 3s/epoch - 768ms/step\n",
            "Epoch 17/1000\n",
            "4/4 - 3s - loss: 1.3723 - accuracy: 0.2750 - val_loss: 1.3855 - val_accuracy: 0.2000 - 3s/epoch - 771ms/step\n",
            "Epoch 18/1000\n",
            "4/4 - 3s - loss: 1.3274 - accuracy: 0.4250 - val_loss: 1.3871 - val_accuracy: 0.2667 - 3s/epoch - 739ms/step\n",
            "Epoch 19/1000\n",
            "4/4 - 3s - loss: 1.5097 - accuracy: 0.3250 - val_loss: 1.3881 - val_accuracy: 0.2667 - 3s/epoch - 769ms/step\n",
            "Epoch 20/1000\n",
            "4/4 - 3s - loss: 1.1542 - accuracy: 0.5750 - val_loss: 1.3818 - val_accuracy: 0.2000 - 3s/epoch - 782ms/step\n",
            "Epoch 21/1000\n",
            "4/4 - 4s - loss: 1.2928 - accuracy: 0.5000 - val_loss: 1.3896 - val_accuracy: 0.2000 - 4s/epoch - 1s/step\n",
            "Epoch 22/1000\n",
            "4/4 - 4s - loss: 1.2668 - accuracy: 0.4750 - val_loss: 1.3849 - val_accuracy: 0.2333 - 4s/epoch - 906ms/step\n",
            "Epoch 23/1000\n",
            "4/4 - 3s - loss: 1.3024 - accuracy: 0.4500 - val_loss: 1.3928 - val_accuracy: 0.2000 - 3s/epoch - 749ms/step\n",
            "Epoch 24/1000\n",
            "4/4 - 3s - loss: 1.3219 - accuracy: 0.4250 - val_loss: 1.3870 - val_accuracy: 0.2000 - 3s/epoch - 774ms/step\n",
            "Epoch 25/1000\n",
            "4/4 - 4s - loss: 1.1169 - accuracy: 0.5250 - val_loss: 1.3896 - val_accuracy: 0.1333 - 4s/epoch - 890ms/step\n",
            "Epoch 26/1000\n",
            "4/4 - 4s - loss: 1.2733 - accuracy: 0.5500 - val_loss: 1.3861 - val_accuracy: 0.3000 - 4s/epoch - 908ms/step\n",
            "Epoch 27/1000\n",
            "4/4 - 3s - loss: 1.3278 - accuracy: 0.3250 - val_loss: 1.3908 - val_accuracy: 0.2000 - 3s/epoch - 765ms/step\n",
            "Epoch 28/1000\n",
            "4/4 - 3s - loss: 1.2854 - accuracy: 0.3750 - val_loss: 1.3881 - val_accuracy: 0.1667 - 3s/epoch - 786ms/step\n",
            "Epoch 29/1000\n",
            "4/4 - 4s - loss: 1.3912 - accuracy: 0.3500 - val_loss: 1.3816 - val_accuracy: 0.3000 - 4s/epoch - 910ms/step\n",
            "Epoch 30/1000\n",
            "4/4 - 3s - loss: 1.2627 - accuracy: 0.3500 - val_loss: 1.3918 - val_accuracy: 0.2333 - 3s/epoch - 791ms/step\n",
            "Epoch 31/1000\n",
            "4/4 - 3s - loss: 1.2893 - accuracy: 0.4500 - val_loss: 1.3860 - val_accuracy: 0.2667 - 3s/epoch - 766ms/step\n",
            "Epoch 32/1000\n",
            "4/4 - 3s - loss: 1.2269 - accuracy: 0.5750 - val_loss: 1.3915 - val_accuracy: 0.2000 - 3s/epoch - 769ms/step\n",
            "Epoch 33/1000\n",
            "4/4 - 3s - loss: 1.2538 - accuracy: 0.5000 - val_loss: 1.3878 - val_accuracy: 0.2333 - 3s/epoch - 774ms/step\n",
            "Epoch 34/1000\n",
            "4/4 - 3s - loss: 1.0680 - accuracy: 0.4750 - val_loss: 1.3825 - val_accuracy: 0.3000 - 3s/epoch - 804ms/step\n",
            "Epoch 35/1000\n",
            "4/4 - 4s - loss: 1.2960 - accuracy: 0.4750 - val_loss: 1.3805 - val_accuracy: 0.3333 - 4s/epoch - 928ms/step\n",
            "Epoch 36/1000\n",
            "4/4 - 3s - loss: 1.3271 - accuracy: 0.4000 - val_loss: 1.3855 - val_accuracy: 0.2000 - 3s/epoch - 755ms/step\n",
            "Epoch 37/1000\n",
            "4/4 - 3s - loss: 1.4047 - accuracy: 0.4000 - val_loss: 1.3889 - val_accuracy: 0.2000 - 3s/epoch - 759ms/step\n",
            "Epoch 38/1000\n",
            "4/4 - 3s - loss: 1.2138 - accuracy: 0.5000 - val_loss: 1.3827 - val_accuracy: 0.3333 - 3s/epoch - 775ms/step\n",
            "Epoch 39/1000\n",
            "4/4 - 3s - loss: 1.2281 - accuracy: 0.3500 - val_loss: 1.3762 - val_accuracy: 0.3667 - 3s/epoch - 812ms/step\n",
            "Epoch 40/1000\n",
            "4/4 - 4s - loss: 1.1991 - accuracy: 0.5250 - val_loss: 1.3751 - val_accuracy: 0.3667 - 4s/epoch - 898ms/step\n",
            "Epoch 41/1000\n",
            "4/4 - 3s - loss: 1.1496 - accuracy: 0.4750 - val_loss: 1.3947 - val_accuracy: 0.1000 - 3s/epoch - 764ms/step\n",
            "Epoch 42/1000\n",
            "4/4 - 3s - loss: 1.2844 - accuracy: 0.4000 - val_loss: 1.3913 - val_accuracy: 0.2333 - 3s/epoch - 742ms/step\n",
            "Epoch 43/1000\n",
            "4/4 - 3s - loss: 1.0872 - accuracy: 0.5000 - val_loss: 1.3752 - val_accuracy: 0.3667 - 3s/epoch - 777ms/step\n",
            "Epoch 44/1000\n",
            "4/4 - 3s - loss: 1.4541 - accuracy: 0.3750 - val_loss: 1.3934 - val_accuracy: 0.2667 - 3s/epoch - 757ms/step\n",
            "Epoch 45/1000\n",
            "4/4 - 3s - loss: 1.1929 - accuracy: 0.3750 - val_loss: 1.3884 - val_accuracy: 0.2667 - 3s/epoch - 751ms/step\n",
            "Epoch 46/1000\n",
            "4/4 - 3s - loss: 1.1941 - accuracy: 0.4250 - val_loss: 1.3916 - val_accuracy: 0.2667 - 3s/epoch - 775ms/step\n",
            "Epoch 47/1000\n",
            "4/4 - 3s - loss: 1.2404 - accuracy: 0.4750 - val_loss: 1.3774 - val_accuracy: 0.4333 - 3s/epoch - 761ms/step\n",
            "Epoch 48/1000\n",
            "4/4 - 3s - loss: 1.2351 - accuracy: 0.5500 - val_loss: 1.3882 - val_accuracy: 0.2333 - 3s/epoch - 768ms/step\n",
            "Epoch 49/1000\n",
            "4/4 - 3s - loss: 0.9925 - accuracy: 0.6250 - val_loss: 1.3934 - val_accuracy: 0.2333 - 3s/epoch - 868ms/step\n",
            "Epoch 50/1000\n",
            "4/4 - 3s - loss: 0.9943 - accuracy: 0.6500 - val_loss: 1.3724 - val_accuracy: 0.4000 - 3s/epoch - 802ms/step\n",
            "Epoch 51/1000\n",
            "4/4 - 3s - loss: 1.3356 - accuracy: 0.4000 - val_loss: 1.3841 - val_accuracy: 0.2667 - 3s/epoch - 739ms/step\n",
            "Epoch 52/1000\n",
            "4/4 - 3s - loss: 1.3171 - accuracy: 0.4500 - val_loss: 1.3948 - val_accuracy: 0.2000 - 3s/epoch - 866ms/step\n",
            "Epoch 53/1000\n",
            "4/4 - 3s - loss: 1.1629 - accuracy: 0.5250 - val_loss: 1.3759 - val_accuracy: 0.3667 - 3s/epoch - 758ms/step\n",
            "Epoch 54/1000\n",
            "4/4 - 3s - loss: 1.2646 - accuracy: 0.4500 - val_loss: 1.4149 - val_accuracy: 0.1333 - 3s/epoch - 790ms/step\n",
            "Epoch 55/1000\n",
            "4/4 - 3s - loss: 1.0198 - accuracy: 0.6000 - val_loss: 1.3885 - val_accuracy: 0.2333 - 3s/epoch - 736ms/step\n",
            "Epoch 56/1000\n",
            "4/4 - 4s - loss: 1.1397 - accuracy: 0.5000 - val_loss: 1.3938 - val_accuracy: 0.2667 - 4s/epoch - 898ms/step\n",
            "Epoch 57/1000\n",
            "4/4 - 3s - loss: 1.2240 - accuracy: 0.5500 - val_loss: 1.3798 - val_accuracy: 0.2333 - 3s/epoch - 756ms/step\n",
            "Epoch 58/1000\n",
            "4/4 - 3s - loss: 1.3259 - accuracy: 0.4250 - val_loss: 1.4070 - val_accuracy: 0.2333 - 3s/epoch - 775ms/step\n",
            "Epoch 59/1000\n",
            "4/4 - 3s - loss: 1.1472 - accuracy: 0.5500 - val_loss: 1.3836 - val_accuracy: 0.3000 - 3s/epoch - 784ms/step\n",
            "Epoch 60/1000\n",
            "4/4 - 3s - loss: 1.0185 - accuracy: 0.4500 - val_loss: 1.3805 - val_accuracy: 0.2667 - 3s/epoch - 768ms/step\n",
            "Epoch 61/1000\n",
            "4/4 - 4s - loss: 1.3785 - accuracy: 0.4250 - val_loss: 1.3822 - val_accuracy: 0.3333 - 4s/epoch - 1s/step\n",
            "Epoch 62/1000\n",
            "4/4 - 3s - loss: 1.2288 - accuracy: 0.3250 - val_loss: 1.3953 - val_accuracy: 0.2000 - 3s/epoch - 791ms/step\n",
            "Epoch 63/1000\n",
            "4/4 - 3s - loss: 1.1016 - accuracy: 0.5500 - val_loss: 1.3795 - val_accuracy: 0.3000 - 3s/epoch - 747ms/step\n",
            "Epoch 64/1000\n",
            "4/4 - 3s - loss: 1.0280 - accuracy: 0.6500 - val_loss: 1.3791 - val_accuracy: 0.3000 - 3s/epoch - 796ms/step\n",
            "Epoch 65/1000\n",
            "4/4 - 3s - loss: 1.1716 - accuracy: 0.5000 - val_loss: 1.4004 - val_accuracy: 0.2667 - 3s/epoch - 844ms/step\n",
            "Epoch 66/1000\n",
            "4/4 - 3s - loss: 1.2714 - accuracy: 0.4500 - val_loss: 1.4030 - val_accuracy: 0.2000 - 3s/epoch - 773ms/step\n",
            "Epoch 67/1000\n",
            "4/4 - 3s - loss: 1.2416 - accuracy: 0.5500 - val_loss: 1.3991 - val_accuracy: 0.2667 - 3s/epoch - 777ms/step\n",
            "Epoch 68/1000\n",
            "4/4 - 3s - loss: 1.2050 - accuracy: 0.4750 - val_loss: 1.3621 - val_accuracy: 0.3000 - 3s/epoch - 791ms/step\n",
            "Epoch 69/1000\n",
            "4/4 - 3s - loss: 0.8229 - accuracy: 0.6750 - val_loss: 1.3891 - val_accuracy: 0.3000 - 3s/epoch - 780ms/step\n",
            "Epoch 70/1000\n",
            "4/4 - 3s - loss: 1.1350 - accuracy: 0.4250 - val_loss: 1.3889 - val_accuracy: 0.3000 - 3s/epoch - 748ms/step\n",
            "Epoch 71/1000\n",
            "4/4 - 3s - loss: 1.0888 - accuracy: 0.5250 - val_loss: 1.3857 - val_accuracy: 0.3333 - 3s/epoch - 786ms/step\n",
            "Epoch 72/1000\n",
            "4/4 - 3s - loss: 1.0646 - accuracy: 0.5750 - val_loss: 1.3854 - val_accuracy: 0.2333 - 3s/epoch - 777ms/step\n",
            "Epoch 73/1000\n",
            "4/4 - 3s - loss: 1.2659 - accuracy: 0.4250 - val_loss: 1.4103 - val_accuracy: 0.1333 - 3s/epoch - 746ms/step\n",
            "Epoch 74/1000\n",
            "4/4 - 3s - loss: 1.2751 - accuracy: 0.5250 - val_loss: 1.4161 - val_accuracy: 0.1667 - 3s/epoch - 744ms/step\n",
            "Epoch 75/1000\n",
            "4/4 - 3s - loss: 1.2309 - accuracy: 0.5250 - val_loss: 1.3948 - val_accuracy: 0.1667 - 3s/epoch - 745ms/step\n",
            "Epoch 76/1000\n",
            "4/4 - 3s - loss: 1.1003 - accuracy: 0.5500 - val_loss: 1.3917 - val_accuracy: 0.2333 - 3s/epoch - 757ms/step\n",
            "Epoch 77/1000\n",
            "4/4 - 3s - loss: 1.2103 - accuracy: 0.4750 - val_loss: 1.4011 - val_accuracy: 0.3000 - 3s/epoch - 767ms/step\n",
            "Epoch 78/1000\n",
            "4/4 - 3s - loss: 1.1488 - accuracy: 0.5000 - val_loss: 1.3763 - val_accuracy: 0.3333 - 3s/epoch - 767ms/step\n",
            "Epoch 79/1000\n",
            "4/4 - 3s - loss: 1.0582 - accuracy: 0.4750 - val_loss: 1.3861 - val_accuracy: 0.2667 - 3s/epoch - 738ms/step\n",
            "Epoch 80/1000\n",
            "4/4 - 3s - loss: 1.0188 - accuracy: 0.5000 - val_loss: 1.3617 - val_accuracy: 0.3667 - 3s/epoch - 771ms/step\n",
            "Epoch 81/1000\n",
            "4/4 - 4s - loss: 1.1524 - accuracy: 0.4706 - val_loss: 1.3493 - val_accuracy: 0.3667 - 4s/epoch - 1s/step\n",
            "Epoch 82/1000\n",
            "4/4 - 3s - loss: 1.0326 - accuracy: 0.5500 - val_loss: 1.4111 - val_accuracy: 0.1667 - 3s/epoch - 736ms/step\n",
            "Epoch 83/1000\n",
            "4/4 - 3s - loss: 1.3270 - accuracy: 0.4750 - val_loss: 1.4258 - val_accuracy: 0.2333 - 3s/epoch - 763ms/step\n",
            "Epoch 84/1000\n",
            "4/4 - 3s - loss: 1.3110 - accuracy: 0.3500 - val_loss: 1.3793 - val_accuracy: 0.3000 - 3s/epoch - 754ms/step\n",
            "Epoch 85/1000\n",
            "4/4 - 3s - loss: 1.2905 - accuracy: 0.5500 - val_loss: 1.4030 - val_accuracy: 0.2667 - 3s/epoch - 755ms/step\n",
            "Epoch 86/1000\n",
            "4/4 - 3s - loss: 1.0937 - accuracy: 0.6250 - val_loss: 1.3668 - val_accuracy: 0.3667 - 3s/epoch - 773ms/step\n",
            "Epoch 87/1000\n",
            "4/4 - 4s - loss: 1.2011 - accuracy: 0.5000 - val_loss: 1.3494 - val_accuracy: 0.3667 - 4s/epoch - 878ms/step\n",
            "Epoch 88/1000\n",
            "4/4 - 4s - loss: 1.0039 - accuracy: 0.5000 - val_loss: 1.4086 - val_accuracy: 0.2333 - 4s/epoch - 917ms/step\n",
            "Epoch 89/1000\n",
            "4/4 - 3s - loss: 0.9661 - accuracy: 0.6500 - val_loss: 1.4378 - val_accuracy: 0.2000 - 3s/epoch - 764ms/step\n",
            "Epoch 90/1000\n",
            "4/4 - 3s - loss: 1.0664 - accuracy: 0.5250 - val_loss: 1.3389 - val_accuracy: 0.2667 - 3s/epoch - 776ms/step\n",
            "Epoch 91/1000\n",
            "4/4 - 3s - loss: 1.0949 - accuracy: 0.5500 - val_loss: 1.3735 - val_accuracy: 0.3000 - 3s/epoch - 788ms/step\n",
            "Epoch 92/1000\n",
            "4/4 - 3s - loss: 1.1759 - accuracy: 0.5250 - val_loss: 1.3878 - val_accuracy: 0.2667 - 3s/epoch - 781ms/step\n",
            "Epoch 93/1000\n",
            "4/4 - 3s - loss: 0.8990 - accuracy: 0.6500 - val_loss: 1.4550 - val_accuracy: 0.2667 - 3s/epoch - 765ms/step\n",
            "Epoch 94/1000\n",
            "4/4 - 3s - loss: 1.1216 - accuracy: 0.5000 - val_loss: 1.3742 - val_accuracy: 0.3000 - 3s/epoch - 755ms/step\n",
            "Epoch 95/1000\n",
            "4/4 - 3s - loss: 1.2069 - accuracy: 0.4250 - val_loss: 1.4392 - val_accuracy: 0.1667 - 3s/epoch - 786ms/step\n",
            "Epoch 96/1000\n",
            "4/4 - 3s - loss: 0.8606 - accuracy: 0.6250 - val_loss: 1.3701 - val_accuracy: 0.3000 - 3s/epoch - 770ms/step\n",
            "Epoch 97/1000\n",
            "4/4 - 3s - loss: 1.1993 - accuracy: 0.4500 - val_loss: 1.3603 - val_accuracy: 0.4333 - 3s/epoch - 772ms/step\n",
            "Epoch 98/1000\n",
            "4/4 - 3s - loss: 0.9712 - accuracy: 0.5750 - val_loss: 1.4124 - val_accuracy: 0.2333 - 3s/epoch - 783ms/step\n",
            "Epoch 99/1000\n",
            "4/4 - 3s - loss: 1.0699 - accuracy: 0.6750 - val_loss: 1.3982 - val_accuracy: 0.2333 - 3s/epoch - 772ms/step\n",
            "Epoch 100/1000\n",
            "4/4 - 3s - loss: 1.0552 - accuracy: 0.5500 - val_loss: 1.3899 - val_accuracy: 0.3333 - 3s/epoch - 752ms/step\n",
            "Epoch 101/1000\n",
            "4/4 - 3s - loss: 1.1667 - accuracy: 0.5250 - val_loss: 1.3117 - val_accuracy: 0.2667 - 3s/epoch - 800ms/step\n",
            "Epoch 102/1000\n",
            "4/4 - 3s - loss: 1.0738 - accuracy: 0.5750 - val_loss: 1.4266 - val_accuracy: 0.2667 - 3s/epoch - 776ms/step\n",
            "Epoch 103/1000\n",
            "4/4 - 3s - loss: 1.3121 - accuracy: 0.5000 - val_loss: 1.4082 - val_accuracy: 0.2667 - 3s/epoch - 774ms/step\n",
            "Epoch 104/1000\n",
            "4/4 - 3s - loss: 1.1221 - accuracy: 0.5250 - val_loss: 1.3733 - val_accuracy: 0.3667 - 3s/epoch - 867ms/step\n",
            "Epoch 105/1000\n",
            "4/4 - 3s - loss: 1.1348 - accuracy: 0.4500 - val_loss: 1.4094 - val_accuracy: 0.2667 - 3s/epoch - 757ms/step\n",
            "Epoch 106/1000\n",
            "4/4 - 3s - loss: 0.9841 - accuracy: 0.5500 - val_loss: 1.5216 - val_accuracy: 0.2000 - 3s/epoch - 778ms/step\n",
            "Epoch 107/1000\n",
            "4/4 - 3s - loss: 1.0436 - accuracy: 0.5500 - val_loss: 1.4027 - val_accuracy: 0.3333 - 3s/epoch - 787ms/step\n",
            "Epoch 108/1000\n",
            "4/4 - 3s - loss: 1.0380 - accuracy: 0.6000 - val_loss: 1.3550 - val_accuracy: 0.2667 - 3s/epoch - 736ms/step\n",
            "Epoch 109/1000\n",
            "4/4 - 3s - loss: 0.9972 - accuracy: 0.6000 - val_loss: 1.4411 - val_accuracy: 0.2000 - 3s/epoch - 749ms/step\n",
            "Epoch 110/1000\n",
            "4/4 - 3s - loss: 0.9270 - accuracy: 0.5750 - val_loss: 1.3739 - val_accuracy: 0.2667 - 3s/epoch - 780ms/step\n",
            "Epoch 111/1000\n",
            "4/4 - 3s - loss: 0.9720 - accuracy: 0.6250 - val_loss: 1.3585 - val_accuracy: 0.3667 - 3s/epoch - 763ms/step\n",
            "Epoch 112/1000\n",
            "4/4 - 3s - loss: 0.9844 - accuracy: 0.6000 - val_loss: 1.3383 - val_accuracy: 0.3000 - 3s/epoch - 749ms/step\n",
            "Epoch 113/1000\n",
            "4/4 - 4s - loss: 1.2085 - accuracy: 0.5500 - val_loss: 1.4872 - val_accuracy: 0.1667 - 4s/epoch - 932ms/step\n",
            "Epoch 114/1000\n",
            "4/4 - 3s - loss: 1.2033 - accuracy: 0.5000 - val_loss: 1.4086 - val_accuracy: 0.3000 - 3s/epoch - 780ms/step\n",
            "Epoch 115/1000\n",
            "4/4 - 3s - loss: 1.0474 - accuracy: 0.6250 - val_loss: 1.3835 - val_accuracy: 0.2333 - 3s/epoch - 752ms/step\n",
            "Epoch 116/1000\n",
            "4/4 - 3s - loss: 1.1657 - accuracy: 0.4500 - val_loss: 1.3607 - val_accuracy: 0.2000 - 3s/epoch - 759ms/step\n",
            "Epoch 117/1000\n",
            "4/4 - 3s - loss: 0.8202 - accuracy: 0.6750 - val_loss: 1.3226 - val_accuracy: 0.3000 - 3s/epoch - 774ms/step\n",
            "Epoch 118/1000\n",
            "4/4 - 3s - loss: 1.0623 - accuracy: 0.4750 - val_loss: 1.3939 - val_accuracy: 0.2667 - 3s/epoch - 750ms/step\n",
            "Epoch 119/1000\n",
            "4/4 - 3s - loss: 0.9950 - accuracy: 0.6000 - val_loss: 1.4803 - val_accuracy: 0.2667 - 3s/epoch - 785ms/step\n",
            "Epoch 120/1000\n",
            "4/4 - 3s - loss: 1.2278 - accuracy: 0.3500 - val_loss: 1.3670 - val_accuracy: 0.2000 - 3s/epoch - 748ms/step\n",
            "Epoch 121/1000\n",
            "4/4 - 4s - loss: 1.0905 - accuracy: 0.6000 - val_loss: 1.4787 - val_accuracy: 0.3333 - 4s/epoch - 890ms/step\n",
            "Epoch 122/1000\n",
            "4/4 - 3s - loss: 1.0197 - accuracy: 0.5250 - val_loss: 1.5001 - val_accuracy: 0.0667 - 3s/epoch - 757ms/step\n",
            "Epoch 123/1000\n",
            "4/4 - 3s - loss: 1.2901 - accuracy: 0.5000 - val_loss: 1.3835 - val_accuracy: 0.2667 - 3s/epoch - 748ms/step\n",
            "Epoch 124/1000\n",
            "4/4 - 3s - loss: 0.9394 - accuracy: 0.6250 - val_loss: 1.3379 - val_accuracy: 0.2667 - 3s/epoch - 764ms/step\n",
            "Epoch 125/1000\n",
            "4/4 - 3s - loss: 1.1716 - accuracy: 0.5000 - val_loss: 1.4913 - val_accuracy: 0.2667 - 3s/epoch - 733ms/step\n",
            "Epoch 126/1000\n",
            "4/4 - 3s - loss: 0.9353 - accuracy: 0.6000 - val_loss: 1.2826 - val_accuracy: 0.3333 - 3s/epoch - 807ms/step\n",
            "Epoch 127/1000\n",
            "4/4 - 3s - loss: 1.3969 - accuracy: 0.5250 - val_loss: 1.4755 - val_accuracy: 0.1333 - 3s/epoch - 785ms/step\n",
            "Epoch 128/1000\n",
            "4/4 - 3s - loss: 0.9553 - accuracy: 0.5750 - val_loss: 1.3549 - val_accuracy: 0.4000 - 3s/epoch - 756ms/step\n",
            "Epoch 129/1000\n",
            "4/4 - 3s - loss: 1.0797 - accuracy: 0.5500 - val_loss: 1.2919 - val_accuracy: 0.4000 - 3s/epoch - 765ms/step\n",
            "Epoch 130/1000\n",
            "4/4 - 3s - loss: 0.9556 - accuracy: 0.6000 - val_loss: 1.2713 - val_accuracy: 0.4667 - 3s/epoch - 792ms/step\n",
            "Epoch 131/1000\n",
            "4/4 - 3s - loss: 1.2014 - accuracy: 0.4250 - val_loss: 1.3732 - val_accuracy: 0.3000 - 3s/epoch - 749ms/step\n",
            "Epoch 132/1000\n",
            "4/4 - 3s - loss: 0.9175 - accuracy: 0.6250 - val_loss: 1.4497 - val_accuracy: 0.4000 - 3s/epoch - 759ms/step\n",
            "Epoch 133/1000\n",
            "4/4 - 3s - loss: 1.1509 - accuracy: 0.5500 - val_loss: 1.3576 - val_accuracy: 0.3333 - 3s/epoch - 763ms/step\n",
            "Epoch 134/1000\n",
            "4/4 - 3s - loss: 0.9073 - accuracy: 0.5500 - val_loss: 1.3029 - val_accuracy: 0.3667 - 3s/epoch - 762ms/step\n",
            "Epoch 135/1000\n",
            "4/4 - 3s - loss: 1.0663 - accuracy: 0.6000 - val_loss: 1.3432 - val_accuracy: 0.2667 - 3s/epoch - 733ms/step\n",
            "Epoch 136/1000\n",
            "4/4 - 3s - loss: 1.0383 - accuracy: 0.5500 - val_loss: 1.3708 - val_accuracy: 0.3333 - 3s/epoch - 754ms/step\n",
            "Epoch 137/1000\n",
            "4/4 - 3s - loss: 0.9008 - accuracy: 0.6500 - val_loss: 1.3055 - val_accuracy: 0.3333 - 3s/epoch - 777ms/step\n",
            "Epoch 138/1000\n",
            "4/4 - 3s - loss: 1.0853 - accuracy: 0.5500 - val_loss: 1.6305 - val_accuracy: 0.2333 - 3s/epoch - 783ms/step\n",
            "Epoch 139/1000\n",
            "4/4 - 3s - loss: 1.4001 - accuracy: 0.4118 - val_loss: 1.4662 - val_accuracy: 0.2000 - 3s/epoch - 710ms/step\n",
            "Epoch 140/1000\n",
            "4/4 - 3s - loss: 1.0206 - accuracy: 0.5750 - val_loss: 1.2718 - val_accuracy: 0.3667 - 3s/epoch - 760ms/step\n",
            "Epoch 141/1000\n",
            "4/4 - 3s - loss: 0.9339 - accuracy: 0.5500 - val_loss: 1.3870 - val_accuracy: 0.3000 - 3s/epoch - 782ms/step\n",
            "Epoch 142/1000\n",
            "4/4 - 3s - loss: 1.2398 - accuracy: 0.4750 - val_loss: 1.3696 - val_accuracy: 0.2667 - 3s/epoch - 768ms/step\n",
            "Epoch 143/1000\n",
            "4/4 - 3s - loss: 0.8748 - accuracy: 0.6250 - val_loss: 1.1952 - val_accuracy: 0.3667 - 3s/epoch - 786ms/step\n",
            "Epoch 144/1000\n",
            "4/4 - 3s - loss: 1.0030 - accuracy: 0.4750 - val_loss: 1.1211 - val_accuracy: 0.5000 - 3s/epoch - 780ms/step\n",
            "Epoch 145/1000\n",
            "4/4 - 3s - loss: 1.0092 - accuracy: 0.5000 - val_loss: 1.1631 - val_accuracy: 0.4000 - 3s/epoch - 784ms/step\n",
            "Epoch 146/1000\n",
            "4/4 - 3s - loss: 1.0455 - accuracy: 0.5750 - val_loss: 1.2830 - val_accuracy: 0.4667 - 3s/epoch - 751ms/step\n",
            "Epoch 147/1000\n",
            "4/4 - 3s - loss: 0.9259 - accuracy: 0.6750 - val_loss: 1.1071 - val_accuracy: 0.5333 - 3s/epoch - 783ms/step\n",
            "Epoch 148/1000\n",
            "4/4 - 3s - loss: 1.0967 - accuracy: 0.4250 - val_loss: 1.0714 - val_accuracy: 0.5333 - 3s/epoch - 817ms/step\n",
            "Epoch 149/1000\n",
            "4/4 - 3s - loss: 1.1803 - accuracy: 0.4500 - val_loss: 0.9864 - val_accuracy: 0.4667 - 3s/epoch - 799ms/step\n",
            "Epoch 150/1000\n",
            "4/4 - 3s - loss: 1.0186 - accuracy: 0.5250 - val_loss: 1.1370 - val_accuracy: 0.5333 - 3s/epoch - 757ms/step\n",
            "Epoch 151/1000\n",
            "4/4 - 4s - loss: 0.8676 - accuracy: 0.6500 - val_loss: 0.9698 - val_accuracy: 0.5000 - 4s/epoch - 944ms/step\n",
            "Epoch 152/1000\n",
            "4/4 - 3s - loss: 1.2813 - accuracy: 0.4750 - val_loss: 1.2787 - val_accuracy: 0.4000 - 3s/epoch - 790ms/step\n",
            "Epoch 153/1000\n",
            "4/4 - 3s - loss: 1.1637 - accuracy: 0.4250 - val_loss: 1.2500 - val_accuracy: 0.4000 - 3s/epoch - 770ms/step\n",
            "Epoch 154/1000\n",
            "4/4 - 3s - loss: 0.8493 - accuracy: 0.7750 - val_loss: 1.0829 - val_accuracy: 0.3667 - 3s/epoch - 785ms/step\n",
            "Epoch 155/1000\n",
            "4/4 - 3s - loss: 0.9415 - accuracy: 0.6500 - val_loss: 1.1127 - val_accuracy: 0.4667 - 3s/epoch - 785ms/step\n",
            "Epoch 156/1000\n",
            "4/4 - 3s - loss: 1.1212 - accuracy: 0.4750 - val_loss: 1.0467 - val_accuracy: 0.5333 - 3s/epoch - 768ms/step\n",
            "Epoch 157/1000\n",
            "4/4 - 3s - loss: 0.9459 - accuracy: 0.7000 - val_loss: 1.2859 - val_accuracy: 0.5000 - 3s/epoch - 745ms/step\n",
            "Epoch 158/1000\n",
            "4/4 - 3s - loss: 1.1764 - accuracy: 0.4500 - val_loss: 0.9937 - val_accuracy: 0.6000 - 3s/epoch - 764ms/step\n",
            "Epoch 159/1000\n",
            "4/4 - 3s - loss: 0.8762 - accuracy: 0.6250 - val_loss: 1.0242 - val_accuracy: 0.6000 - 3s/epoch - 762ms/step\n",
            "Epoch 160/1000\n",
            "4/4 - 3s - loss: 1.1705 - accuracy: 0.5250 - val_loss: 0.9974 - val_accuracy: 0.6333 - 3s/epoch - 751ms/step\n",
            "Epoch 161/1000\n",
            "4/4 - 3s - loss: 1.0992 - accuracy: 0.5500 - val_loss: 1.0295 - val_accuracy: 0.5667 - 3s/epoch - 774ms/step\n",
            "Epoch 162/1000\n",
            "4/4 - 3s - loss: 1.0370 - accuracy: 0.5750 - val_loss: 1.0009 - val_accuracy: 0.5333 - 3s/epoch - 774ms/step\n",
            "Epoch 163/1000\n",
            "4/4 - 3s - loss: 0.8220 - accuracy: 0.6250 - val_loss: 0.8617 - val_accuracy: 0.7000 - 3s/epoch - 821ms/step\n",
            "Epoch 164/1000\n",
            "4/4 - 3s - loss: 0.9625 - accuracy: 0.6000 - val_loss: 1.1714 - val_accuracy: 0.5000 - 3s/epoch - 808ms/step\n",
            "Epoch 165/1000\n",
            "4/4 - 3s - loss: 1.0412 - accuracy: 0.5000 - val_loss: 1.2051 - val_accuracy: 0.4333 - 3s/epoch - 753ms/step\n",
            "Epoch 166/1000\n",
            "4/4 - 3s - loss: 1.1102 - accuracy: 0.4500 - val_loss: 1.1694 - val_accuracy: 0.5667 - 3s/epoch - 770ms/step\n",
            "Epoch 167/1000\n",
            "4/4 - 3s - loss: 0.8875 - accuracy: 0.6250 - val_loss: 0.9726 - val_accuracy: 0.5667 - 3s/epoch - 752ms/step\n",
            "Epoch 168/1000\n",
            "4/4 - 3s - loss: 0.9909 - accuracy: 0.5500 - val_loss: 1.3708 - val_accuracy: 0.4333 - 3s/epoch - 766ms/step\n",
            "Epoch 169/1000\n",
            "4/4 - 3s - loss: 0.8411 - accuracy: 0.7250 - val_loss: 1.1489 - val_accuracy: 0.6667 - 3s/epoch - 757ms/step\n",
            "Epoch 170/1000\n",
            "4/4 - 3s - loss: 1.0469 - accuracy: 0.5500 - val_loss: 1.1793 - val_accuracy: 0.5667 - 3s/epoch - 747ms/step\n",
            "Epoch 171/1000\n",
            "4/4 - 3s - loss: 1.0637 - accuracy: 0.5500 - val_loss: 0.9550 - val_accuracy: 0.5667 - 3s/epoch - 764ms/step\n",
            "Epoch 172/1000\n",
            "4/4 - 3s - loss: 1.0002 - accuracy: 0.5250 - val_loss: 0.9776 - val_accuracy: 0.7000 - 3s/epoch - 791ms/step\n",
            "Epoch 173/1000\n",
            "4/4 - 3s - loss: 0.8322 - accuracy: 0.6500 - val_loss: 0.6918 - val_accuracy: 0.7667 - 3s/epoch - 771ms/step\n",
            "Epoch 174/1000\n",
            "4/4 - 3s - loss: 0.9170 - accuracy: 0.6250 - val_loss: 1.0313 - val_accuracy: 0.5333 - 3s/epoch - 754ms/step\n",
            "Epoch 175/1000\n",
            "4/4 - 3s - loss: 1.0051 - accuracy: 0.5250 - val_loss: 1.0201 - val_accuracy: 0.6000 - 3s/epoch - 787ms/step\n",
            "Epoch 176/1000\n",
            "4/4 - 3s - loss: 0.9999 - accuracy: 0.5500 - val_loss: 0.6179 - val_accuracy: 0.6667 - 3s/epoch - 792ms/step\n",
            "Epoch 177/1000\n",
            "4/4 - 3s - loss: 0.9750 - accuracy: 0.5250 - val_loss: 0.8792 - val_accuracy: 0.6000 - 3s/epoch - 758ms/step\n",
            "Epoch 178/1000\n",
            "4/4 - 3s - loss: 0.9956 - accuracy: 0.5500 - val_loss: 1.2633 - val_accuracy: 0.5333 - 3s/epoch - 752ms/step\n",
            "Epoch 179/1000\n",
            "4/4 - 3s - loss: 1.0081 - accuracy: 0.5750 - val_loss: 1.0281 - val_accuracy: 0.6000 - 3s/epoch - 751ms/step\n",
            "Epoch 180/1000\n",
            "4/4 - 3s - loss: 0.9040 - accuracy: 0.6000 - val_loss: 0.7402 - val_accuracy: 0.6667 - 3s/epoch - 784ms/step\n",
            "Epoch 181/1000\n",
            "4/4 - 3s - loss: 1.0662 - accuracy: 0.6250 - val_loss: 1.0107 - val_accuracy: 0.5333 - 3s/epoch - 764ms/step\n",
            "Epoch 182/1000\n",
            "4/4 - 3s - loss: 1.1762 - accuracy: 0.5500 - val_loss: 1.9191 - val_accuracy: 0.3333 - 3s/epoch - 770ms/step\n",
            "Epoch 183/1000\n",
            "4/4 - 3s - loss: 0.9568 - accuracy: 0.5250 - val_loss: 1.2254 - val_accuracy: 0.3333 - 3s/epoch - 788ms/step\n",
            "Epoch 184/1000\n",
            "4/4 - 3s - loss: 0.8997 - accuracy: 0.7000 - val_loss: 1.2276 - val_accuracy: 0.5000 - 3s/epoch - 766ms/step\n",
            "Epoch 185/1000\n",
            "4/4 - 3s - loss: 0.7919 - accuracy: 0.6500 - val_loss: 1.7799 - val_accuracy: 0.3667 - 3s/epoch - 771ms/step\n",
            "Epoch 186/1000\n",
            "4/4 - 3s - loss: 0.8915 - accuracy: 0.6750 - val_loss: 1.4921 - val_accuracy: 0.4000 - 3s/epoch - 766ms/step\n",
            "Epoch 187/1000\n",
            "4/4 - 3s - loss: 0.8953 - accuracy: 0.7000 - val_loss: 1.6926 - val_accuracy: 0.3667 - 3s/epoch - 796ms/step\n",
            "Epoch 188/1000\n",
            "4/4 - 3s - loss: 1.2858 - accuracy: 0.3500 - val_loss: 1.4212 - val_accuracy: 0.4333 - 3s/epoch - 829ms/step\n",
            "Epoch 189/1000\n",
            "4/4 - 3s - loss: 0.9341 - accuracy: 0.6750 - val_loss: 1.1670 - val_accuracy: 0.6000 - 3s/epoch - 782ms/step\n",
            "Epoch 190/1000\n",
            "4/4 - 3s - loss: 0.9782 - accuracy: 0.4750 - val_loss: 0.7435 - val_accuracy: 0.7333 - 3s/epoch - 782ms/step\n",
            "Epoch 191/1000\n",
            "4/4 - 3s - loss: 1.1028 - accuracy: 0.5250 - val_loss: 1.2163 - val_accuracy: 0.5667 - 3s/epoch - 756ms/step\n",
            "Epoch 192/1000\n",
            "4/4 - 3s - loss: 1.0571 - accuracy: 0.5750 - val_loss: 1.4981 - val_accuracy: 0.5000 - 3s/epoch - 766ms/step\n",
            "Epoch 193/1000\n",
            "4/4 - 3s - loss: 0.9054 - accuracy: 0.6750 - val_loss: 1.1508 - val_accuracy: 0.7000 - 3s/epoch - 761ms/step\n",
            "Epoch 194/1000\n",
            "4/4 - 3s - loss: 0.8596 - accuracy: 0.6750 - val_loss: 1.2489 - val_accuracy: 0.6000 - 3s/epoch - 771ms/step\n",
            "Epoch 195/1000\n",
            "4/4 - 3s - loss: 1.0268 - accuracy: 0.5250 - val_loss: 1.0204 - val_accuracy: 0.6667 - 3s/epoch - 766ms/step\n",
            "Epoch 196/1000\n",
            "4/4 - 3s - loss: 0.9571 - accuracy: 0.5500 - val_loss: 1.8178 - val_accuracy: 0.4000 - 3s/epoch - 780ms/step\n",
            "Epoch 197/1000\n",
            "4/4 - 3s - loss: 1.0539 - accuracy: 0.5750 - val_loss: 1.2316 - val_accuracy: 0.6667 - 3s/epoch - 774ms/step\n",
            "Epoch 198/1000\n",
            "4/4 - 3s - loss: 0.8985 - accuracy: 0.6250 - val_loss: 1.6469 - val_accuracy: 0.5667 - 3s/epoch - 743ms/step\n",
            "Epoch 199/1000\n",
            "4/4 - 3s - loss: 1.1186 - accuracy: 0.5500 - val_loss: 2.4471 - val_accuracy: 0.5000 - 3s/epoch - 771ms/step\n",
            "Epoch 200/1000\n",
            "4/4 - 3s - loss: 0.9939 - accuracy: 0.6250 - val_loss: 1.6080 - val_accuracy: 0.5333 - 3s/epoch - 767ms/step\n",
            "Epoch 201/1000\n",
            "4/4 - 3s - loss: 1.0276 - accuracy: 0.5750 - val_loss: 1.3446 - val_accuracy: 0.6333 - 3s/epoch - 751ms/step\n",
            "Epoch 202/1000\n",
            "4/4 - 3s - loss: 0.9981 - accuracy: 0.6500 - val_loss: 1.8612 - val_accuracy: 0.6000 - 3s/epoch - 786ms/step\n",
            "Epoch 203/1000\n",
            "4/4 - 3s - loss: 1.1372 - accuracy: 0.5250 - val_loss: 1.2280 - val_accuracy: 0.5000 - 3s/epoch - 753ms/step\n",
            "Epoch 204/1000\n",
            "4/4 - 3s - loss: 1.0639 - accuracy: 0.5500 - val_loss: 0.9581 - val_accuracy: 0.6333 - 3s/epoch - 776ms/step\n",
            "Epoch 205/1000\n",
            "4/4 - 3s - loss: 1.0786 - accuracy: 0.4500 - val_loss: 1.0675 - val_accuracy: 0.5333 - 3s/epoch - 743ms/step\n",
            "Epoch 206/1000\n",
            "4/4 - 3s - loss: 0.9510 - accuracy: 0.6000 - val_loss: 1.7566 - val_accuracy: 0.4333 - 3s/epoch - 754ms/step\n",
            "Epoch 207/1000\n",
            "4/4 - 3s - loss: 0.8582 - accuracy: 0.6000 - val_loss: 1.9186 - val_accuracy: 0.5000 - 3s/epoch - 776ms/step\n",
            "Epoch 208/1000\n",
            "4/4 - 3s - loss: 0.8646 - accuracy: 0.6500 - val_loss: 1.7091 - val_accuracy: 0.4333 - 3s/epoch - 741ms/step\n",
            "Epoch 209/1000\n",
            "4/4 - 3s - loss: 0.9391 - accuracy: 0.5750 - val_loss: 1.2755 - val_accuracy: 0.5000 - 3s/epoch - 754ms/step\n",
            "Epoch 210/1000\n",
            "4/4 - 3s - loss: 0.9670 - accuracy: 0.6000 - val_loss: 1.3862 - val_accuracy: 0.5000 - 3s/epoch - 785ms/step\n",
            "Epoch 211/1000\n",
            "4/4 - 3s - loss: 0.9634 - accuracy: 0.5750 - val_loss: 1.9562 - val_accuracy: 0.4000 - 3s/epoch - 743ms/step\n",
            "Epoch 212/1000\n",
            "4/4 - 3s - loss: 0.9377 - accuracy: 0.6000 - val_loss: 1.3583 - val_accuracy: 0.5667 - 3s/epoch - 793ms/step\n",
            "Epoch 213/1000\n",
            "4/4 - 3s - loss: 0.8900 - accuracy: 0.5750 - val_loss: 2.3958 - val_accuracy: 0.4333 - 3s/epoch - 773ms/step\n",
            "Epoch 214/1000\n",
            "4/4 - 3s - loss: 0.8224 - accuracy: 0.7000 - val_loss: 2.4676 - val_accuracy: 0.4333 - 3s/epoch - 764ms/step\n",
            "Epoch 215/1000\n",
            "4/4 - 3s - loss: 0.8636 - accuracy: 0.6500 - val_loss: 1.2771 - val_accuracy: 0.6000 - 3s/epoch - 777ms/step\n",
            "Epoch 216/1000\n",
            "4/4 - 3s - loss: 1.0259 - accuracy: 0.5750 - val_loss: 1.0959 - val_accuracy: 0.5333 - 3s/epoch - 782ms/step\n",
            "Epoch 217/1000\n",
            "4/4 - 3s - loss: 1.0738 - accuracy: 0.5000 - val_loss: 1.2348 - val_accuracy: 0.5333 - 3s/epoch - 756ms/step\n",
            "Epoch 218/1000\n",
            "4/4 - 3s - loss: 1.0184 - accuracy: 0.5500 - val_loss: 1.4795 - val_accuracy: 0.5667 - 3s/epoch - 767ms/step\n",
            "Epoch 219/1000\n",
            "4/4 - 3s - loss: 0.9177 - accuracy: 0.5750 - val_loss: 1.0942 - val_accuracy: 0.5000 - 3s/epoch - 804ms/step\n",
            "Epoch 220/1000\n",
            "4/4 - 3s - loss: 0.8402 - accuracy: 0.6250 - val_loss: 1.9253 - val_accuracy: 0.4333 - 3s/epoch - 745ms/step\n",
            "Epoch 221/1000\n",
            "4/4 - 3s - loss: 0.9087 - accuracy: 0.6250 - val_loss: 1.6738 - val_accuracy: 0.5000 - 3s/epoch - 764ms/step\n",
            "Epoch 222/1000\n",
            "4/4 - 3s - loss: 1.2140 - accuracy: 0.5250 - val_loss: 1.0280 - val_accuracy: 0.6000 - 3s/epoch - 761ms/step\n",
            "Epoch 223/1000\n",
            "4/4 - 3s - loss: 0.8076 - accuracy: 0.6250 - val_loss: 0.8002 - val_accuracy: 0.6667 - 3s/epoch - 738ms/step\n",
            "Epoch 224/1000\n",
            "4/4 - 3s - loss: 0.8583 - accuracy: 0.7000 - val_loss: 0.6470 - val_accuracy: 0.7000 - 3s/epoch - 768ms/step\n",
            "Epoch 225/1000\n",
            "4/4 - 3s - loss: 0.9916 - accuracy: 0.5250 - val_loss: 1.0515 - val_accuracy: 0.7333 - 3s/epoch - 743ms/step\n",
            "Epoch 226/1000\n",
            "4/4 - 3s - loss: 1.2140 - accuracy: 0.5250 - val_loss: 0.6576 - val_accuracy: 0.7667 - 3s/epoch - 768ms/step\n",
            "Epoch 227/1000\n",
            "4/4 - 3s - loss: 0.9597 - accuracy: 0.6000 - val_loss: 0.9725 - val_accuracy: 0.6333 - 3s/epoch - 749ms/step\n",
            "Epoch 228/1000\n",
            "4/4 - 3s - loss: 0.9837 - accuracy: 0.5750 - val_loss: 0.9966 - val_accuracy: 0.6333 - 3s/epoch - 746ms/step\n",
            "Epoch 229/1000\n",
            "4/4 - 3s - loss: 0.7703 - accuracy: 0.6750 - val_loss: 0.9947 - val_accuracy: 0.7667 - 3s/epoch - 761ms/step\n",
            "Epoch 230/1000\n",
            "4/4 - 3s - loss: 0.9405 - accuracy: 0.7500 - val_loss: 2.6217 - val_accuracy: 0.4333 - 3s/epoch - 827ms/step\n",
            "Epoch 231/1000\n",
            "4/4 - 3s - loss: 1.0092 - accuracy: 0.6000 - val_loss: 0.7997 - val_accuracy: 0.7333 - 3s/epoch - 739ms/step\n",
            "Epoch 232/1000\n",
            "4/4 - 3s - loss: 0.8164 - accuracy: 0.6750 - val_loss: 1.1444 - val_accuracy: 0.6333 - 3s/epoch - 778ms/step\n",
            "Epoch 233/1000\n",
            "4/4 - 3s - loss: 0.8362 - accuracy: 0.6750 - val_loss: 1.2552 - val_accuracy: 0.6333 - 3s/epoch - 764ms/step\n",
            "Epoch 234/1000\n",
            "4/4 - 3s - loss: 1.1622 - accuracy: 0.5500 - val_loss: 2.0771 - val_accuracy: 0.4000 - 3s/epoch - 770ms/step\n",
            "Epoch 235/1000\n",
            "4/4 - 3s - loss: 0.9092 - accuracy: 0.6000 - val_loss: 2.3409 - val_accuracy: 0.4667 - 3s/epoch - 766ms/step\n",
            "Epoch 236/1000\n",
            "4/4 - 3s - loss: 1.0118 - accuracy: 0.5500 - val_loss: 1.8948 - val_accuracy: 0.5333 - 3s/epoch - 770ms/step\n",
            "Epoch 237/1000\n",
            "4/4 - 3s - loss: 0.8237 - accuracy: 0.6750 - val_loss: 2.1759 - val_accuracy: 0.4000 - 3s/epoch - 781ms/step\n",
            "Epoch 238/1000\n",
            "4/4 - 3s - loss: 0.6710 - accuracy: 0.6750 - val_loss: 2.4514 - val_accuracy: 0.4333 - 3s/epoch - 763ms/step\n",
            "Epoch 239/1000\n",
            "4/4 - 3s - loss: 1.1247 - accuracy: 0.6176 - val_loss: 1.8925 - val_accuracy: 0.5333 - 3s/epoch - 688ms/step\n",
            "Epoch 240/1000\n",
            "4/4 - 3s - loss: 0.7364 - accuracy: 0.7250 - val_loss: 1.8837 - val_accuracy: 0.5333 - 3s/epoch - 754ms/step\n",
            "Epoch 241/1000\n",
            "4/4 - 3s - loss: 0.7521 - accuracy: 0.7000 - val_loss: 1.7566 - val_accuracy: 0.5000 - 3s/epoch - 781ms/step\n",
            "Epoch 242/1000\n",
            "4/4 - 3s - loss: 0.8673 - accuracy: 0.6500 - val_loss: 1.9656 - val_accuracy: 0.5000 - 3s/epoch - 746ms/step\n",
            "Epoch 243/1000\n",
            "4/4 - 3s - loss: 0.7346 - accuracy: 0.7000 - val_loss: 3.1869 - val_accuracy: 0.4333 - 3s/epoch - 769ms/step\n",
            "Epoch 244/1000\n",
            "4/4 - 3s - loss: 1.2435 - accuracy: 0.5500 - val_loss: 0.6635 - val_accuracy: 0.7333 - 3s/epoch - 784ms/step\n",
            "Epoch 245/1000\n",
            "4/4 - 3s - loss: 1.0996 - accuracy: 0.5500 - val_loss: 2.1670 - val_accuracy: 0.3667 - 3s/epoch - 741ms/step\n",
            "Epoch 246/1000\n",
            "4/4 - 3s - loss: 1.1521 - accuracy: 0.5294 - val_loss: 1.1592 - val_accuracy: 0.6000 - 3s/epoch - 699ms/step\n",
            "Epoch 247/1000\n",
            "4/4 - 3s - loss: 0.8242 - accuracy: 0.6750 - val_loss: 1.7330 - val_accuracy: 0.5000 - 3s/epoch - 769ms/step\n",
            "Epoch 248/1000\n",
            "4/4 - 3s - loss: 0.7786 - accuracy: 0.6500 - val_loss: 1.7510 - val_accuracy: 0.5000 - 3s/epoch - 775ms/step\n",
            "Epoch 249/1000\n",
            "4/4 - 3s - loss: 0.8811 - accuracy: 0.6250 - val_loss: 1.9272 - val_accuracy: 0.4333 - 3s/epoch - 763ms/step\n",
            "Epoch 250/1000\n",
            "4/4 - 3s - loss: 1.0390 - accuracy: 0.5750 - val_loss: 1.5453 - val_accuracy: 0.4667 - 3s/epoch - 757ms/step\n",
            "Epoch 251/1000\n",
            "4/4 - 3s - loss: 1.1134 - accuracy: 0.6000 - val_loss: 1.9611 - val_accuracy: 0.4667 - 3s/epoch - 742ms/step\n",
            "Epoch 252/1000\n",
            "4/4 - 3s - loss: 0.9517 - accuracy: 0.6500 - val_loss: 1.2719 - val_accuracy: 0.5667 - 3s/epoch - 817ms/step\n",
            "Epoch 253/1000\n",
            "4/4 - 3s - loss: 0.8411 - accuracy: 0.7000 - val_loss: 1.2788 - val_accuracy: 0.5667 - 3s/epoch - 767ms/step\n",
            "Epoch 254/1000\n",
            "4/4 - 3s - loss: 1.3225 - accuracy: 0.5250 - val_loss: 0.7562 - val_accuracy: 0.7000 - 3s/epoch - 789ms/step\n",
            "Epoch 255/1000\n",
            "4/4 - 3s - loss: 0.8585 - accuracy: 0.7000 - val_loss: 0.9959 - val_accuracy: 0.5667 - 3s/epoch - 736ms/step\n",
            "Epoch 256/1000\n",
            "4/4 - 3s - loss: 0.8979 - accuracy: 0.7000 - val_loss: 1.2437 - val_accuracy: 0.6667 - 3s/epoch - 771ms/step\n",
            "Epoch 257/1000\n",
            "4/4 - 3s - loss: 0.7507 - accuracy: 0.7250 - val_loss: 1.0023 - val_accuracy: 0.6333 - 3s/epoch - 754ms/step\n",
            "Epoch 258/1000\n",
            "4/4 - 3s - loss: 0.9191 - accuracy: 0.6765 - val_loss: 2.4068 - val_accuracy: 0.4667 - 3s/epoch - 675ms/step\n",
            "Epoch 259/1000\n",
            "4/4 - 3s - loss: 1.0153 - accuracy: 0.5750 - val_loss: 2.0163 - val_accuracy: 0.5333 - 3s/epoch - 770ms/step\n",
            "Epoch 260/1000\n",
            "4/4 - 3s - loss: 0.9020 - accuracy: 0.7000 - val_loss: 1.1151 - val_accuracy: 0.7000 - 3s/epoch - 753ms/step\n",
            "Epoch 261/1000\n",
            "4/4 - 3s - loss: 1.0364 - accuracy: 0.5250 - val_loss: 2.1141 - val_accuracy: 0.5000 - 3s/epoch - 778ms/step\n",
            "Epoch 262/1000\n",
            "4/4 - 4s - loss: 0.9621 - accuracy: 0.5500 - val_loss: 1.7445 - val_accuracy: 0.5667 - 4s/epoch - 1s/step\n",
            "Epoch 263/1000\n",
            "4/4 - 3s - loss: 1.1221 - accuracy: 0.5250 - val_loss: 1.1824 - val_accuracy: 0.6000 - 3s/epoch - 753ms/step\n",
            "Epoch 264/1000\n",
            "4/4 - 3s - loss: 0.9664 - accuracy: 0.5750 - val_loss: 1.2694 - val_accuracy: 0.5667 - 3s/epoch - 775ms/step\n",
            "Epoch 265/1000\n",
            "4/4 - 3s - loss: 0.7575 - accuracy: 0.7250 - val_loss: 1.9976 - val_accuracy: 0.5000 - 3s/epoch - 768ms/step\n",
            "Epoch 266/1000\n",
            "4/4 - 3s - loss: 0.9980 - accuracy: 0.5500 - val_loss: 5.3568 - val_accuracy: 0.3667 - 3s/epoch - 770ms/step\n",
            "Epoch 267/1000\n",
            "4/4 - 3s - loss: 0.9756 - accuracy: 0.6000 - val_loss: 1.6033 - val_accuracy: 0.5667 - 3s/epoch - 744ms/step\n",
            "Epoch 268/1000\n",
            "4/4 - 3s - loss: 0.6199 - accuracy: 0.7250 - val_loss: 1.8298 - val_accuracy: 0.5000 - 3s/epoch - 762ms/step\n",
            "Epoch 269/1000\n",
            "4/4 - 3s - loss: 0.7947 - accuracy: 0.7000 - val_loss: 2.0694 - val_accuracy: 0.5667 - 3s/epoch - 778ms/step\n",
            "Epoch 270/1000\n",
            "4/4 - 3s - loss: 0.9453 - accuracy: 0.6000 - val_loss: 2.1199 - val_accuracy: 0.5667 - 3s/epoch - 753ms/step\n",
            "Epoch 271/1000\n",
            "4/4 - 3s - loss: 0.6185 - accuracy: 0.7250 - val_loss: 3.5141 - val_accuracy: 0.2667 - 3s/epoch - 754ms/step\n",
            "Epoch 272/1000\n",
            "4/4 - 3s - loss: 1.0498 - accuracy: 0.7000 - val_loss: 1.7700 - val_accuracy: 0.5667 - 3s/epoch - 768ms/step\n",
            "Epoch 273/1000\n",
            "4/4 - 3s - loss: 1.0657 - accuracy: 0.4500 - val_loss: 1.9590 - val_accuracy: 0.6333 - 3s/epoch - 767ms/step\n",
            "Epoch 274/1000\n",
            "4/4 - 3s - loss: 0.7033 - accuracy: 0.7500 - val_loss: 1.4600 - val_accuracy: 0.6000 - 3s/epoch - 779ms/step\n",
            "Epoch 275/1000\n",
            "4/4 - 3s - loss: 0.8696 - accuracy: 0.7000 - val_loss: 1.8618 - val_accuracy: 0.4667 - 3s/epoch - 762ms/step\n",
            "Epoch 276/1000\n",
            "4/4 - 3s - loss: 1.0338 - accuracy: 0.5500 - val_loss: 1.6986 - val_accuracy: 0.5333 - 3s/epoch - 748ms/step\n",
            "Epoch 277/1000\n",
            "4/4 - 3s - loss: 0.9808 - accuracy: 0.5500 - val_loss: 0.7173 - val_accuracy: 0.6333 - 3s/epoch - 754ms/step\n",
            "Epoch 278/1000\n",
            "4/4 - 3s - loss: 1.2724 - accuracy: 0.4500 - val_loss: 1.0181 - val_accuracy: 0.7000 - 3s/epoch - 774ms/step\n",
            "Epoch 279/1000\n",
            "4/4 - 3s - loss: 0.7368 - accuracy: 0.7000 - val_loss: 0.9743 - val_accuracy: 0.7000 - 3s/epoch - 755ms/step\n",
            "Epoch 280/1000\n",
            "4/4 - 3s - loss: 0.8806 - accuracy: 0.6000 - val_loss: 0.9284 - val_accuracy: 0.6000 - 3s/epoch - 738ms/step\n",
            "Epoch 281/1000\n",
            "4/4 - 3s - loss: 1.0156 - accuracy: 0.5750 - val_loss: 1.5593 - val_accuracy: 0.6000 - 3s/epoch - 750ms/step\n",
            "Epoch 282/1000\n",
            "4/4 - 3s - loss: 1.0028 - accuracy: 0.5250 - val_loss: 1.2682 - val_accuracy: 0.5333 - 3s/epoch - 775ms/step\n",
            "Epoch 283/1000\n",
            "4/4 - 3s - loss: 0.9530 - accuracy: 0.5500 - val_loss: 1.5883 - val_accuracy: 0.5667 - 3s/epoch - 789ms/step\n",
            "Epoch 284/1000\n",
            "4/4 - 3s - loss: 0.7891 - accuracy: 0.7000 - val_loss: 1.4916 - val_accuracy: 0.5000 - 3s/epoch - 769ms/step\n",
            "Epoch 285/1000\n",
            "4/4 - 3s - loss: 0.7249 - accuracy: 0.6500 - val_loss: 3.0742 - val_accuracy: 0.4000 - 3s/epoch - 781ms/step\n",
            "Epoch 286/1000\n",
            "4/4 - 3s - loss: 1.0582 - accuracy: 0.6250 - val_loss: 0.7473 - val_accuracy: 0.6333 - 3s/epoch - 775ms/step\n",
            "Epoch 287/1000\n",
            "4/4 - 3s - loss: 1.1991 - accuracy: 0.4500 - val_loss: 1.2449 - val_accuracy: 0.6333 - 3s/epoch - 743ms/step\n",
            "Epoch 288/1000\n",
            "4/4 - 3s - loss: 0.9125 - accuracy: 0.6250 - val_loss: 1.6176 - val_accuracy: 0.5333 - 3s/epoch - 751ms/step\n",
            "Epoch 289/1000\n",
            "4/4 - 3s - loss: 0.8650 - accuracy: 0.6250 - val_loss: 1.4491 - val_accuracy: 0.5667 - 3s/epoch - 777ms/step\n",
            "Epoch 290/1000\n",
            "4/4 - 3s - loss: 0.8840 - accuracy: 0.7000 - val_loss: 1.4566 - val_accuracy: 0.5000 - 3s/epoch - 768ms/step\n",
            "Epoch 291/1000\n",
            "4/4 - 3s - loss: 0.8364 - accuracy: 0.7000 - val_loss: 1.5009 - val_accuracy: 0.6667 - 3s/epoch - 768ms/step\n",
            "Epoch 292/1000\n",
            "4/4 - 3s - loss: 0.8466 - accuracy: 0.7250 - val_loss: 1.8568 - val_accuracy: 0.5000 - 3s/epoch - 756ms/step\n",
            "Epoch 293/1000\n",
            "4/4 - 3s - loss: 0.8649 - accuracy: 0.6250 - val_loss: 1.9039 - val_accuracy: 0.4667 - 3s/epoch - 783ms/step\n",
            "Epoch 294/1000\n",
            "4/4 - 3s - loss: 0.7118 - accuracy: 0.6250 - val_loss: 1.4999 - val_accuracy: 0.6000 - 3s/epoch - 772ms/step\n",
            "Epoch 295/1000\n",
            "4/4 - 3s - loss: 0.8939 - accuracy: 0.5500 - val_loss: 1.5142 - val_accuracy: 0.5667 - 3s/epoch - 792ms/step\n",
            "Epoch 296/1000\n",
            "4/4 - 3s - loss: 0.8052 - accuracy: 0.7000 - val_loss: 1.0322 - val_accuracy: 0.5333 - 3s/epoch - 754ms/step\n",
            "Epoch 297/1000\n",
            "4/4 - 3s - loss: 0.9978 - accuracy: 0.6000 - val_loss: 1.2644 - val_accuracy: 0.6000 - 3s/epoch - 787ms/step\n",
            "Epoch 298/1000\n",
            "4/4 - 3s - loss: 0.8982 - accuracy: 0.7000 - val_loss: 0.9541 - val_accuracy: 0.6000 - 3s/epoch - 775ms/step\n",
            "Epoch 299/1000\n",
            "4/4 - 3s - loss: 0.9857 - accuracy: 0.5750 - val_loss: 0.8345 - val_accuracy: 0.6667 - 3s/epoch - 763ms/step\n",
            "Epoch 300/1000\n",
            "4/4 - 3s - loss: 1.1046 - accuracy: 0.4750 - val_loss: 0.9428 - val_accuracy: 0.4667 - 3s/epoch - 740ms/step\n",
            "Epoch 301/1000\n",
            "4/4 - 3s - loss: 0.7957 - accuracy: 0.7250 - val_loss: 0.7965 - val_accuracy: 0.6000 - 3s/epoch - 769ms/step\n",
            "Epoch 302/1000\n",
            "4/4 - 3s - loss: 0.8493 - accuracy: 0.6500 - val_loss: 1.4797 - val_accuracy: 0.5333 - 3s/epoch - 788ms/step\n",
            "Epoch 303/1000\n",
            "4/4 - 3s - loss: 1.0097 - accuracy: 0.6000 - val_loss: 1.1017 - val_accuracy: 0.4667 - 3s/epoch - 753ms/step\n",
            "Epoch 304/1000\n",
            "4/4 - 3s - loss: 1.0280 - accuracy: 0.5500 - val_loss: 0.7866 - val_accuracy: 0.7667 - 3s/epoch - 756ms/step\n",
            "Epoch 305/1000\n",
            "4/4 - 3s - loss: 1.0185 - accuracy: 0.5750 - val_loss: 1.5923 - val_accuracy: 0.6000 - 3s/epoch - 756ms/step\n",
            "Epoch 306/1000\n",
            "4/4 - 3s - loss: 0.9437 - accuracy: 0.5500 - val_loss: 1.9596 - val_accuracy: 0.5000 - 3s/epoch - 739ms/step\n",
            "Epoch 307/1000\n",
            "4/4 - 3s - loss: 0.9349 - accuracy: 0.6500 - val_loss: 0.9938 - val_accuracy: 0.7333 - 3s/epoch - 772ms/step\n",
            "Epoch 308/1000\n",
            "4/4 - 3s - loss: 0.9594 - accuracy: 0.6250 - val_loss: 0.7663 - val_accuracy: 0.7000 - 3s/epoch - 744ms/step\n",
            "Epoch 309/1000\n",
            "4/4 - 3s - loss: 0.7745 - accuracy: 0.6500 - val_loss: 1.0763 - val_accuracy: 0.6333 - 3s/epoch - 754ms/step\n",
            "Epoch 310/1000\n",
            "4/4 - 3s - loss: 0.8571 - accuracy: 0.7500 - val_loss: 1.0788 - val_accuracy: 0.6000 - 3s/epoch - 765ms/step\n",
            "Epoch 311/1000\n",
            "4/4 - 3s - loss: 0.6840 - accuracy: 0.6500 - val_loss: 0.9392 - val_accuracy: 0.6000 - 3s/epoch - 789ms/step\n",
            "Epoch 312/1000\n",
            "4/4 - 3s - loss: 0.7473 - accuracy: 0.7000 - val_loss: 1.2949 - val_accuracy: 0.6000 - 3s/epoch - 784ms/step\n",
            "Epoch 313/1000\n",
            "4/4 - 3s - loss: 0.9493 - accuracy: 0.6000 - val_loss: 3.8790 - val_accuracy: 0.2667 - 3s/epoch - 762ms/step\n",
            "Epoch 314/1000\n",
            "4/4 - 3s - loss: 0.8379 - accuracy: 0.6000 - val_loss: 1.5608 - val_accuracy: 0.4667 - 3s/epoch - 758ms/step\n",
            "Epoch 315/1000\n",
            "4/4 - 3s - loss: 0.9197 - accuracy: 0.6500 - val_loss: 1.4997 - val_accuracy: 0.4000 - 3s/epoch - 744ms/step\n",
            "Epoch 316/1000\n",
            "4/4 - 3s - loss: 0.7664 - accuracy: 0.7500 - val_loss: 1.0678 - val_accuracy: 0.6000 - 3s/epoch - 745ms/step\n",
            "Epoch 317/1000\n",
            "4/4 - 3s - loss: 0.9486 - accuracy: 0.6000 - val_loss: 2.2476 - val_accuracy: 0.4333 - 3s/epoch - 779ms/step\n",
            "Epoch 318/1000\n",
            "4/4 - 3s - loss: 1.0269 - accuracy: 0.5500 - val_loss: 1.6902 - val_accuracy: 0.4000 - 3s/epoch - 757ms/step\n",
            "Epoch 319/1000\n",
            "4/4 - 3s - loss: 0.9495 - accuracy: 0.6000 - val_loss: 1.4898 - val_accuracy: 0.5667 - 3s/epoch - 780ms/step\n",
            "Epoch 320/1000\n",
            "4/4 - 3s - loss: 1.0890 - accuracy: 0.4750 - val_loss: 1.4334 - val_accuracy: 0.6000 - 3s/epoch - 766ms/step\n",
            "Epoch 321/1000\n",
            "4/4 - 3s - loss: 1.0803 - accuracy: 0.6000 - val_loss: 0.6978 - val_accuracy: 0.6667 - 3s/epoch - 764ms/step\n",
            "Epoch 322/1000\n",
            "4/4 - 3s - loss: 1.0764 - accuracy: 0.6500 - val_loss: 0.9040 - val_accuracy: 0.6667 - 3s/epoch - 734ms/step\n",
            "Epoch 323/1000\n",
            "4/4 - 3s - loss: 0.6693 - accuracy: 0.8000 - val_loss: 1.0298 - val_accuracy: 0.4667 - 3s/epoch - 787ms/step\n",
            "Epoch 324/1000\n",
            "4/4 - 3s - loss: 0.9095 - accuracy: 0.6750 - val_loss: 0.7160 - val_accuracy: 0.6667 - 3s/epoch - 762ms/step\n",
            "Epoch 325/1000\n",
            "4/4 - 3s - loss: 1.1987 - accuracy: 0.6250 - val_loss: 1.4755 - val_accuracy: 0.4333 - 3s/epoch - 771ms/step\n",
            "Epoch 326/1000\n",
            "Restoring model weights from the end of the best epoch: 176.\n",
            "4/4 - 3s - loss: 1.0740 - accuracy: 0.5750 - val_loss: 0.9628 - val_accuracy: 0.6667 - 3s/epoch - 858ms/step\n",
            "Epoch 326: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Callback to save the current best model\n",
        "epochs = 1000\n",
        "patience = epochs\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=150, mode='min', verbose=1, restore_best_weights=True),\n",
        "    #CustomEarlyStopping(patience=patience),\n",
        "    #tf.keras.callbacks.ModelCheckpoint(filepath='batik-recognition-model.{epoch:03d}.hdf5',  monitor='val_accuracy', mode='max', verbose=0, save_best_only=False),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "]\n",
        "\n",
        "# Using Batch Gradient Descent (batch_size = training_examples) because data is less than 2000\n",
        "# Stochastic Gradient Descent (batch_size = 1)\n",
        "# Mini-Batch Gradient Descent (batch_size = 1 < number_power_of_2 < training_examples)\n",
        "# steps per epoch = 18\n",
        "# validation steps = 3\n",
        "history = xception.fit(train_batches, \n",
        "                        steps_per_epoch=4, \n",
        "                        batch_size=training_examples, \n",
        "                        validation_data=valid_batches, \n",
        "                        validation_steps=2, \n",
        "                        epochs=epochs, verbose=2, \n",
        "                        callbacks=my_callbacks, \n",
        "                        shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "_YjotpcCY1WW"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path):\n",
        "    data = load_files(path)\n",
        "    paths = np.array(data['filenames'])\n",
        "    targets = np_utils.to_categorical(np.array(data['target']))\n",
        "    return paths, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "2e-ZFqEaY1WX"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "\n",
        "test_files, test_targets = load_dataset(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YZTRmdooUOCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1a208f-b966-4a6d-8d30-dd4a98073508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 160/160 [00:01<00:00, 152.82it/s]\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import image  \n",
        "from tqdm import tqdm\n",
        "\n",
        "def path_to_tensor(img_path):\n",
        "    img = image.load_img(img_path, target_size=(299, 299))\n",
        "    x = image.img_to_array(img)\n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "def paths_to_tensor(img_paths):\n",
        "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
        "    return np.vstack(list_of_tensors)\n",
        "\n",
        "test_tensors = preprocess_input(paths_to_tensor(test_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "UNOvbJI0UQyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc60876-22f3-400a-886c-80f9cdac0b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 2s 282ms/step - loss: 1.6922 - accuracy: 0.4313\n",
            "\n",
            "Testing loss: 1.6922\n",
            "Testing accuracy: 0.4313\n"
          ]
        }
      ],
      "source": [
        "# Model Testing\n",
        "# if you want to select the model yourself, uncomment the next line and change the filename as the one you choose\n",
        "# new_model.load_weights('filename.hdf5')\n",
        "\n",
        "print('\\nTesting loss: {:.4f}\\nTesting accuracy: {:.4f}'.format(*xception.evaluate(test_tensors, test_targets)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "RrCuxDCuUTW6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "de99356c-bbed-450a-c072-0faf84e1d5d8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAG6CAYAAAD3bxTsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5wV5dnG8d9FF0FQASOIYon6ikFUNPZuFEtsScQK0WgSezQxlkRNLIlGY02RqMEuajRYsGIvEQERe9SABVAEUbCAsNzvHzMHZ9cth22zs1xfPufDmX6f2bN7z1PmGUUEZmZmVixt8g7AzMzMlpwTuJmZWQE5gZuZmRWQE7iZmVkBOYGbmZkVkBO4mZlZATmBW6ORtIykuyV9Kum2BuznIEkPNmZseZB0n6ShecdRlaQRks7JO46GkHSapKvyjqMIluTnLWmKpJ2aOiZrHE7gSyFJB0oaJ+kzSdPTRLNVI+z6B8BKwIoR8cP67iQiboyI7zVCPJVI2k5SSLqzyvwN0vmPlbmfsyTdUNd6ETE4Iq6tZ7jZ442Q9FX68yq9XmzofusZy2mSJqcxvC9pZGbZY5J+0hxxRMR5EdEkx0q/C5+nn3GmpJsldW+k/a5Vy/Jh6ToXV5m/Vzp/RENjsNbFCXwpI+lE4BLgPJJkuyrwV2CvRtj9asB/I2JhI+yrqXwEbC5pxcy8ocB/G+sASjT279YFEdEl89qgnrG1rW8AaW3CIcBOEdEFGASMqe/+WrgN0s+4BrA8cFYzHfdt4EeS2mXmNer301oPJ/CliKRuwO+BoyPijoj4PCIWRMTdEfGrdJ2Oki6RNC19XSKpY7psu7TUdZKkGWnp/cfpst8BZwD7pyWXw6uWVCX1S0sS7dLpYZL+J2luWqo7KDP/qcx2W0h6Pq2af17SFpllj0k6W9LT6X4elNSjltPwFfBvYEi6fVtgf+DGKufqUknvSZojabykrdP5uwKnZT7ni5k4zpX0NPAFsEa2RCrpb5L+ldn/+ZLGSFLZP8AaSLpN0gfp+XlCUv/MshHpsUdL+hzYvsq2L0vaMzPdPi11bljNoTYBHoiItwEi4oOIGJ5udy6wNXBFel6uSOfX9bP7g6Sx6XkeJWmFdFnpu3Jk+j2cLumXmW0Xf7cy6w6V9G4a/+mZdZeRdK2k2ZJek3SypPfLObcRMQe4C1gvs79ukq5OY5oq6ZzShZGktSQ9nn7emUprKCQ9kW7+Ynp+9q/hkB8ALwG7pNutAGyRxrCYpO9LekXSJ+l5/L/Msg0lTUh/H0YCnapsu4ekiem2z0gaUM65sJbHCXzpsjnJL/OdtaxzOrAZMBDYANgU+E1m+beAbkAf4HDgL5KWj4gzSUr1I9MS4tW1BSJpWeAyYHBEdCX5IzWxmvVWAO5N110R+DNwryqXoA8Efgz0AjoAv6y6nyquAw5N3+8CvAxMq7LO8yTnYAXgJuA2SZ0i4v4qnzNbEj4EOBLoCrxTZX8nAd9JL062Jjl3Q6NxxjK+D/g2yeefQJWLEZLzc24a11NVll0HHJyZ3g2YHhEvVHOc/wCHSvqVpEHKlOYj4nTgSeCY9LwcU+bP7lDgMGBlYGG6btb26Wf7HvBr1d4+uxWwDrAjcEYmqZ0J9CMpTe9c5fPWStLywN7pZy8Zkca6FrBhGlupOv9s4EGSUvsqwOUAEbFNunyD9PyMpGbZ7+cQYBQwPxPT2sDNwAlAT2A0cLekDpI6kFygXk/y3b0N2C+z7YbANcBPSX4mVwJ3Kb1It2JxAl+6rAjMrKOK+yDg9xExIyI+An5HkphKFqTLF0TEaOAzkj+a9bEIWF/SMhExPSJeqWad3YE3I+L6iFgYETcDrwN7Ztb5Z0T8NyK+BG4lSbw1iohngBUkrUPyh/K6ata5ISJmpce8COhI3Z9zRES8km6zoMr+viA5j38GbgCOjYiySoGpX6YlptJrcdt6RFwTEXMjYj5JVe8GSmpbSkZFxNMRsSgi5lXZ7w3AbpKWS6cPIfnj/w0RcQNwLMlFz+PADEm/riXmcn5210fEyxHxOfBbkurjbDX/79KaopeAfwIH1HK830XElxHxIvAiyQUowI+A8yJidnrOq14kVGeCpE+AmSTNTFcCSFqJ5CLnhDSuGcDFpDU6JL8fqwG9I2JeRFS9YCrHncB26c+wuu/n/sC9EfFQ+j27EFiG5CJ4M6A9cEn6O3o7ycVoyZHAlRHxXERUpH005qfbWcE4gS9dZgE9VLl9rareVC49vpPOW7yPKhcAXwBdljSQ9A/2/sDPgOmS7pW0bhnxlGLqk5n+oB7xXA8cQ1LC+0aNhKRfptWtn6Z/yLsBtVXNA7xX28KIeA74HyCSC40lcWFEdM+8hqZxtpX0R0lvS5oDTEnXz8ZaY1wRMQ14GthPSUetwXyzBJ9d/8aI2AnoTvKzO1vSLjWsXs7P7r0qy9rXEnvV72JVNX0PelfZT60/p9RGEdGdpMbqb8CTkjqRJOf2JN/ZT9LvxpUktR8AJ5P8fMemVdyHlXGsStIL0XtJar5WjIinq6xS6bxGxKL0M/VJl02tUrOT/RmsBpyUvRgE+lL7ebUWygl86fIsydX23rWsM43kl7xkVb5ZvVyuz4HOmelvZRdGxAMRsTNJ9enrwD/KiKcU09R6xlRyPXAUMDotHS+WVnGfTFJyWz79Q/4pyR9mgJqqvWutDpd0NElJflq6/8ZwIEkHxJ1ILjL6lQ5XblzAtSTVyj8Eno2IOs9tWrq7DZgErF/Dccr52fWtsmwBSam3puX1+S5OJ6nOrm6ftUpLuFcBq5N8zvdIfod6ZC6mlouI/un6H0TEERHRm6Sa+q+qped5La4jaXap7m6HSudVktLPNJXks/ZJ55Wsmnn/HnBulYvBzmntiBWME/hSJCI+Jelo9hdJe0vqrKTT0mBJF6Sr3Qz8RlJPJZ3BzqD6PyLlmAhsI2nVtDrw1NICSSspuT1mWZI/iJ+RVKlXNRpYW8mtb+3Szj/rAffUMyYAImIysC1Jm39VXUnaOD8C2kk6A1gus/xDoJ+WoKd52m55DkmiPAQ4WdLAzPKQtN2Sfo401vkktSudSdrnl9S/gY2A46mmOSET4zBJu0vqKqmNpMFAf+C5dJUPSdqZS8r52R0saT1JnUk6WN4eERWZ5b9Nv6f9Sfo51NZ2XJNbgVMlLS+pD0nNS1nS6vwfA18C/4uI6SRt3BdJWi49D2tK2jZd/4eSShcLs0kuakrf66rnpzaPk7TXX17D59ld0o6S2pMk+vnAMyQX6QuB49Lf7X1J+rGU/AP4maTvKrFs6WdaZlzWgjiBL2XS9twTSarnPiK5Ij+G5I84JElmHEnJ6iWSTlH1GvQjIh4i+YM7CRhP5T/cbdI4pgEfkyTTn1ezj1nAHiR/pGaRlFz3iIiZVdetR3xPpVXIVT0A3E9y6847wDwqV7uWBqmZJWlCXcdJmyxuAM6PiBcj4k2SnuzXK+n13xeYS3K+a3KyKt8HXvr816UxTgVepXJnq7KkVbb/Iill3lHLqnPSuN8FPgEuAH6eaee9FPiBkt7el5X5s7uepFPYByTV1cdVOebjwFskt6tdGBH1GeDn98D7wGTgYeB2Mp3CavCipM9IkvBQYJ+I+DhddihJZ8lX0+W3k9QiQdJT/7l027uA4yPif+mys4Br06rrH9V28EiMyRwzu+wNkgvBy0lqK/YE9oyIryLiK2BfYBjJ79X+ZH6mETEOOAK4Io39rXRdKyA1TidYM6svSQcD/SPi1DpXbroYzgDWjoiye2g3wjEfA26IiG+MqCapH0nCbV9Hp8v6HPfnwJCI2LYx92vW3GrrzGRmzSDt3Z2b9Havw6l8t0GrIWllkqrrZ0luSTuJpARqVmiuQjdbikk6gqR54L6IeKKu9QuqA0lP8bnAIyT3Vf8114jMGoGr0M3MzArIJXAzM7MCcgI3MzMrIHdiy0G35VeMXr1XqXtFq1XbNr7+bKhlO9T74WSWMW1O1RFqbUl9OmMqX3w6u8EP92motsutFrHwy3pvH19+9EBE7NqIIdXICTwHvXqvwiUj63M7q2V179gh7xAKb+PVl887hFbh7If8tM+Guua4ffMOAYBYOI+O6w6pe8UazHvh8rqGXG40LsKYmZkVkEvgZmZmJQKUe01+WZzAzczMssp/zEGunMDNzMyyXAI3MzMrGhWmBF6MKM3MzKwSl8DNzMyyXIVuZmZWMKIwVehO4GZmZovJJXAzM7NCKkgJvBhRmpmZWSUugZuZmWW5Ct3MzKxoinMfuBO4mZlZSYHGQi/GZYaZmZlV4hK4mZlZlqvQzczMisZt4GZmZsXUphht4E7gZmZmJQUaSrUYUZqZmVklLoGbmZllFeQ2MidwMzOzxdyJzczMrJhcAjczMyuggpTAixGlmZmZVeISuJmZWYnkKnQzM7NCKkgVuhO4mZlZVkFK4MW4zDAzM2sFJHWSNFbSi5JekfS7dP4ISZMlTUxfA+val0vgZmZmizX5feDzgR0i4jNJ7YGnJN2XLvtVRNxe7o6cwM3MzLKasAo9IgL4LJ1sn76iPvtyFbrV6JLfnsBB2/bnqH22XTzvmot+x8/23Ipj9t2ec47/MZ/N+TTHCIvhvFOPYY/N1uaQ3bdYPG/OJ7M5Ydg+DNl5ECcM24c5n36SY4TF8OAD9zOg/zr0X3ct/nTBH/MOp5DuufhULjlgc4b/fI/F8z58+zVG/OJHXHXMXlxz3L5Me2NSjhG2AKWHmdT3BT0kjcu8jvzGIaS2kiYCM4CHIuK5dNG5kiZJulhSx7pCdQK3Gu201/787m83V5o3cPNt+cudj3HFHY/SZ7U1uO2qy3KKrjh22/dALrr6tkrzbhh+CRtvvi23PDSOjTfflhuGX5JTdMVQUVHBCccdzai77+OFSa9y2y0389qrr+YdVuEM2Glfhpx9VaV5j1zzJ7Y+8Gh+csUotjnkeB655k85RddSqKEJfGZEDMq8hlc9QkRURMRAYBVgU0nrA6cC6wKbACsAv64rUidwq9H6gzana7fuleZttMV2tG2XtLyss8HGzPxweh6hFcrATbZguW7LV5r35Jj7GLzPEAAG7zOEJx8enUdohfH82LGsueZarL7GGnTo0IEf7j+Ee+4elXdYhbPqdzahU9dulWdKzP/icwDmfz6XLiv0yiGypVNEfAI8CuwaEdMjMR/4J7BpXdu7Ddzq7aE7b2abXfbKO4xCmj1zBj16fQuAFXuuxOyZM3KOqGWbNm0qq6zSd/F0nz6rMHbsc7VsYeXa+cjTuOW3hzPm6vOJWMTQC2/JO6T8NWEbuKSewIKI+ETSMsDOwPmSVo6I6ZIE7A28XNe+ci+BS6pIu8y/KGmCpC3qWL+7pKMy070l3Z6+Hybpijq2r3YdSaMlda9uG/umkcMvoW3bdmy3x355h1J4KtDIT9b6TBh9MzsdcSrHXvc4Ox1xKvdeenreIeWvYVXodVkZeFTSJOB5kjbwe4AbJb0EvAT0AM6pa0ctoQT+ZdoWgKRdgD8A29ayfnfgKOCvABExDfhBQ4OIiN0auo+lxcP/voWxjz/EuVfdliQfW2LL9+jFzBkf0KPXt5g54wOWX7Fn3iG1aL179+H9999bPD116vv06dMnx4haj5cevpOdf5ok7f/bejCjL/1NzhG1AE3bC30SsGE183dY0n3lXgKvYjlgNoCkLpLGpKXylySV6mr/CKyZltr/JKmfpG9UNUjaXdKzknqUc2BJU0rrSjpR0svp64R0Xj9Jr0n6R3rz/YNp9QeSNkl7DpZiqrPqo6jGP/UI//rnXzjj8mvptEznvMMprK122JX77kyqKu+78xa23nFwzhG1bIM22YS33nqTKZMn89VXX3HbyFvYfY/v5x1Wq9BlxV68+9JYAKa8+B9W6NMv34CsbC2hBL5M2p2+E0nVQukqZB6wT0TMSRPrfyTdBZwCrJ8ptferukNJ+wAnArtFxOwlCUbSxsCPge+S3FDwnKTHSS4svg0cEBFHSLoV2A+4gaTDwRER8aykau9vSW8lOBKg58qrLElIubng5J/x0vPPMOeTjxm644YcdPSvuO2qy1jw1Vf85sj9AVhnwMYcc8YFOUfasp35i58wcezTfDJ7Fvts3Z/DjzuFg488gTOOP4x7b7+BlXr35exLr8k7zBatXbt2XHzpFey5+y5UVFQwdNhhrNe/f95hFc6/zz+RdyaN5cs5s7n8kG3Y+uBj2e24s3noyvNYVLGQdu07MvjY3+cdZr7U5AO5NJqWkMCzVeibA9elXeoFnCdpG2AR0AdYqYz97QAMAr4XEXPqEc9WwJ0R8Xka0x3A1sBdwOSImJiuNx7ol7abd42IZ9P5NwF7VNkn6a0EwwG+3X+Det2039xOvuDv35j3vX0PzCGSYvvdxVdVO//S6/7dzJEU266Dd2PXwW7paoi9f/3naucfdtkdzRxJC1eQpsGWkMAXS0uwPYCewG7p/xtHxAJJU0hK6XV5G1gDWBsY18ghzs+8rwCWaeT9m5lZzorSt6dF1RNIWhdoC8wCugEz0uS9PbBautpcoGstu3mHpGr7Okn1qWN7EthbUmdJywL7pPOqld7HN1fSd9NZQ+pxTDMzawFEksDr+2pOLaEEXmoDh+TcDY2ICkk3Anen3erHAa8DRMQsSU+nHcXuA/5SdYcR8bqkg4DbJO0ZEW9XWWWYpL0z05tltp0gaQQwNp11VUS8UF1be8bhwD8kLQIeBzy+qJmZNancE3hEtK1h/kxg8xqWVW2IXT+dPwIYkb5/AVivmm0Xr1NFv8w6fwYqNRZFxJTScdLpCzOLX4mIAQCSTqHxq+7NzKw5KH0VQO4JvJXYXdKpJOfzHWBYvuGYmVn9NH9VeH05gTeCiBgJjMw7DjMzazgncDMzswIqSgJvUb3QzczMrDwugZuZmWUUpQTuBG5mZlbiXuhmZmbFowL1QncbuJmZWQG5BG5mZpZRlBK4E7iZmVmGE7iZmVkBOYGbmZkVTYF6obsTm5mZWQG5BG5mZpbhKnQzM7OCKdJ94E7gZmZmGU7gZmZmRVSM/O1ObGZmZkXkEriZmVmJXIVuZmZWSE7gZmZmBVSUBO42cDMzswJyCdzMzCzl+8DNzMyKqhj52wnczMxssQL1QncbuJmZWYaker/K2HcnSWMlvSjpFUm/S+evLuk5SW9JGimpQ137cgI3MzNrPvOBHSJiA2AgsKukzYDzgYsjYi1gNnB4XTtyAjczM8toyhJ4JD5LJ9unrwB2AG5P518L7F3XvpzAzczMstSAVzm7l9pKmgjMAB4C3gY+iYiF6SrvA33q2o87sZmZmWU0sBNbD0njMtPDI2J4doWIqAAGSuoO3AmsW58DOYGbmZmlyq0Kr8XMiBhUzooR8YmkR4HNge6S2qWl8FWAqXVt7yp0MzOzZiKpZ1ryRtIywM7Aa8CjwA/S1YYCo+ral0vgZmZmGU18H/jKwLWS2pIUom+NiHskvQrcIukc4AXg6rp25ARuZmaW0ZQJPCImARtWM/9/wKZLsi8ncDMzs6xiDMTmBJ6Hrp3as81aPfMOo/D++OhbeYdQeAP6dss7hFZh5mcL8g6h8BYuirxDKBwncDMzs4yijIXuBG5mZlZSoIeZOIGbmZmlBBQkfzuBm5mZfa3BA7k0Gw/kYmZmVkAugZuZmWUUpADuBG5mZpZVlCp0J3AzM7MSuQRuZmZWOALatClGBncnNjMzswJyCdzMzCzDVehmZmYF5E5sZmZmRVOgTmxuAzczMysgl8DNzMxSyVjoxSiCO4GbmZktVpyx0J3AzczMMgqSv53AzczMsopSAncnNjMzswJyCdzMzKykQLeROYGbmZml3AvdzMysoAqSv53AzczMsopSAncnNjMzswJyCdzMzCyjIAVwJ3AzM7PFVJwqdCdwMzOzVNILPe8oyuM2cDMzswJyCdzMzGwxP8zEzMyskAqSv53AzczMsopSAncbuJmZWUk6Fnp9X3XuXuor6VFJr0p6RdLx6fyzJE2VNDF97VbXvlwCNzMzaz4LgZMiYoKkrsB4SQ+lyy6OiAvL3ZETuNXoqJ8ezv333UvPnr14bvykvMMprHsuPpW3xj5G5+4rcuTf7gHgw7df474rzmThgvm0adOWXY8+i97rDMg50pbL38WG+2zmdB79y2l8+cksJLHuTj/gO7sdwrzPPmXMxScx96NpdO3Zm51+cREdu3TLO9zcNPXDTCJiOjA9fT9X0mtAn/rsy1XoVqODDhnKHaNG5x1G4Q3YaV+GnH1VpXmPXPMntj7waH5yxSi2OeR4HrnmTzlFVwz+LjZcm7bt2PyQX/Gji+9ir3Nv4tUHbmH2+28z8d9X0ec7mzHkstH0+c5mTPz31XmHmjtJ9X4t4XH6ARsCz6WzjpE0SdI1kpava3sncKvRllttw/IrrJB3GIW36nc2oVPXKiUaiflffA7A/M/n0mWFXjlEVhz+LjZc5+V70mON9QDosMyydO+zBp9//CHvPP8oa2+7FwBrb7sXU55/JM8wW4QGtoH3kDQu8zqy+mOoC/Av4ISImAP8DVgTGEhSQr+orjhdhW6Wg52PPI1bfns4Y64+n4hFDL3wlrxDsqXI3BlTmTn5NXqtNYAvP51F5+V7ArBM9x58+emsnKMrvJkRMai2FSS1J0neN0bEHQAR8WFm+T+Ae+o6UIssgUv6rAn33U/Sy021f7NyTBh9MzsdcSrHXvc4Ox1xKvdeenreIdlSYsG8L3jool+wxbBf06Fzl0rLVG5X6lauKavQlax0NfBaRPw5M3/lzGr7AHXmqRaZwPMgybUR1mxeevhO1tnyewD839aDmfaGO2ZZ01u0cAEPXXQCa229O6t/d2cAlum2Il/M/giAL2Z/xDLLLeVNFU18GxmwJXAIsEOVW8YukPSSpEnA9sAv6tpRi03gkrpIGiNpQvqh9krn95P0uqQRkv4r6UZJO0l6WtKbkjZN1ztL0vWSnk3nH1HNMYZJukvSI8CYOo75mqR/pPftPShpmXTZJmmng4mS/uTSvZWjy4q9ePelsQBMefE/rNCnX74BWasXETz+9zPo3mcNBuwxdPH81QZtx38fHwXAfx8fxWqbbJ9XiC2CqH/pu5wSeEQ8FRGKiAERMTB9jY6IQyLiO+n876e91WvVkkud84B9ImKOpB7AfyTdlS5bC/ghcBjwPHAgsBXwfeA0YO90vQHAZsCywAuS7q3mOBsBAyLi47QUXtMxvw0cEBFHSLoV2A+4AfgncEREPCvpjzV9mLQjw5EAffuuWp/z0ex+fOiBPPXk48yaOZN111yV0357JocOOzzvsArn3+efyDuTxvLlnNlcfsg2bH3wsex23Nk8dOV5LKpYSLv2HRl87O/zDrNF83ex4T584wXefOJuVlj12/zrV/sBsMkBxzNw75/w8MUn8fojd9C1Z292/EWdfadavaK0IrTkBC7gPEnbAItI7pNbKV02OSJeApD0CjAmIkLSS0C/zD5GRcSXwJeSHgU2BSZWOc5DEfFxmccsbTse6CepO9A1Ip5N598E7FHdh4mI4cBwgI02HhRLcB5y88/rbso7hFZh71//udr5h112RzNHUlz+Ljbct9bdiCNvrb6CcI8zfOtYEbXkBH4Q0BPYOCIWSJoCdEqXzc+stygzvYjKn6lqoqwucX5ej2NWAMuU9zHMzKxI2hSkCN5i28CBbsCMNJFuD6xWj33sJamTpBWB7Uiq2xvtmBHxCTBX0nfTWUPqEaOZmbUgTdyJrdG0uBJ42g49H7gRuDutFh8HvF6P3U0CHgV6AGdHxLR05Jua1OeYhwP/kLQIeBz4tB5xmplZC5Ak4mKUwFtcAgf6A29HxExg8xrWWb/0JiKGZd5PyS4DJkXEodkNs+tExAhgRGZZucfMDjb/SkQMAJB0CkniNzOzgmpTjPzdshK4pJ8BxwEn5B3LEthd0qkk5/IdYFi+4ZiZ2dKgRSXwiPg78PdG2tdZjbGfMo4zEhjZHMcyM7Om5yp0MzOzAipI/nYCNzMzKxHJaGxF0JJvIzMzM7MauARuZmaW4V7oZmZmRVPmQ0laAidwMzOzjILkbydwMzOzEuGx0M3MzKwJuQRuZmaWUZACuBO4mZlZljuxmZmZFUwejwWtrxoTuKTLgahpeUQc1yQRmZmZ5agondhqK4H7sZhmZmYtVI0JPCKuzU5L6hwRXzR9SGZmZvkpRvm7jNvIJG0u6VXg9XR6A0l/bfLIzMzMcqB0NLb6vJpTOfeBXwLsAswCiIgXgW2aMigzM7M8JAO51P/VnMoayCUi3qsyq6IJYjEzM7MylXMb2XuStgBCUnvgeOC1pg3LzMwsB63sYSY/Ay4F+gDTgAeAo5syKDMzs7wUJH/XncAjYiZwUDPEYmZmlruilMDL6YW+hqS7JX0kaYakUZLWaI7gzMzMmlNr68R2E3ArsDLQG7gNuLkpgzIzM7PalZPAO0fE9RGxMH3dAHRq6sDMzMzyUJT7wGsbC32F9O19kk4BbiEZG31/YHQzxGZmZtbsitECXnsntvEkCbv0WX6aWRbAqU0VlJmZWR6kVvAwk4hYvTkDMTMzawmaMn9L6gtcB6xEUhgeHhGXprXeI4F+wBTgRxExu7Z9lfU8cEnrA+uRafuOiOvqE7yZmdlSbCFwUkRMkNQVGC/pIWAYMCYi/pg2W58C/Lq2HdWZwCWdCWxHksBHA4OBp0iuIMzMzFqVpuyMFhHTgenp+7mSXiMZKG0vklwLcC3wGHUk8HJ6of8A2BH4ICJ+DGwAdKtP4GZmZi2dVP8X0EPSuMzryJqPo37AhsBzwEppcgf4gKSKvVblVKF/GRGLJC2UtBwwA+hbxnZmZmaFItTQTmwzI2JQnceRugD/Ak6IiDnZUn9EhKSoax/lJPBxkroD/yDpmf4Z8GwZ25mZmVkV6YPB/gXcGBF3pLM/lLRyREyXtDJJYblW5YyFflT69u+S7geWi4hJ9Q3czMysxVKT90IXcDXwWkT8ObPoLmAo8Mf0/1F17au2gVw2qm1ZREwoO2KrZGFF8MkXC/IOo/CW7VDW4+ytFu3b+Rw2hs4d2+YdQuG1pHuvm3hEtS2BQ4CXJAtppuwAACAASURBVE1M551GkrhvlXQ48A7wo7p2VFsJ/KJalgWwQ3mxmpmZFUdTXtZGxFPUPNjbjkuyr9oGctl+SXZkZmZWdKIVPU7UzMzMWp6yRmIzMzNbWjT3c73rywnczMwsoygJvM4qdCUOlnRGOr2qpE2bPjQzM7PmlYyoVozngZfTBv5XYHPggHR6LvCXJovIzMwsR21U/1dzKqcK/bsRsZGkFwAiYrakDk0cl5mZmdWinAS+QFJbknu/kdQTWNSkUZmZmeWkIHeRlZXALwPuBHpJOpfk6WS/adKozMzMciBa1qhwtSlnLPQbJY0nGSFGwN4R8VqTR2ZmZpaDogyQUmcCl7Qq8AVwd3ZeRLzblIGZmZlZzcqpQr+XpP1bQCdgdeANoH8TxmVmZpaLgtSgl1WF/p3sdPqUsqNqWN3MzKywJLWeNvCqImKCpO82RTBmZmZ5K0j+LqsN/MTMZBtgI2Bak0VkZmaWo6IMpVpOCbxr5v1CkjbxfzVNOGZmZlaOWhN4OoBL14j4ZTPFY2ZmlptWcR+4pHYRsVDSls0ZkJmZWZ4Kkr9rLYGPJWnvnijpLuA24PPSwoi4o4ljMzMza145PJSkvsppA+8EzAJ24Ov7wQNwAjczs1ZHFCOD15bAe6U90F/m68RdEk0alZmZmdWqtgTeFugC1V6KOIGbmVmrk3RiyzuK8tSWwKdHxO+bLRIzM7MWoDUk8IJ8BDMzs8ajgnRDr+2paTs2WxRmZma2RGosgUfEx80ZiJmZWd5aSxu4mZnZ0kWtYyAXMzOzpU7hh1I1MzNb2hSpCr22TmxmZmbWQrkEbmZmllGQGnQncDMzs6+JNgUZBsUJ3OpUUVHBHjtuwUor92bEzXfmHU7h/OtPp/DGc4+ybPcVOf6q0QDccvbxfPT+/wCY99lcOnXpyrFX3p1nmC3egw/czy9PPJ6KigqGHfYTfnXyKXmHVDgPXnY6k8c9RuduK3DI5cn37aPJrzPmb2exYN4XLNerD7ue+Cc6du6Sc6T5EcUpgbsN3Op0zZVXsNba6+QdRmFttMu+DP3DNZXmDfntpRx75d0ce+Xd9N96F/pv9b2coiuGiooKTjjuaEbdfR8vTHqV2265mddefTXvsApnvR33Zp8zh1ea9/AVv2WrQ0/kkMvuYq3NdmL8nVfnFF0LkT5OtL6vOncvXSNphqSXM/POkjRV0sT0tVs5oTqBW62mT32fMQ/ex5CDf5x3KIW1+oBN6dy1W7XLIoKXHx/NgO33bOaoiuX5sWNZc821WH2NNejQoQM/3H8I99w9Ku+wCmeV/pvQsUv3SvNmT5tCn/6bALDqBlvw1jMP5RHa0mQEsGs18y+OiIHpa3Q5O3ICt1qddfqvOO2s82jTxl+VpjDlpedZdvke9FilX96htGjTpk1llVX6Lp7u02cVpk6dmmNErceKfdfi7efGAPDmMw8wd+b0nCPKXxup3q+6RMQTQKOMdNokf5UlrZipCvigStVAh6Y4ZhkxZasoXpf0N0m1fn5J20m6p7libGkefmA0PXr0ZMDAjfIOpdWa9Mg9bLD9HnmHYUuxnY87l0n33cxNJ+7HV19+Ttv27fMOKVelNvD6voAeksZlXkeWeehjJE1Kq9iXL2eDJunEFhGzgIGQJE7gs4i4sK7tJLWLiIVNEVPq4oi4ME3cTwDbAo824fEKbdxzz/DQ/ffy6MP3M3/+fObOncPxPx3GpVeOyDu0VqGiYiGvPPUgR//NHQPr0rt3H95//73F01Onvk+fPn1yjKj1WGGVNdj3d0m79+ypk5k87vGcI8pfA0dimxkRg5Zwm78BZwOR/n8RcFhdGzVbvaikjSU9Lmm8pAckrZzOf0zSJZLGAcdL2lPSc5JekPSwpJXS9c5Kr0wek/Q/Scdl9v1bSW9IekrSzZJ+WUc4HYBOwOxMDIPS9z0kTakm/k0lPZvG9YykddL5wyTdIel+SW9KuqARTleLcMoZ5zD25bd5ZuJ/ueIf17HF1ts5eTeit8c/Q89V16Bbz5XzDqXFG7TJJrz11ptMmTyZr776ittG3sLue3w/77BahS8+mQVALFrE2Fv/zoBd9885oqVPRHwYERURsQj4B7BpOds1121kAi4H9oqIjyTtD5zL11cYHUpXLGnVwWYREZJ+ApwMnJSuty6wPdAVeEPS30hK+vsBGwDtgQnA+Bri+IWkg4HVgPsiYuISfIbXga0jYqGknYDz0uOSxrAhMD+N6/KIeC+7cVqNciRAn0xbnrV+I889gf+9OJYvPp3N+UO2YsehxzNo8A+Z9Ng9DHD1eVnatWvHxZdewZ6770JFRQVDhx3Gev375x1W4Yy+8CTef3ks8+Z8wlWHbcdmBxzDgnlf8OLomwBYa7OdWW/HffMNsgVo7tvIJK0cEaXOB/sAL9e2fklzJfCOwPrAQ+mD0tsC2Z4SIzPvVwFGpiX0DsDkzLJ7I2I+MF/SDGAlYEtgVETMA+ZJqu1m2lIVenvgdklDIuKWMj9DN+BaSd8mqebINhSNiYhPASS9SnKBUCmBR8RwYDjAgIEbR5nHbDE232pbNt9q27zDKKT9T7+k2vk/OLnVVNY0i10H78aug8u6u8ZqsNsvL6p2/oZ7HtrMkbRcommrpiXdDGxH0lb+PnAmsJ2kgSS5ZQrw03L21Zwl8FciYvMaln+eeX858OeIuEvSdsBZmWXzM+8rqGf8EbFA0v3ANsAtwEK+/pl1qmGzs4FHI2IfSf2Axxo7LjMzy5lATVgEj4gDqpldr5vvm6sNfD7QU9LmAJLaS6qp/qsbULo/ZGgZ+34a2FNSJ0ldgDrrJJX8dLYE3k5nTQE2Tt//oIy4hpURl5mZFZAa8GpOzZXAF5EkxvMlvQhMBLaoYd2zgNskjQdm1rXjiHgeuAuYBNwHvAR8WsPqv5A0kaR9oS3w13T+hcDPJb0A9Khh2wuAP6TruIRtZma5avJEFBFnZSa3qWb5dlWmRwHfGGKpyn6IiPUzkxdGxFmSOpPcHvaNTmzp9mdVnZ8uex0YkJn1m3T+Y6RV5RHxLLB2NeuMIBlZp7Qv90oyMyuo5HngxRgMvbWUJIdLWo+k/fraiJiQd0BmZlZMxUjfrSSBR8SBecdgZmatQ0EK4B4L3czMrIhaRQnczMyscahJbyNrTE7gZmZmqaYeyKUxOYGbmZlluARuZmZWQMVI38WpKTAzM7MMl8DNzMxKmngs9MbkBG5mZpZyJzYzM7OCcgnczMysgIqRvotTU2BmZmYZLoGbmZllFKQG3QnczMysJOnEVowM7gRuZmaWUZQSuNvAzczMCsglcDMzs8WEXIVuZmZWPEWpQncCNzMzS7kTm5mZWRGpOCVwd2IzMzMrIJfAzczMMopSAncCNzMzy3AvdDMzs4IR0KYY+dsJ3MzMLKsoJXB3YjMzMysgl8DNzMwy3InNzMysgIpShe4EbmZmlipSJza3gZuZmTUTSddImiHp5cy8FSQ9JOnN9P/ly9mXE7iZmdliatC/MowAdq0y7xRgTER8GxiTTtfJCdzMzKwkHQu9vq+6RMQTwMdVZu8FXJu+vxbYu5xQ3QZuZmaW0cAm8B6SxmWmh0fE8Dq2WSkipqfvPwBWKudATuBmZmappBNbg1L4zIgYVN+NIyIkRTnrOoHnoH1b0XO5jnmHUXgnbrtW3iEU3oKFi/IOoVX4+5lX5B1C4c2fNiPvEPL0oaSVI2K6pJWBsk6G28DNzMwy1IBXPd0FDE3fDwVGlbORE7iZmVlWE2ZwSTcDzwLrSHpf0uHAH4GdJb0J7JRO18lV6GZmZhlNORJbRBxQw6Idl3RfTuBmZmYZRRkL3VXoZmZmBeQSuJmZWUZBCuBO4GZmZpUUJIM7gZuZmaWSzuTFyOBuAzczMysgl8DNzMxKynwoSUvgBG5mZpZRkPztBG5mZlZJQTK4E7iZmdlicic2MzMzazougZuZmWW4E5uZmVnBNPCxoM3KCdzMzCyrIBncCdzMzCzDndjMzMysybgEbmZmluFObGZmZgVUkPztBG5mZrZYgbqhuw3czMysgFwCNzMzyyhKL3QncDMzs5RwJzYzM7NCKkj+dgI3MzOrpCAZ3J3YzMzMCsglcDMzswx3YjMzMysgd2IzMzMroILkbydwMzOzSgqSwd2JzczMrICcwK1WDz5wPwP6r0P/ddfiTxf8Me9wCsnnsOGO+unhrLHqt/juxgPyDqWwYtFC5v/3Nua/fgvzX7+JBdOfA6Bi7vvMf2Mk81+/ma/eeZiIRTlHmq9kKPT6/2tOTuBWo4qKCk447mhG3X0fL0x6ldtuuZnXXn0177AKxeewcRx0yFDuGDU67zCKTW3psOZedFx3CB3W2Z9Fc99l0efTWfDuGNqvtgsd1z0AdehKxcev5x1pvpR0Yqvvqzk5gVuNnh87ljXXXIvV11iDDh068MP9h3DP3aPyDqtQfA4bx5ZbbcPyK6yQdxiFJgm17ZBMxKLkhZDa0KZTdwDadu3Lok/ezi/IFkINeDUnJ3Cr0bRpU1lllb6Lp/v0WYWpU6fmGFHx+BxaSxKxKKlCf/ka2nTtizqvRMQiFn0xA4CKT94mFnyWc5Stn6Qpkl6SNFHSuPruJ9de6JJWBMakk98CKoCP0ulNI+KrzLq9gcsi4gd17POziOhSxzrDgD8BU4FOwJURcXG9PoSZWUFIbei47hBi4XwWTLmPmPcxHfrtwoKpT0FU0KZrXwrTBbspNc8p2D4iZjZkB7km8IiYBQwEkHQW8FlEXFjDutOAWpP3EhoZEcekFxFvSLo9It5rxP0XXu/efXj//a9PydSp79OnT58cIyoen0NridSuI2269GHR3Hdp12tDOn57XwAq5rxLzP8k5+jy1vyd0eqrxVWhSxoh6QeZ6c/S//tJejl9P0zSFZl17pG0XWb6XEkvSvqPpJVqO156EfEWsHL2GOl+fpleWCDpMUmXplUeL0vaNJ2/qaRnJb0g6RlJ6zTGeWgJBm2yCW+99SZTJk/mq6++4raRt7D7Ht/PO6xC8Tm0liIWfkksnJ+8X7SQirnvoY7LEwu+SOdVUDFjAm1XXD/PMFuEBnZi6yFpXOZ1ZDWHCOBBSeNrWF6W1jiQy7LAfyLidEkXAEcA59S0sqRVSarRJ5FU49emc0QMlLQNcA2wPvA6sHVELJS0E3AesF81xzkSOBKg76qrLvmnykG7du24+NIr2HP3XaioqGDosMNYr3//vMMqFJ/DxvHjQw/kqScfZ9bMmay75qqc9tszOXTY4XmHVSix4HMWvDsGIoCgbfe1aNutHwumPs2iOe8k81Zcn7ZdV8k71Fw1Qme0mRExqI51toqIqZJ6AQ9Jej0inljSA7XGBP4VcE/6fjywcw3r7Z8m4nWBYyJinuq+B+BmgIh4QtJykroDXYFrJX2b5KqqfXUbRsRwYDjAxhsPiiX4PLnadfBu7Dp4t7zDKDSfw4b753U35R1C4bVZpgcd19n/G/Pb99kS+myZQ0RLr4iYmv4/Q9KdwKbAEifwFleFDiwkjUtSG6BDbeukOmXeL4iIUoKsoOaLlJERMQDYAvijpG/VsV9IEnTV6bOBRyNifWDParYxM7MiacL7yCQtK6lr6T3wPeDl2reqXktM4FOAjdP336f6Eu0UYKCkNpL6kly91EtEjAOuB44HPgR6SVpRUkdgjyqr7w8gaSvg04j4FOhG0psdYFh94zAzs5ahiUdiWwl4StKLwFjg3oi4vz5xtsQq9H8Ao9IPdz/weWZZqQT8NDAZeBV4DZjQwGOen+7jPOD3JCd1Kkn7dtY8SS+QXFQcls67gKQK/TfAvQ2Mw8zMctaUI6pFxP+ADRpjXy0mgUfEWZnJzTLvf53+vyLwcbpuAAfVsJ8umfe3A7dXs84IYERmehpfd2C7LH1V54aIOKHKvp4F1s7M+k0N25qZWQEU4yayllmF/g2SBpF0ILs071jMzMxaghZTAq9N2k69dp0rNm0M2+V5fDMzawY5PJSkvgqRwM3MzJpPMTK4E7iZmVlKFKcEXog2cDMzM6vMJXAzM7OMghTAncDNzMyyilKF7gRuZmaWUZTHiTqBm5mZZRUjf7sTm5mZWRG5BG5mZpZRkAK4E7iZmVmJPBKbmZlZMRWlE5vbwM3MzArIJXAzM7OsYhTAncDNzMyyCpK/ncDNzMyy3InNzMyscORObGZmZtZ0XAI3MzNL+XngZmZm1qRcAjczM8soSgncCdzMzCzDndjMzMysybgEbmZmVuKHmZiZmRWP8EhsZmZmxVSQDO42cDMzswJyCdzMzCyjKL3QncDNzMwy3InNzMysgAqSv90GbmZmVoka8Cpn99Kukt6Q9JakU+obphO4mZlZM5HUFvgLMBhYDzhA0nr12ZcTuJmZWYYa8K8MmwJvRcT/IuIr4BZgr/rE6QRuZmaWKj1OtL6vMvQB3stMv5/OW2LuxJaDCRPGz1ymvd7JO4469ABm5h1EK+Dz2HA+h42jpZ/H1fIOAGDChPEPLNNePRqwi06SxmWmh0fE8IbGVR0n8BxERM+8Y6iLpHERMSjvOIrO57HhfA4bh89jeSJi1yY+xFSgb2Z6lXTeEnMVupmZWfN5Hvi2pNUldQCGAHfVZ0cugZuZmTWTiFgo6RjgAaAtcE1EvFKffTmBW02apM1mKeTz2HA+h43D57GFiIjRwOiG7kcR0QjhmJmZWXNyG7iZmVkBOYGbmZkVkNvAzazFkdSH5L7gxX+jIuKJ/CIya3mcwA0ASS8BVTtEfAqMA86JiFnNH1Wx+Bw2DknnA/sDrwIV6ewAnMCXgKRvA38gGW+7U2l+RKyRW1DWqJzAreQ+kj+WN6XTQ4DOwAfACGDPfMIqFJ/DxrE3sE5EzM87kIL7J3AmcDGwPfBj3GzaqrgXugEgaUJEbFTdPEkvRcR38oqtKHwOG4ek+4AfRsRnecdSZJLGR8TG2e9eaV7esVnjcAncStpK2jQixgJI2oRkkAGAhfmFVSg+h43jC2CipDHA4lJ4RByXX0iFNF9SG+DNdOCQqUCXnGOyRuQEbiU/Aa6R1IXkgTxzgJ9IWpakHc3q5nPYOO6inkNLWiXHkzThHAecDewADM01ImtUrkK3SiR1A4iIT/OOpah8Dq0lkbQcEBExN+9YrHE5gRsAkjoC+wH9qHzrzu/ziqlofA4bh3tPNw5Jg0g6snVNZ30KHBYR4/OLyhqTq9CtZBTJL/h4Mu2OtkR8DhuHe083jmuAoyLiSQBJW5Gc2wG5RmWNxiVwA0DSyxGxft5xFJnPYeNw7+nGIemFiNiwyrxv3ClhxeUSuJU8I+k7EfFS3oEUmM9h43Dv6cbxuKQrgZtJBsLZH3hM0kYAETEhz+Cs4VwCNwAkvQqsBUwmqf4VSccXV7eVyeewcaS3370GdCfpPd0NuCAi/pNrYAUj6dFaFkdE7NBswViTcAI3ACStVt38iHinuWMpKp9DM2tOTuC2mKQNgK3TyScj4sU84ykqSb2o3Hv63RzDKQxJd/PNseQXi4jvN2M4hSfpjOrm+66I1sNt4AaApOOBI4A70lk3SBoeEZfnGFahSPo+cBHQG5hB8jSt14D+ecZVIBfmHUAr83nmfSdgD5Lvo7USLoEbAJImAZtHxOfp9LLAs26/LZ+kF0lGu3o4IjaUtD1wcEQcnnNoZqVxCh6IiO3yjsUah0vgViK+fnQj6XvlFEtRLYiIWZLaSGoTEY9KuiTvoIpG0mSqqUr3QC4N1hlYJe8grPE4gVvJP4HnJN2ZTu8NXJ1jPEX0SToO+hPAjZJmULka08ozKPO+E/BDYIWcYimsKs+nbwv0JOnVb62Eq9BtsfT+0K3SyScj4oU84ymatNnhS5JRww4iuf3pxoiYlWtgrYAHcllyVe6KWAh8CHQsNZNZ8TmBL+UkLRcRcyRVW8KJiI+bO6YiktSWpO17+7xjKbrSQCOpNiQl8p9HxAY5hVQ4kvoAKwOTIuKr9M6IE4BhEdE73+issbgK3W4i6Z06nsrtjkqn3e5YhoiokLRIUjc/hazBLsq8XwhMAX6UTyjFI+kE4HTgLaCjpL8C5wPXAa7FaEVcArcaSeoTEVPzjqMoJI0CNgQeItP2HRHH5RaULXXSEQG3ioiPJa0K/BfY0k8ha31cArfaPAusmncQBXIHX99Hb/UgaVtgdkRMkvQjYBvgbeCvEeEnvJVnXqnpKyLelfSGk3fr5BK41UjSexHRN+84bOkg6S8kj7rsBLxB8gCT+4EtgTYRcVCO4RVGevfDLZlZQ7LTrhFqPVwCt9r46q4MVW7X+QYPhlO27SNiPUmdSJ5A1ivtW3AlMCnn2IrkV1WmXfpupZzAl3KSLqf65COSp0FZ3fbIO4BWYh5ARMyT9E5EVKTTIWlBvqEVR0Rcm3cM1jycwG1cPZdZKvu0MUnfAjYluSh6PiI+yC2w4ukl6USSi8fSe9LpnvmFZdYyuQ3crJFI+glwBvAISdLZFvh9RFyTa2AFIenM2pZHxO+aKxazInACN2skkt4AtiiNvCZpReCZiFgn38jMrDVyFbpZ45kFzM1Mz03nmTU7ST1JHhHcj8zf+og4LK+YrHE5gRsAklaoOmyqpNUjYnJeMRXQWyQPhBlF0ga+FzCp1JYbEX/OMzhb6owCngQepvKTBq2VcAK3krslDY6IOQCS1gNuBdbPN6xCeTt9lYxK/++aQyxmnSPi13kHYU3HbeAGgKTdgZOB3YF1SMZNPigiJuYamC11Mr3Psz4Fxvv7WD5J55D0wRiddyzWNJzAbTFJe5Mk8a7AfhHx35xDKhRJg0geIrEaldscPZDLEpB0E8kTyO5OZ+1BMpBLP+C2iLggp9AKQdJckiYcAcsC84EF6XRExHI5hmeNyAl8KVfNQC47klQDTwEPu7gk0l7ovwJeAhaV5mfvE7e6SXoC2C0iPkunuwD3AruSlMLXyzM+s5bCbeBWdbAWD7tYfx9FxF15B9EK9CIpNZYsAFaKiC8l+YEmZZK0TXXzI+KJ5o7FmoYT+FLOwy42qjMlXQWMIZOAIsJPKFsyN/J1b36APYGbJC0LvJpfWIWTHRO9E8kIgeOBHfIJxxqbq9CXcpJujYgf1fRADrfflk/SDcC6wCt8XYUevu92yUnaBNginXw6IjysbwNJ6gtcEhH75R2LNQ4n8KWcpJUjYrqk1apb7vbb8qXPXfaoa41AUltgJSp3Bnw3v4iKT5KAV9yHoPVwFfpSLiKmp2+PqnrPqKTzAd9HWr5nJK0XEa7mbQBJxwJnAh+SDEAiktoh1wYtgSodVNsAA4EJ+UVkjc0lcANA0oSI2KjKvEmuQi+fpNeANYHJJG3gpdt2fA6XgKS3gO+WxpS3+pE0NDO5EJgSEU/nFY81PpfAl3KSfg4cBawhaVJmUVfAv+xLZte8A2gl3iMZuMUawB1UWz+XwJdykroBywN/AE7JLJpbdWx0K4+kXiS9fgG33S4pSVeTjAZ4L5V783ss+TLU0TE1gI9JOrON+ubWViRO4FaJk0/9Sfo+cBHQG5hBMiLbaxHRP9fACqam54L7eeDlqatjKtADuDEi1m3OuKzxOYEbAJL2BP6Mk0+9SXqR5B7bhyNiQ0nbAwdHxOE5h2ZWiaSNI8KDNhWc28Ct5BxgM6okn5xjKpoFETFLUhtJbSLiUUmX5B1U0aTPsT4Z6E/l2iAPQLIEMmOiA3QA2gOfR8RyTt6tgxO4lTj5NNwn6bjdTwI3SpoBfJ5zTEV0IzCS5CEmPwOGAh/lGlEBRcTix9im94DvRXKRbq2Eq9ANAEkPA3uTdGbrQVKNvklEbFHrhraYpM7APJLbxw4GliNpa3RnwCUgaXxEbJy9jVHS8xGxSd6xFYGkdhGxsIZlL0TEhs0dkzUNl8CtZC/gS+AXwEFAN+D3uUZUEFWqKhfPTv8/Q9LbwOkRMaZ5IyusBen/09Pn1E8DVsgxnqIZC2wkad/MvDYkj2idl09I1hScwA2AiChV9S6SdC8wK1w9U5ZsVWVV6ZCg65NUC6/fbEEV2znp7Y0nAZeT1GT8It+QCmlPvr6wXEjyiODv5xaNNTpXoS/lJG0G/JHk3tCzgetJqtDbAIdGxP05htdqSPppRFyZdxwtXXrBc1xEXJx3LEUl6X2SO0pUZVGA76dvTVwCtyuA00iqzB8BBkfEfyStC9wMOIE3Aifv8kREhaQDACfw+msLdOGbCdxaGZfAl3KSJkbEwPT9axHxf5ll7vBizU7SxSS3PI0k04s/IvwgjjJU91wDa51cArdFmfdfVlnmqzvLw8D0/2wnyiAZJMfq5pL3UsIl8KWcpAqSUo6AZYAvSouAThHRPq/YzOz/27u/ECvKMI7j399WmFlJq5sUFIX9sUXKwkqNFpOIti7CMAK7yzCDlIyu++NFBAXeRPRnDYkoSqwwgt0lQ1ylcEs03I3ywuiimzCzNCtYni7mOe3psOo5Intm2N/nZmffM++8z8zNM+8777zTOkmdfnVxanACN7NSkTQHeBG4PCJ6JXUDiyNiU5tDMyuVjnYHYGbWYDMwQLEuP8APwFNti8aspJzAzawUJNXm5MyOiA/J+Rm5qthY2wIzKykncDMriz3597ikWeQkylyr4GjbojIrKc9CN7OyqM2efhrYBsyVtBvoAla0LSqzkvIkNjMrhboVxKAYHZxGkdT/Bsa8gpjZ/7kHbmZlcbIVxC5oQyxmpeceuJmVglcQM2uNJ7GZWVl4BTGzFrgHbmal4BXEzFrjBG5mZlZBHkI3MzOrICdwMzOzCnICN5tEksYk7ZN0QNIWSWf8ipSkzZJW5HZffvTjZPsulbTkDNr4UdLsZssb9jnWYlvPS3qm1RjNpioncLPJdSIiFkTEfOAfYE39j3XrgbckIh6LiNFT7LIUaDmBm1l5OYGbtc8QcE32jockbQNGJZ0j6WVJw5K+lfQ4gAqvSvpe0ufApbUDjopc4gAAAn9JREFUSdohaWFu3ytpr6T9krZLuoriRmF99v7vlNQlaWu2MSzpjqw7S9KgpBFJfTTxapekTyR9k3VWN/y2Mcu3S+rKsrmS+rPOkKR5Z+Nimk01XonNrA2yp90L9GfRLcD8iDiUSfBoRNwqaRqwW9IgcDNwPdANzAFGgbcbjtsFvAX05LE6I+JXSa8DxyLildzvPWBjROySdCXF5ztvAJ4DdkXEBkn3A6uaOJ1Hs43pwLCkrRFxGJgBfB0R6yU9m8d+EngTWBMRByXdDrwGLDuDy2g2pTmBm02u6ZL25fYQsIliaHtPRBzK8nuAG2vPt4GZwLVAD/B+RIwBP0v6YoLjLwJ21o51iveq7wa6pf862BdLujDbeDDrfibpSBPntE7S8ty+ImM9TPE50A+y/F3go2xjCbClru1pTbRhZg2cwM0m14mIWFBfkInseH0RsDYiBhr2u+8sxtEBLIqIvyaIpWmSllLcDCyOiD8l7QDOP8nuke3+1ngNzKx1fgZuVj4DwBOSzgOQdJ2kGcBO4OF8Rn4ZcNcEdb8CeiRdnXU7s/wP4KK6/QaBtbV/JNUS6k5gZZb1ApecJtaZwJFM3vMoRgBqOhj/DOhKiqH534FDkh7KNiTpptO0YWYTcAI3K58+iufbeyUdAN6gGC37GDiYv70DfNlYMSJ+AVZTDFfvZ3wI+1NgeW0SG7AOWJiT5EYZnw3/AsUNwAjFUPpPp4m1HzhX0nfASxQ3EDXHgdvyHJYBG7L8EWBVxjcCPNDENTGzBl5K1czMrILcAzczM6sgJ3AzM7MKcgI3MzOrICdwMzOzCnICNzMzqyAncDMzswpyAjczM6sgJ3AzM7MK+hc9R1NsRGEbYgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Confussion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm_labels = ['Batik Liong','Jamplrang', 'Terang Bulan', 'Tujuh Rupa']\n",
        "\n",
        "y_true = np.argmax(test_targets, axis=1)\n",
        "y_pred = np.argmax(xception.predict(test_tensors), axis=1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "indexes = np.arange(len(cm_labels))\n",
        "for i in indexes:\n",
        "    for j in indexes:\n",
        "        plt.text(j, i, cm[i, j])\n",
        "plt.xticks(indexes, cm_labels, rotation=90)\n",
        "plt.xlabel('Predicted label')\n",
        "plt.yticks(indexes, cm_labels)\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix, Early Stopping Best Model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "EsqYNyL1UYkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b853fe9c-521a-42fc-ace5-ee49ccae5b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " Batik Liong       0.71      0.30      0.42        40\n",
            "   Jamplrang       0.40      0.45      0.42        40\n",
            "Terang Bulan       0.00      0.00      0.00        40\n",
            "  Tujuh Rupa       0.41      0.97      0.57        40\n",
            "\n",
            "    accuracy                           0.43       160\n",
            "   macro avg       0.38      0.43      0.35       160\n",
            "weighted avg       0.38      0.43      0.35       160\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.argmax(test_targets, axis=1), np.argmax(xception.predict(test_tensors), axis=1), target_names=cm_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "cuRuiTk340rK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b483a101-f835-4a6f-a862-a9b8ca0de1b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.53619026, 0.59055059, 0.        , 0.7154544 ])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# Geometric Mean\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "geometric_mean_score(y_true, y_pred, pos_label=1, average=None, correction=0.0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Xception_4_Kelas.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "55b315c3dbf10ef7f12b59bd8ad1fda37f03e8048b8c0ccbc36f7a976bce2219"
    },
    "kernelspec": {
      "display_name": "Python 3.8.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}